reference_dict = {'LogiCoT: Logical Chain-of-Thought Instruction Tuning': ['Falcon-40B: an open large language model with state-of-the-art performance', 'Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality', 'Scaling instruction-finetuned language models', 'Explaining answers with entailment trees', 'Specializing smaller language models towards multi-step reasoning', 'Pal: Program-aided language models', 'Folio: Natural language reasoning with first-order logic', 'Measuring mathematical problem solving with the math dataset', 'Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes', 'Towards reasoning in large language models: A survey', 'Large language models are zero-shot reasoners', "Symbolic chain-of-thought distillation: Small models can also 'think' step-by-step", 'Augmenting neural networks with first-order logic', 'Evaluating the logical reasoning ability of chatgpt and gpt-4', 'Logiqa: A challenge dataset for machine reading comprehension with logical reasoning', 'From zero to hero: Examining the power of symbolic tasks in instruction tuning', 'The flan collection: Designing data and methods for effective instruction tuning', 'Natural logic for textual inference', 'Teaching small language models to reason', 'Cross-task generalization via natural language crowdsourcing instructions', 'Logicinference: A new dataset for teaching logical inference to seq2seq models', 'Gpt-4 technical report', 'Training language models to follow instructions with human feedback', 'Instruction tuning with gpt-4', 'Multitask prompted training enables zero-shot task generalization', 'Paradigm shift in natural language processing', 'Stanford alpaca: An instruction-following llama model', 'Llama: Open and efficient foundation language models', 'GLUE: A multi-task benchmark and analysis platform for natural language understanding', 'GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model', 'Pinto: Faithful language reasoning using prompt-generated rationales', 'Self-instruct: Aligning language model with self generated instructions', 'Finetuned language models are zero-shot learners', 'Chain-of-thought prompting elicits reasoning in large language models', 'Reclor: A reading comprehension dataset requiring logical reasoning', 'Star: Bootstrapping reasoning with reasoning', 'Adapting language models for zero-shot learning by meta-tuning on dataset and prompt collections', 'Large language models are human-level prompt engineers'], 'MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of Thought Prompting': ['Language models are few-shot learners', 'PaLM: Scaling Language Modeling with Pathways', 'Training verifiers to solve math word problems', 'SemEval-2012 task 7: Choice of plausible alternatives: An evaluation of commonsense causal reasoning', 'Large language models are zero-shot reasoners', 'Solving quantitative reasoning problems with language models', 'Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing', 'NumGLUE: A suite of fundamental yet challenging mathematical reasoning tasks', 'Webgpt: Browser-assisted question-answering with human feedback', 'Commonsense reasoning for natural language processing', 'Chain-of-thought prompting elicits reasoning in large language models', 'React: Synergizing reasoning and acting in language models', 'OPT: Open Pre-trained Transformer Language Models'], 'Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference': ['Synthetic QA corpora generation with roundtrip consistency', 'Logicguided data augmentation and regularization for consistent question answering', 'Hyperopt: A python library for optimizing the hyperparameters of machine learning algorithms', "Can NLI models verify QA systems' predictions?", 'Transforming question answering datasets into natural language inference datasets', 'Evaluating coherence in dialogue systems using entailment', 'Measuring and improving consistency in pretrained language models', 'TRUE: Re-evaluating factual consistency evaluation', 'Rc2: an efficient maxsat solver', 'Maieutic prompting: Logically consistent reasoning with recursive explanations', 'BeliefBank: Adding memory to a pre-trained language model for a systematic notion of belief', 'ViLT: Vision-and-language transformer without convolution or region supervision', 'Visual genome: Connecting language and vision using crowdsourced dense image annotations', 'Natural questions: A benchmark for question answering research', 'SummaC: Re-visiting NLI-based models for inconsistency detection in summarization', 'ALBERT: A lite BERT for selfsupervised learning of language representations', 'A logic-driven framework for consistency of neural models', 'Roberta: A robustly optimized BERT pretraining approach', 'An introduction to factor graphs', 'Modeling semantic containment and exclusion in natural language inference', 'Fast model editing at scale', 'Improving factual completeness and consistency of image-to-text radiology report generation', 'Adversarial NLI: A new benchmark for natural language understanding', 'Differentiation of blackbox combinatorial solvers', 'Exploring the limits of transfer learning with a unified text-to-text transformer', "Know what you don't know: Unanswerable questions for SQuAD", 'SQuAD: 100,000+ questions for machine comprehension of text', 'Sunny and dark outside?! improving answer consistency in VQA through entailed question generation', 'Unsupervised commonsense question answering with self-talk', 'Editable neural networks', 'Generating persona consistent dialogues by exploiting natural language inference', 'Conceptnet 5.5: An open multilingual graph of general knowledge', 'Generalpurpose question-answering with macaw', 'LXMERT: Learning cross-modality encoder representations from transformers', 'Diverse beam search for improved description of complex scenes', 'Dialogue natural language inference', 'A broad-coverage challenge corpus for sentence understanding through inference'], 'COMPLEXITY-BASED PROMPTING FOR MULTI-STEP REASONING': ['Notes on teaching gpt-3 adding numbers', 'MathQA: Towards interpretable math word problem solving with operation-based formalisms', 'Language models are few-shot learners', 'Evaluating large language models trained on code', 'Learning an Executable Neural Semantic Parser', 'Palm: Scaling language modeling with pathways', 'Training verifiers to solve math word problems', 'Selection-inference: Exploiting large language models for interpretable logical reasoning', 'Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies', 'Scaling laws for neural language models', 'Large language models are zero-shot reasoners', 'Why machine reading comprehension models learn shortcuts?', 'Internet-augmented language models through few-shot prompting for open-domain question answering', 'Solving quantitative reasoning problems with language models', 'Prefix-tuning: Optimizing continuous prompts for generation', 'On the advance of making language models better reasoners', 'Learning executable semantic parsers for natural language understanding', 'What makes good in-context examples for GPT-3?', 'Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'Did the model understand the question?', 'Sentence-bert: Sentence embeddings using siamese bert-networks', 'Pushing the limits of rule reasoning in transformers through natural language satisfiability', "Extrapolating to unnatural language processing with gpt-3's in-context learning: The good, the bad, and the mysterious", 'Solving general arithmetic word problems', 'Learning to retrieve prompts for in-context learning', 'AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts', 'Selective annotation makes language models better few-shot learners', 'What makes reading comprehension questions easier?', 'Challenging big-bench tasks and whether chain-of-thought can solve them', 'LaMDA: Language models for dialog applications', 'Universal adversarial triggers for attacking and analyzing NLP', 'Rationale-augmented ensembles in language models', 'Self-consistency improves chain of thought reasoning in language models', 'Why do pretrained language models help in downstream tasks? An analysis of head and prompt tuning', 'Emergent abilities of large language models', 'Chain of thought prompting elicits reasoning in large language models', 'An explanation of in-context learning as implicit Bayesian inference', 'StructVAE: Tree-structured latent variable models for semi-supervised semantic parsing', 'Calibrate before use: Improving few-shot performance of language models'], 'Reasoning with Language Model is Planning with World Model': ['Working memory', 'Mental imagery and the varieties of amodal perception', 'Language models are few-shot learners', 'Sparks of artificial general intelligence: Early experiments with gpt-4', 'The computational complexity of propositional strips planning', 'Model predictive control', 'Palm: Scaling language modeling with pathways', 'Training verifiers to solve math word problems', 'Efficient selectivity and backup operators in monte-carlo tree search', 'Task and motion planning with large language models for object rearrangement', 'Designology: Studies on Planning for Action', 'Mental models', 'Recurrent world models facilitate policy evolution', 'World models', 'Dream to control: Learning behaviors by latent imagination', 'Mastering atari with discrete world models', 'Toolkengpt: Augmenting frozen language models with massive tools via tool embeddings', 'Bertnet: Harvesting knowledge graphs with arbitrary relations from pretrained language models', 'Control of mental representations in human planning', 'Towards reasoning in large language models: A survey', 'Inner monologue: Embodied reasoning through planning with language models', 'Bonsai trees in your head: how the pavlovian system sculpts goal-directed choices by pruning decision trees', 'Task planning in robotics: an empirical comparison of pddl-and asp-based systems', 'Mental models and human reasoning', 'Mental models: Towards a cognitive science of language, inference, and consciousness', 'Gpt is becoming a turing machine: Here are some ways to program it', 'Bandit based monte-carlo planning', 'Large language models are zero-shot reasoners', 'A path towards autonomous machine intelligence', 'Language modeling with latent situations', 'Llm+ p: Empowering large language models with optimal planning proficiency', 'Faithful chain-of-thought reasoning', 'Deep learning, reinforcement learning, and world models', 'Situations, actions, and causal laws', 'Augmented language models: a survey', 'Gpt-4 technical report', 'Refiner: Reasoning feedback on intermediate representations', 'Virtualhome: Simulating household activities via programs', 'Language models are greedy reasoners: A systematic formal analysis of chain-of-thought', 'Toolformer: Language models can teach themselves to use tools', 'Mastering atari, go, chess and shogi by planning with a learned model', 'Action, perception and the brain: Adaptation and cephalic expression', 'Planning to explore via self-supervised world models', 'Reflexion: an autonomous agent with dynamic memory and self-reflection', 'Mastering chess and shogi by self-play with a general reinforcement learning algorithm', 'Progprompt: Generating situated robot task plans using large language models', 'Cognitive maps in rats and men', 'Llama: Open and efficient foundation language models', 'Llama 2: Open foundation and fine-tuned chat models', "Large language models still can't plan (a benchmark for llms on planning and reasoning about change)", 'On the planning abilities of large language models (a critical investigation with a proposed benchmark)', 'Self-consistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'Generating sequences by learning to self-correct', 'Daydreamer: World models for physical robot learning', 'Language models meet world models: Embodied experiences enhance language models', 'Tree of thoughts: Deliberate problem solving with large language models', 'Least-to-most prompting enables complex reasoning in large language models', 'Adaptive information seeking for open-domain question answering'], 'TAKE A STEP BACK: EVOKING REASONING VIA ABSTRACTION IN LARGE LANGUAGE MODELS': ['Palm 2 technical report', 'Language models are few-shot learners', 'A dataset for answering time-sensitive questions', 'Palm: Scaling language modeling with pathways', 'Bert: Pre-training of deep bidirectional transformers for language understanding', 'Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies', 'Measuring massive multitask language understanding', 'Training compute-optimal large language models', 'Scaling laws for neural language models', 'Decomposed prompting: A modular approach for solving complex tasks', 'Large language models are zero-shot reasoners', 'Draw me a flower: Processing and grounding abstraction in natural language', "Let's verify step by step", 'Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing', "Reframing instructional prompts to gptk's language", 'Cross-task generalization via natural language crowdsourcing instructions', 'Show your work: Scratchpads for intermediate computation with language models', 'Gpt-4 technical report', "Don't blame the annotator: Bias already starts in the annotation instructions", 'Is a question decomposition unit all we need?', 'Measuring and narrowing the compositionality gap in language models', 'Exploring the limits of transfer learning with a unified text-to-text transformer', "Kepler's laws of planetary motion: 1609–1666", 'Recitation-augmented language models', 'Llama 2: Open foundation and fine-tuned chat models', 'Musique: Multihop questions via single-hop question composition', 'Attention is all you need', 'Finetuned language models are zero-shot learners', 'Emergent abilities of large language models', 'Chain-of-thought prompting elicits reasoning in large language models', 'Large language models as optimizers', 'Situatedqa: Incorporating extra-linguistic contexts into qa', 'Calibrate before use: Improving few-shot performance of language models', 'Least-to-most prompting enables complex reasoning in large language models'], 'Large Language Models are Better Reasoners with Self-Verification': ['What learning algorithm is in-context learning? investigations with linear models', 'Mathqa: Towards interpretable math word problem solving with operation-based formalisms', 'Are nlp models really able to solve simple math word problems?', 'Ask me anything: A simple strategy for prompting language models', 'Logicguided data augmentation and regularization for consistent question answering', 'Abductive commonsense reasoning', 'Language models are few-shot learners', 'Evaluating large language models trained on code', 'A survey of chain of thought reasoning: Advances, frontiers and future', 'Training verifiers to solve math word problems', 'Reasonbert: Pre-trained to reason with distant supervision', 'Chain-of-verification reduces hallucination in large language models', 'On a new law of large numbers', 'Complexity-based prompting for multi-step reasoning', 'Pal: Program-aided language models', 'Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies', 'Eva2.0: Investigating open-domain chinese dialogue systems with large-scale pre-training', 'Array programming with numpy', 'Large language models are reasoning teachers', 'Learning to solve arithmetic word problems with verb categorization', 'A multi-type multi-span network for reading comprehension that requires discrete reasoning', 'Qascore - an unsupervised unreferenced metric for the question generation evaluation', 'Large language models are zero-shot reasoners', 'Parsing algebraic word problems into equations', 'Learning to automatically solve algebra word problems', 'More but correct: Generating diversified and entity-revised medical response', 'Modeling intrarelation in math word problems with different functional multi-head attentions', 'On the advance of making language models better reasoners', "Let's verify step by step", 'Program induction by rationale generation : Learning to solve and explain algebraic word problems', 'Logiqa: A challenge dataset for machine reading comprehension with logical reasoning', 'What makes pre-trained language models better zero/few-shot learners?', 'Language models of code are few-shot commonsense learners', 'Training language models to follow instructions with human feedback', 'Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'Paradigm shift in natural language processing', 'Answer-focused and position-aware neural question generation', 'Commonsenseqa: A question answering challenge targeting commonsense knowledge', 'Towards understanding chain-of-thought prompting: An empirical study of what matters', 'Translating a math word problem to a expression tree', 'Logic-driven context extension and data augmentation for logical reasoning of text', 'Large language models are implicitly topic models: Explaining and finding good demonstrations for in-context learning', 'Self-consistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'Large language models need holistically thought in medical conversational qa', 'Mastering symbolic operations: Augmenting language models with compiled neural networks', 'Medconqa: Medical conversational question answering system based on knowledge graphs', 'A survey on non-autoregressive generation for neural machine translation and beyond', 'Human parity on commonsenseqa: Augmenting self-attention with external attention', 'Turning tables: Generating examples from semistructured tables for endowing language models with reasoning skills', 'Reclor: A reading comprehension dataset requiring logical reasoning', 'Towards better chain-of-thought prompting strategies: A survey', 'Automatic chain of thought prompting in large language models', 'Least-to-most prompting enables complex reasoning in large language models', 'A knowledge storage and semantic space alignment method for multi-documents dialogue generation', 'Reasonchainqa: Text-based complex question answering with explainable evidence chains', 'Learning to build reasoning chains by reliable path retrieval'], 'Chain of Hindsight aligns Language Models with Feedback': ['Hindsight experience replay', 'A general language assistant as a laboratory for alignment', 'An actor-critic algorithm for sequence prediction', 'Training a helpful and harmless assistant with reinforcement learning from human feedback', 'Constitutional ai: Harmlessness from ai feedback', 'Better rewards yield better summaries: Learning to summarise without references', 'Language models are few-shot learners', 'Decision transformer: Reinforcement learning via sequence modeling', 'Towards coherent and cohesive long-form text generation', 'Deep reinforcement learning from human preferences', 'Scaling instruction-finetuned language models', 'Hierarchical neural story generation', 'Controlling linguistic style aspects in neural language generation', 'Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned', 'The Pile: An 800GB dataset of diverse text for language modeling', 'Scaling laws for reward model overoptimization', 'Koala: A dialogue model for academic research', 'Learning from dialogue after deployment: Feed yourself, chatbot!', 'Large language models can self-improve', 'Learning to achieve goals', 'Ctrl: A conditional transformer language model for controllable generation', 'Adam: A method for stochastic optimization', 'Pretraining language models with human preferences', 'Can neural machine translation be improved with user feedback?', 'In-context reinforcement learning with algorithm distillation', 'Improving a neural semantic parser by counterfactual learning from human bandit feedback', 'Pebble: Feedback-efficient interactive reinforcement learning via relabeling experience and unsupervised pre-training', 'Evaluating human-language model interaction', "Don't say that! making inconsistent dialogue unlikely with unlikelihood training", 'Fcm: Forgetful causal masking makes causal language models better zero-shot learners', 'QUARK: Controllable text generation with reinforced unlearning', 'Interactive learning from policy-dependent human feedback', 'Cross-task generalization via natural language crowdsourcing instructions', 'Webgpt: Browser-assisted question-answering with human feedback', 'Training language models to follow instructions with human feedback', 'Finding generalizable evidence by learning to convince q&a models', 'Improving language understanding by generative pre-training', 'Language models are unsupervised multitask learners', 'Multitask prompted training enables zero-shot task generalization', 'Universal value function approximators', 'Training language models with language feedback', 'Chatgpt: Optimizing language models for dialogue', 'Proximal policy optimization algorithms', 'Dropout: a simple way to prevent neural networks from overfitting', 'Learning to summarize with human feedback', 'Llama: Open and efficient foundation language models', 'Attention is all you need', 'Tl; dr: Mining reddit to learn automatic summarization', 'GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model', 'Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks', 'Deep tamer: Interactive agent shaping in high-dimensional state spaces', 'Finetuned language models are zero-shot learners', 'Chain of thought prompting elicits reasoning in large language models', 'Neural text generation with unlikelihood training', 'Crossfit: A few-shot learning challenge for cross-task generalization in nlp', 'Towards coherent and engaging spoken dialog response generation using automatic conversation evaluators', 'Star: Self-taught reasoner bootstrapping reasoning with reasoning', 'Opt: Open pre-trained transformer language models', 'The wisdom of hindsight makes language models better instruction followers', 'Learning to compare for better training and evaluation of open domain natural language generation models', 'Fine-tuning language models from human preferences'], 'Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data': ['MathQA: Towards interpretable math word problem solving with operation-based formalisms', 'Square attack: a query-efficient black-box adversarial attack via random search', 'PADA: Example-based prompt learning for on-the-fly adaptation to unseen domains', 'Language models are few-shot learners', 'e-snli: Natural language inference with natural language explanations', 'Evaluating large language models trained on code', 'Improving black-box adversarial attacks with a transfer-based prior', 'Palm: Scaling language modeling with pathways', 'Training verifiers to solve math word problems', 'Commonsense knowledge mining from pretrained models', 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding', 'Zen: Pre-training chinese text encoder enhanced by n-gram representations', 'Black-box prompt learning for pre-trained language models', 'Taming pre-trained language models with n-gram representations for low-resource domain adaptation', 'Disarm: An antithetic gradient estimator for binary latent variables', 'Complexity-based prompting for multi-step reasoning', 'Normsage: Multi-lingual multi-cultural norm discovery from conversations on-the-fly', 'Making pre-trained language models better few-shot learners', 'Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies', 'Retrieval-augmented gpt-3.5-based text-to-sql framework with sample-aware prompting and dynamic revision chain', 'WARP: Word-level Adversarial ReProgramming', 'PTR: Prompt Tuning with Rules for Text Classification', 'BERTese: Learning to speak to BERT', 'DEBERTA: Decoding-enhanced bert with disentangled attention', 'Large language models can self-improve', 'Black-box adversarial attack with transferable model-based embedding', 'Black-box adversarial attacks with limited queries and information', 'Prior convictions: Black-box adversarial attacks with bandits and priors', 'How can we know what language models know?', 'Large language models are zero-shot reasoners', 'MAWPS: A math word problem repository', 'Why machine reading comprehension models learn shortcuts?', 'Can language models learn from explanations in context?', 'Mwptoolkit: an open-source framework for deep learning-based math word problem solvers', 'The power of scale for parameter-efficient prompt tuning', 'Prefix-tuning: Optimizing continuous prompts for generation', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'What makes good in-context examples for GPT-3?', 'GPT Understands, Too', 'RoBERTa: A Robustly Optimized BERT Pretraining Approach', 'Decoupled weight decay regularization', 'Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'A diverse corpus for evaluating and developing English math word problem solvers', 'Can a suit of armor conduct electricity? A new dataset for open book question answering', 'Training language models to follow instructions with human feedback', 'The effect of prompting to students with different learning styles', 'Reasoning like program executors', 'Grips: Gradient-free, edit-based instruction search for prompting large language models', 'Learning how to ask: Querying LMs with mixtures of soft prompts', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'The Probabilistic Relevance Framework: BM25 and Beyond', 'AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts', 'Recursive deep models for semantic compositionality over a sentiment treebank', 'Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'Selective annotation makes language models better few-shot learners', 'What makes reading comprehension questions easier?', 'Black-box tuning for language-model-as-a-service', 'CommonsenseQA: A question answering challenge targeting commonsense knowledge', 'Universal adversarial triggers for attacking and analyzing NLP', 'Rationale-augmented ensembles in language models', 'Self-consistency improves chain of thought reasoning in language models', 'Emergent abilities of large language models', 'Simple statistical gradient-following algorithms for connectionist reinforcement learning', 'Human parity on commonsenseqa: Augmenting self-attention with external attention', 'Adept: A debiasing prompt framework', 'BARTScore: Evaluating generated text as text generation', 'Star: Bootstrapping reasoning with reasoning', 'Active example selection for in-context learning', 'Automatic chain of thought prompting in large language models', 'Calibrate before use: Improving few-shot performance of language models', 'Factual probing is [MASK]: Learning vs. learning to recall', 'Efficient neural network training via forward and backward propagation sparsification'], 'Finding Support Examples for In-Context Learning': ['A survey on data-efficient algorithms in big data era', 'On the dangers of stochastic parrots: Can language models be too big?', 'GPT-Neo: Large Scale Autoregressive Language Modeling with MeshTensorflow', 'Language models are few-shot learners', 'Data curation alone can stabilize in-context learning', 'On the relation between sensitivity and accuracy in in-context learning', 'Super-samples from kernel herding', 'Improving contrastive learning of sentence embeddings from AI feedback', 'Selection via proxy: Efficient data selection for deep learning', 'Support-vector networks', "V12. 1: User's manual for cplex", 'Case-based reasoning for natural language queries over knowledge bases', 'BERT: pre-training of deep bidirectional transformers for language understanding', 'A survey for in-context learning', 'The turking test: Can language models understand instructions?', 'Zerogen+: Self-guided high-quality data generation in efficient zero-shot learning', 'Deepcore: A comprehensive library for coreset selection in deep learning', 'In-context learning for few-shot dialogue state tracking', 'Submodular optimization with submodular cover and submodular knapsack constraints', 'Speech and language processing: an introduction to natural language processing, computational linguistics, and speech recognition, 2nd Edition', 'GRAD-MATCH: gradient matching based data subset selection for efficient deep model training', 'GLISTER: generalization based data subset selection for efficient and robust learning', 'Reordering examples helps during priming-based few-shot learning', 'Dbpedia A large-scale, multilingual knowledge base extracted from wikipedia', 'Diverse demonstrations improve in-context compositional generalization', 'What makes good in-context examples for gpt-3?', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'Active learning by acquiring contrastive examples', 'Hidden factors and hidden topics: understanding rating dimensions with review text', 'Tuning language models as training data generators for augmentation-enhanced few-shot learning', 'Noisy channel language model prompting for few-shot text classification', 'Rethinking the role of demonstrations: What makes in-context learning work?', 'Coresets for data-efficient training of machine learning models', 'A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts', 'Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales', 'Deep learning on a data diet: Finding important examples early in training', 'Language models are unsupervised multitask learners', 'Sentence-bert: Sentence embeddings using siamese bert-networks', 'A survey of deep active learning', 'Learning to retrieve prompts for in-context learning', 'Active learning for convolutional neural networks: A core-set approach', 'XRICL: cross-lingual retrieval-augmented in-context learning for cross-lingual text-to-sql semantic parsing', 'Core-set sampling for efficient neural architecture search', 'Recursive deep models for semantic compositionality over a sentiment treebank', 'Selective annotation makes language models better few-shot learners', 'An empirical study of example forgetting during deep neural network learning', 'Attention is all you need', 'Building a question answering test collection', 'Self-adaptive in-context learning', 'Progen: Progressive zero-shot dataset generation via in-context feedback', 'Compositional exemplars for in-context learning', 'OPT: open pre-trained transformer language models', 'Character-level convolutional networks for text classification', 'Active example selection for in-context learning', 'A survey of large language models', 'Calibrate before use: Improving few-shot performance of language models'], 'Post Hoc Explanations of Language Models Can Improve Language Models': ['On the opportunities and risks of foundation models', 'Language models are few-shot learners', 'Sparks of artificial general intelligence: Early experiments with gpt-4', 'Interpretation of black box nlp models: A survey', 'BERT: pre-training of deep bidirectional transformers for language understanding', 'A survey for in-context learning', 'Towards a rigorous science of interpretable machine learning', 'Towards benchmarking the utility of explanations for model debugging', 'How can i choose an explainer? an application-grounded evaluation of post-hoc explanations', 'Survey of hallucination in natural language generation', "The disagreement problem in explainable machine learning: A practitioner's perspective", 'Robust and stable black box explanations', 'Can language models learn from explanations in context?', 'Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing', 'Estimating the carbon footprint of bloom, a 176b parameter language model', 'A unified approach to interpreting model predictions', 'Post-hoc interpretability for neural nlp: A survey', 'Training language models to follow instructions with human feedback', 'Language models are unsupervised multitask learners', 'Why should I trust you? Explaining the predictions of any classifier', 'Learning important features through propagating activation differences', 'Deep inside convolutional networks: Visualising image classification models and saliency maps', 'Reliable post hoc explanations: Modeling uncertainty in explainability', 'Talktomodel: Understanding machine learning models with open ended dialogues', 'Smoothgrad: Removing noise by adding noise', 'Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'Axiomatic attribution for deep networks', 'Challenging big-bench tasks and whether chain-of-thought can solve them', 'CommonsenseQA: A question answering challenge targeting commonsense knowledge', "Language models don't always say what they think: Unfaithful explanations in chain-of-thought prompting", 'Emergent abilities of large language models', 'Chain of thought prompting elicits reasoning in large language models', 'Interpreting language models with contrastive explanations', 'Visualizing and understanding convolutional networks', 'Agieval: A human-centric benchmark for evaluating foundation models'], 'Learning To Retrieve Prompts for In-Context Learning': ['Neuro-symbolic language modeling with automaton-augmented retrieval', 'Task-oriented dialogue as dataflow synthesis', 'Optics: Ordering points to identify the clustering structure', 'On the dangers of stochastic parrots: Can language models be too big?', 'GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow', 'Improving language models by retrieving from trillions of tokens', 'Language models are few-shot learners', 'Reading Wikipedia to answer open-domain questions', 'Evaluating large language models trained on code', 'Case-based reasoning for natural language queries over knowledge bases', 'BERT: Pre-training of deep bidirectional transformers for language understanding', 'GLaM: Efficient scaling of language models with mixture-of-experts', 'The pile: An 800gb dataset of diverse text for language modeling', 'Retrieval augmented language model pre-training', 'Question decomposition with dependency graphs', 'BERTese: Learning to speak to BERT', 'Efficient natural language response suggestion for smart reply', 'Stochastic neighbor embedding', "Surface form competition: Why the highest probability answer isn't always right", 'Billion-scale similarity search with GPUs', 'Dense passage retrieval for open-domain question answering', 'Nearest Neighbor Machine Translation', 'Generalization through memorization: Nearest neighbor language models', 'Colbert: Efficient and effective passage search via contextualized late interaction over bert', 'Adam: A method for stochastic optimization', 'Latent retrieval for weakly supervised open domain question answering', 'The inductive bias of in-context learning: Rethinking pretraining example design', 'Retrieval-augmented generation for knowledge-intensive NLP tasks', 'MTOP: A comprehensive multilingual task-oriented semantic parsing benchmark', 'Prefix-tuning: Optimizing continuous prompts for generation', 'Jurassic-1: Technical details and evaluation', 'What makes good in-context examples for gpt-3?', 'Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing', 'Noisy channel language model prompting for few-shot text classification', 'Rethinking the role of demonstrations: What makes in-context learning work?', 'Controllable semantic parsing via retrieval augmentation', 'Language models as knowledge bases?', 'Learning how to ask: Querying LMs with mixtures of soft prompts', 'RocketQA: An optimized training approach to dense passage retrieval for open-domain question answering', 'Scaling language models: Methods, analysis & insights from training gopher', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'Sentence-BERT: Sentence embeddings using Siamese BERT-networks', 'The probabilistic relevance framework: BM25 and beyond', 'Improving evidence retrieval for automated explainable fact-checking', 'A mathematical exploration of why language models help solve downstream tasks', 'Exploiting cloze-questions for few-shot text classification and natural language inference', 'Improving the cluster structure extracted from OPTICS plots', 'Constrained language models yield few-shot semantic parsers', 'AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts', 'GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model', 'Training data is more valuable than you think: A simple and effective method by retrieving from training data', 'Least-to-most prompting enables complex reasoning in large language models', 'Large language models are human-level prompt engineers', 'An explanation of in-context learning as implicit Bayesian inference', 'Human parity on CommonsenseQA: Augmenting self-attention with external attention', 'Calibrate before use: Improving few-shot performance of language models', 'Factual probing is [MASK]: Learning vs. learning to recall'], 'Batch Prompting: Efficient Inference with Large Language Model APIs': ['In-context examples selection for machine translation', 'Ask me anything: A simple strategy for prompting language models', 'PromptSource: An integrated development environment and repository for natural language prompts', 'The fifth pascal recognizing textual entailment challenge', 'Language models are few-shot learners', 'Evaluating large language models trained on code', 'Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks', 'Binding language models in symbolic languages', 'PaLM: Scaling language modeling with pathways', 'Training verifiers to solve math word problems', 'PAL: Program-aided language models', 'Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies', 'Learning to solve arithmetic word problems with verb categorization', 'How can we know what language models know?', 'Non-autoregressive machine translation with disentangled context transformer', 'Deep encoder, shallow decoder: Reevaluating non-autoregressive machine translation', 'Finetuning pretrained transformers into RNNs', 'Transformers are RNNs: Fast autoregressive transformers with linear attention', 'Decomposed prompting: A modular approach for solving complex tasks', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'What makes good in-context examples for GPT-3?', 'Training language models to follow instructions with human feedback', 'Compositional semantic parsing on semi-structured tables', 'Are NLP models really able to solve simple math word problems?', 'ABC: Attention with bounded-memory control', 'Random feature attention', 'Solving general arithmetic word problems', 'Learning to retrieve prompts for in-context learning', 'Recursive deep models for semantic compositionality over a sentiment treebank', 'Selective annotation makes language models better few-shot learners', 'CommonsenseQA: A question answering challenge targeting commonsense knowledge', 'Model cascading: Towards jointly improving efficiency and accuracy of NLP systems', 'Attention is all you need', 'Self-consistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'A broad-coverage challenge corpus for sentence understanding through inference', 'React: Synergizing reasoning and acting in language models', 'Least-to-most prompting enables complex reasoning in large language models'], 'Hierarchical Prompting Assists Large Language Model on Web Navigation': ['Do as i can, not as i say: Grounding language in robotic affordances', 'Evaluating large language models trained on code', 'Palm: Scaling language modeling with pathways', 'Inner monologue: Embodied reasoning through planning with language models', 'Code as policies: Language model programs for embodied control', 'Evaluating verifiability in generative search engines', 'Multi-stage prompting for knowledgeable dialogue generation', 'Chatgpt: Optimizing language models for dialogue', 'World of bits: An open-domain platform for web-based agents', 'Alfred: A benchmark for interpreting grounded instructions for everyday tasks', 'Progprompt: Generating situated robot task plans using large language models', 'Msp: Multi-stage prompting for making pre-trained language models better translators', 'Chain of thought prompting elicits reasoning in large language models', 'Foundation models for decision making: Problems, methods, and opportunities', 'Webshop: Towards scalable real-world web interaction with grounded language agents', 'React: Synergizing reasoning and acting in language models', 'Webarena: A realistic web environment for building autonomous agents', 'Hierarchical control of situated agents through natural language'], 'Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering': ['The description length of deep learning models', 'A large annotated corpus for learning natural language inference', 'Language models are few-shot learners', 'Training verifiers to solve math word problems', 'Rlprompt: Optimizing discrete text prompts with reinforcement learning', 'Making pre-trained language models better few-shot learners', 'Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies', 'The minimum description length principle', 'Toward semantics-based answer pinpointing', 'How can we know what language models know?', 'TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension', 'Ground-truth labels matter: A deeper look into input-label demonstrations', 'Autoencoding variational bayes', 'k-dpps: Fixedsize determinantal point processes', 'Reordering examples helps during priming-based few-shot learning', 'What makes good in-context examples for gpt-3?', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'Rethinking the role of demonstrations: What makes in-context learning work?', 'Grips: Gradient-free, edit-based instruction search for prompting large language models', 'Language models are unsupervised multitask learners', 'Scaling language models: Methods, analysis & insights from training gopher', 'Learning to retrieve prompts for in-context learning', 'Autoprompt: Eliciting knowledge from language models with automatically generated prompts', 'Recursive deep models for semantic compositionality over a sentiment treebank', 'A formal theory of inductive inference. part i', 'An information-theoretic approach to prompt engineering without ground truth labels', 'Selective annotation makes language models better few-shot learners', 'CommonsenseQA: A question answering challenge targeting commonsense knowledge', 'Transformer memory as a differentiable search index', 'Deep learning and the information bottleneck principle', 'Glue: A multi-task benchmark and analysis platform for natural language understanding', 'Emergent abilities of large language models', 'A broad-coverage challenge corpus for sentence understanding through inference', 'An explanation of in-context learning as implicit bayesian inference', 'Zeroprompt: Scaling prompt-based pretraining to 1,000 tasks improves zero-shot generalization', 'Zerogen: Efficient zero-shot learning via dataset generation', 'Character-level convolutional networks for text classification', 'Calibrate before use: Improving few-shot performance of language models'], 'Decomposed Prompting : A MODULAR APPROACH FOR SOLVING COMPLEX TASKS': ['Neural module networks', 'Language models are few-shot learners', 'PaLM: Scaling language modeling with pathways', 'Training verifiers to solve math word problems', 'Selection-inference: Exploiting large language models for interpretable logical reasoning', 'Language model cascades', 'Successive prompting for decomposing complex questions', 'PAL: Program-aided language models', 'Neural module networks for reasoning over text', 'Constructing a multi-hop QA dataset for comprehensive evaluation of reasoning steps', 'Self-assembling modular networks for interpretable multi-hop reasoning', 'Maieutic prompting: Logically consistent reasoning with recursive explanations', 'Text modular networks: Learning to decompose tasks in the language of existing models', 'Hey AI, can you solve complex tasks by talking to agents?', 'Internet-augmented language models through few-shot prompting for open-domain question answering', 'Standing on the shoulders of giant frozen language models', 'Multi-hop reading comprehension through question decomposition and rescoring', 'Show your work: Scratchpads for intermediate computation with language models', 'Training language models to follow instructions with human feedback', 'TALM: Tool augmented language models', 'Unsupervised question decomposition for question answering', 'True few-shot learning with language models', 'Measuring and narrowing the compositionality gap in language models', 'SQuAD: 100, 000+ questions for machine comprehension of text', 'Solving general arithmetic word problems', 'Toolformer: Language models can teach themselves to use tools', 'The web as a knowledge-base for answering complex questions', 'MuSiQue: Multihop questions via single-hop question composition', 'Self-consistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'Break it down: A question understanding benchmark', 'HotpotQA: A dataset for diverse, explainable multi-hop question answering', 'Least-to-most prompting enables complex reasoning in large language models'], 'Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework': ['Language models are few-shot learners', 'Reading Wikipedia to answer open-domain questions', 'Palm: Scaling language modeling with pathways', 'Selection-inference: Exploiting large language models for interpretable logical reasoning', 'Roscoe: A suite of metrics for scoring step-by-step reasoning', 'Realm: Retrieval-augmented language model pre-training', 'Constructing a multihop QA dataset for comprehensive evaluation of reasoning steps', 'Dense passage retrieval for open-domain question answering', 'Internet-augmented language models through few-shot prompting for open-domain question answering', 'Is chatgpt really a “code red” for google search?', 'Interrater reliability: the kappa statistic', 'Chatgpt: Optimizing language models for dialogue', 'Training language models to follow instructions with human feedback', 'Measuring and narrowing the compositionality gap in language models', 'Sentence-BERT: Sentence embeddings using Siamese BERT-networks', 'Toolformer: Language models can teach themselves to use tools', 'FEVER: a large-scale dataset for fact extraction and VERification', 'Self-consistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'Reframing human-AI collaboration for generating free-text explanations', 'HotpotQA: A dataset for diverse, explainable multi-hop question answering', 'ReAct: Synergizing reasoning and acting in language models', 'The unreliability of explanations in few-shot prompting for textual reasoning', 'Can chatgpt-like generative models guarantee factual accuracy? on the mistakes of new generation search engines', 'Least-to-most prompting enables complex reasoning in large language models'], 'Automatic Prompt Optimization with “Gradient Descent” and Beam Search': ['Best arm identification in multi-armed bandits', 'Nltk: the natural language toolkit', 'Regret analysis of stochastic and nonstochastic multiarmed bandit problems', 'Sparks of artificial general intelligence: Early experiments with gpt-4', 'Teaching large language models to self-debug', 'Rlprompt: Optimizing discrete text prompts with reinforcement learning', 'From arabic sentiment analysis to sarcasm detection: The arsarcasm dataset', 'Making pre-trained language models better few-shot learners', 'Learning to program with natural language', 'Warp: Word-level adversarial reprogramming', 'Optimizing prompts for text-to-image generation', 'Instruction induction: From few examples to natural language task descriptions', 'Promptmaker: Prompt-based prototyping with large language models', 'Almost optimal exploration in multi-armed bandits', 'Algorithms for multi-armed bandit problems', 'The power of scale for parameter-efficient prompt tuning', 'Competition-level code generation with alphacode', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'Ethos: an online hate speech detection dataset', 'Gpt-4 technical report', 'Grips: Gradient-free, edit-based instruction search for prompting large language models', 'Learning how to ask: Querying lms with mixtures of soft prompts', 'Prompt programming for large language models: Beyond the few-shot paradigm', 'Autoprompt: Eliciting knowledge from language models with automatically generated prompts', '"liar, liar pants on fire": A new benchmark dataset for fake news detection', 'Self-instruct: Aligning language model with self generated instructions', 'Gps: Genetic prompt search for efficient few-shot learning', "Why johnny can't prompt: how non-ai experts try (and fail) to design llm prompts", 'Socratic models: Composing zero-shot multimodal reasoning with language', 'Tempera: Test-time prompt editing via reinforcement learning', 'Large language models are human-level prompt engineers'], 'Faithful Chain-of-Thought Reasoning': ['Do As I Can, Not As I Say: Grounding Language in Robotic Affordances', 'FROM SYSTEM 1 DEEP LEARNING TO SYSTEM 2 DEEP LEARNING', 'Beyond the Imitation Game: Measuring and extrapolating the capabilities of language models', 'Language Models are Few-Shot Learners', 'Evaluating Large Language Models Trained on Code', 'Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks', 'Training Verifiers to Solve Math Word Problems', 'PAL: Program-aided Language Models', 'Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies', 'Explaining Explanations: An Overview of Interpretability of Machine Learning', "Harvey Friedman's Research on the Foundations of Mathematics", 'The Promise and Peril of Human Evaluation for Model Interpretability', 'Towards faithfully interpretable NLP systems: How should we define and evaluate faithfulness?', 'Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations', 'Large Language Models are Zero-Shot Reasoners', 'Solving Quantitative Reasoning Problems with Language Models', 'On the Advance of Making Language Models Better Reasoners', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'A diverse corpus for evaluating and developing English math word problem solvers', 'Show Your Work: Scratchpads for Intermediate Computation with Language Models', 'Gpt-4 technical report', 'Are NLP models really able to solve simple math word problems?', 'Boosted prompt ensembles for large language models', 'Learning to deceive with attention-based explanations', 'Limitations of Language Models in Arithmetic and Symbolic Induction', 'Explaining the predictions of any classifier', 'Solving general arithmetic word problems', 'Inseq: An interpretability toolkit for sequence generation models', 'CLUTRR: A diagnostic benchmark for inductive reasoning from text', 'Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods', "Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting", 'Self-Consistency Improves Chain of Thought Reasoning in Language Models', 'Chain of Thought Prompting Elicits Reasoning in Large Language Models', 'Interpreting language models with contrastive explanations', 'Improved logical reasoning of language models via differentiable symbolic programming', 'Leastto-Most Prompting Enables Complex Reasoning in Large Language Models'], 'Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm': ['Findings of the 2014 Workshop on Statistical Machine Translation', 'GPT-3 Creative Fiction', 'Language models are few-shot learners', 'TextWorld: A Learning Environment for Text-based Games', 'Bert: Pre-training of deep bidirectional transformers for language understanding', 'Hierarchical Neural Story Generation', 'Multi-step Reasoning via Recurrent Dual Attention for Visual Dialog', 'Building AGI Using Language Models', 'Making Pre-trained Language Models Better Few-shot Learners', 'Measuring massive multitask language understanding', 'The Curious Case of Neural Text Degeneration', 'Universal language model fine-tuning for text classification', 'Seems to work', "Teaching GPT-3 to do a brute force 'for loop' checking answers", 'CTRL: A Conditional Transformer Language Model for Controllable Generation', 'GeDi: Generative Discriminator Guided Sequence Generation', 'Prefix-Tuning: Optimizing Continuous Prompts for Generation', 'Multi-Step Inference for Reasoning Over Paragraphs', 'A Call for Clarity in Reporting BLEU Scores', 'You Can Probably Amplify GPT3 Directly', 'GPT-3: Using Fiction to Demonstrate How Prompts Impact Output Quality', 'AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts', 'World Creation by Analogy', 'Controllable Neural Text Generation', 'Zero-shot Learning by Generating Task-specific Adapters', 'Low-resource generation of multi-hop reasoning questions', 'Rationalization'], 'LEAST-TO-MOST PROMPTING ENABLES COMPLEX REASONING IN LARGE LANGUAGE MODELS': ['Learning to recombine and resample data for compositional generalization', 'Good-enough compositional data augmentation', 'Language models are few-shot learners', 'Compositional generalization via neural-symbolic stack machines', 'PaLM: Scaling language modeling with pathways', 'Training verifiers to solve math word problems', 'Neural logic machines', 'DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs', 'Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies', 'Permutation equivariant models for compositional generalization in language', 'Span-based semantic parsing for compositional generalization', 'Measuring compositional generalization: A comprehensive method on realistic data', 'Sequence-to-sequence learning with latent neural grammars', 'Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks', 'Compositional generalization through meta sequence-to-sequence learning', 'Compositional generalization for primitive substitutions', 'A comparison of most-to-least and least-to-most prompting on the acquisition of solitary play skills', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'Compositional generalization by learning analytical expressions', 'Learning compositional rules via neural program synthesis', 'Unsupervised question decomposition for question answering', 'Compositional generalization in a deep seq2seq model by separating syntax and semantics', 'Can you learn an algorithm? Generalizing from easy to hard problems with recurrent networks', 'Compositional generalization and natural language variation: Can a semantic parsing approach handle both?', 'Shepherd pre-trained language models to develop a train of thought: An iterative prompting approach', 'Self-consistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'AI chains: Transparent and controllable human-AI interaction by chaining large language model prompts', 'Seqzero: Few-shot compositional semantic parsing with sequential prompts and zero-shot models'], 'AUTOPROMPT: Eliciting Knowledge from Language Models with Automatically Generated Prompts': ['Inducing relational knowledge from BERT', 'A large annotated corpus for learning natural language inference', 'Language models are few-shot learners', 'What you can cram into a single vector: Probing sentence embeddings for linguistic properties', 'The PASCAL recognising textual entailment challenge', 'BERT: pre-training of deep bidirectional transformers for language understanding', 'Fine-tuning pretrained language models: Weight initializations, data orders, and early stopping', 'T-REx: A large scale alignment of natural language with knowledge base triples', 'Designing and interpreting probes with control tasks', 'First quora dataset release: Question pairs', 'Attention is not explanation', 'How can we know what language models know?', 'Why do masked neural language models still need common sense knowledge?', 'Unsupervised question answering by cloze translation', 'Linguistic knowledge and transferability of contextual representations', 'A SICK cure for the evaluation of compositional distributional semantic models', 'Deep contextualized word representations', 'Language models as knowledge bases?', 'Language models are unsupervised multitask learners', 'Exploiting cloze questions for few-shot text classification and natural language inference', 'Unsupervised commonsense question answering with selftalk', 'Recursive deep models for semantic compositionality over a sentiment treebank', 'Context-aware representations for knowledge base relation extraction', 'A simple method for commonsense reasoning', 'Information-theoretic probing with minimum description length', 'Universal adversarial triggers for attacking and analyzing NLP', 'GLUE: A multi-task benchmark and analysis platform for natural language understanding', 'Attention is not not explanation', "HuggingFace's Transformers: State-of-the-art natural language processing"], 'How Can We Know What Language Models Know?': ['Snowball: Extracting relations from large plaintext collections', 'A neural knowledge language model', 'Matching the blanks: Distributional similarity for relation learning', 'Open information extraction from the web', 'What do neural machine translation models learn about morphology?', 'Analysis methods in neural language processing: A survey', 'Large scale acquisition of paraphrases for learning surface patterns', 'Inducing relational knowledge from BERT', 'A survey of automatic query expansion in information retrieval', 'Semi-supervised sequence learning', 'BERT: Pretraining of deep bidirectional transformers for language understanding', 'HotFlip: White-box adversarial examples for text classification', 'T-REx: A large scale alignment of natural language with knowledge base triples', 'Identifying relations for open information extraction', 'Sentence-level MT evaluation without reference translations: Beyond language modeling', 'Mask-predict: Parallel decoding of conditional masked language models', "Assessing BERT's syntactic abilities", 'Latent relation language models', 'A structural probe for finding syntax in word representations', 'Towards decoding as continuous optimisation in neural machine translation', "Barack's wife Hillary: Using knowledge graphs for fact-aware language modeling", 'What does BERT learn about the structure of language?', 'Adam: A method for stochastic optimization', 'A diversity-promoting objective function for neural conversation models', 'Understanding neural networks through representation erasure', 'Assessing the ability of LSTMs to learn syntax-sensitive dependencies', 'Paraphrasing revisited with neural machine translation', 'The natural language decathlon: Multitask learning as question answering', 'context2vec: Learning generic context embedding with bidirectional LSTM', 'On the state of the art of evaluation in neural language models', 'Regularizing and optimizing LSTM language models', 'Context dependent recurrent neural network language model', "Facebook FAIR's WMT19 news translation task submission", 'Deep contextualized word representations', 'Knowledge enhanced contextual word representations', 'Language models as knowledge bases?', 'BERT is not a knowledge base (yet): Factual knowledge vs. Name-based reasoning in unsupervised QA', 'Language models are unsupervised multitask learners', 'Explain yourself! Leveraging language models for commonsense reasoning', 'Learning surface text patterns for a question answering system', 'Investigating a generic paraphrase-based approach for relation extraction', 'Atomic: An atlas of machine commonsense for if-then reasoning', 'Improving neural machine translation models with monolingual data', 'Does string-based neural MT learn source syntax?', 'What do recurrent neural network grammars learn about syntax?', 'BERT rediscovers the classical NLP pipeline', 'What do you learn from context? Probing for sentence structure in contextualized word representations', 'Representing text for joint embedding of text and knowledge bases', 'A simple method for commonsense reasoning', 'Universal adversarial triggers for attacking and analyzing NLP', 'Reference-aware language models', 'ERNIE: Enhanced language representation with informative entities', 'The Microsoft Research sentence completion challenge'], 'SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS': ['A learning algorithm for boltzmann machines', 'Towards a human-like open-domain chatbot', 'MathQA: Towards interpretable math word problem solving with operation-based formalisms', 'Giving BERT a calculator: Finding operations and arguments with reading comprehension', 'Learning to retrieve reasoning paths over wikipedia graph for question answering', 'The second pascal recognising textual entailment challenge', 'Diverse m-best solutions in markov random fields', 'The fifth pascal recognizing textual entailment challenge', 'Beyond the imitation game: Measuring and extrapolating the capabilities of language models', 'Language models are few-shot learners', 'esnli: Natural language inference with natural language explanations', 'Make up your mind! adversarial generation of inconsistent natural language explanations', 'Multi-hop question answering via reasoning chains', 'Evaluating large language models trained on code', 'Palm: Scaling language modeling with pathways', 'Boolq: Exploring the surprising difficulty of natural yes/no questions', 'Think you have solved question answering? try arc, the ai2 reasoning challenge', 'Training verifiers to solve math word problems', 'The pascal recognising textual entailment challenge', 'Is MAP decoding all you need? The inadequacy of the mode in neural machine translation', 'Measuring and improving consistency in pretrained language models', 'Intuition and reasoning: A dual-process perspective', 'Hierarchical neural story generation', 'Controlling linguistic style aspects in neural language generation', 'Making pre-trained language models better few-shot learners', 'Injecting numerical reasoning skills into language models', 'Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies', 'The third pascal recognizing textual entailment challenge', 'Learning to write with cooperative discriminators', 'The curious case of neural text degeneration', 'Learning to solve arithmetic word problems with verb categorization', 'UNIFIEDQA: Crossing format boundaries with a single QA system', 'Large language models are zero-shot reasoners', 'MAWPS: A math word problem repository', 'MWPToolkit: An open-source framework for deep learning-based math word problem solvers', 'Mutual information and diverse decoding improve neural machine translation', 'A simple, fast diverse decoding algorithm for neural generation', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'Typical decoding for natural language generation', 'A diverse corpus for evaluating and developing English math word problem solvers', 'Adversarial NLI: A new benchmark for natural language understanding', 'Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning', 'Are NLP models really able to solve simple math word problems?', 'Reasoning like program executors', "Measuring and improving BERT's mathematical abilities by predicting the order of reasoning", 'Language models are unsupervised multitask learners', 'Scaling language models: Methods, analysis & insights from training gopher', 'NumNet: Machine reading comprehension with numerical reasoning', 'Solving general arithmetic word problems', 'Generate & rank: A multi-task framework for math word problems', 'Natural language to code translation with execution', 'Individual differences in reasoning: Implications for the rationality debate?', 'CommonsenseQA: A question answering challenge targeting commonsense knowledge', 'Unifying language learning paradigms', 'Lamda: Language models for dialog applications', 'Diverse beam search for improved description of complex scenes', 'Chain of thought prompting elicits reasoning in large language models', 'Consistency of a recurrent language model with respect to incomplete decoding', 'Exploiting reasoning chains for multi-hop science question answering', 'Human parity on commonsenseqa: Augmenting self-attention with external attention', 'HotpotQA: A dataset for diverse, explainable multi-hop question answering', 'The unreliability of explanations in few-shot prompting for textual reasoning', 'Diversifying content generation for commonsense reasoning with mixture of knowledge graph experts', 'Calibrate before use: Improving few-shot performance of language models'], 'CONNECTING LARGE LANGUAGE MODELS WITH EVOLUTIONARY ALGORITHMS YIELDS POWERFUL PROMPT OPTIMIZERS': ['Asset: A dataset for tuning and evaluation of sentence simplification models with multiple rewriting transformations', 'Promptsource: An integrated development environment and repository for natural language prompts', 'Self-adapting control parameters in differential evolution: A comparative study on numerical benchmark problems', 'Language models are few-shot learners', 'Evoprompting: Language models for code-level neural architecture search', 'Introduction to derivative-free optimization', 'Differential evolution: A survey of the state-of-the-art', 'Recent advances in differential evolution-an updated survey', 'RLPrompt: Optimizing discrete text prompts with reinforcement learning', 'Ant colony system: a cooperative learning approach to the traveling salesman problem', "Chain-of-thought hub: A continuous effort to measure large language models' reasoning performance", 'Samsum corpus: A human-annotated dialogue dataset for abstractive summarization', 'Learning to program with natural language', 'Adaptation in Natural and Artificial Systems', 'Adaptation in natural and artificial systems: an introductory analysis with applications to biology, control, and artificial intelligence', 'Mining and summarizing customer reviews', 'Opt-iml: Scaling language model instruction meta learning through the lens of generalization', 'How can we know what language models know?', 'Particle swarm optimization', 'Large language models are zero-shot reasoners', 'Chatgpt and other large language models as evolutionary engines for online interactive collaborative game design', 'Evolution through large models', 'The power of scale for parameter-efficient prompt tuning', 'Deliberate then generate: Enhanced prompting framework for text generation', 'Prefix-tuning: Optimizing continuous prompts for generation', 'Roulette-wheel selection via stochastic acceptance', 'Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing', 'P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks', 'Gpt understands, too', 'Language model crossover: Variation through few-shot prompting', 'Genetic algorithm: Theory, literature review, and application in image reconstruction', "Reframing instructional prompts to gptk's language", 'Cross-task generalization via natural language crowdsourcing instructions', 'An introduction to genetic algorithms', 'Illuminating search spaces by mapping elites', 'Gpt-4 technical report', 'Training language models to follow instructions with human feedback', 'Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales', 'A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts', 'Differential evolution: A review of more than two decades of research', 'Grips: Gradient-free, edit-based instruction search for prompting large language models', 'Differential evolution', "Automatic prompt optimization with 'gradient descent' and beam search", 'Is chatgpt a general-purpose natural language processing task solver?', 'Derivative-free optimization: a review of algorithms and comparison of software implementations', 'Multitask prompted training enables zero-shot task generalization', 'Exploiting cloze-questions for few-shot text classification and natural language inference', 'A thorough examination of decoding methods in the era of llms', "Toward human readable prompt tuning: Kubrick's the shining is a good movie, and a good prompt too?", 'Autoprompt: Eliciting knowledge from language models with automatically generated prompts', 'Recursive deep models for semantic compositionality over a sentiment treebank', 'Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces', 'Challenging big-bench tasks and whether chain-of-thought can solve them', 'Stanford alpaca: An instruction-following llama model', 'Llama: Open and efficient foundation language models', 'A comparative study of differential evolution, particle swarm optimization, and evolutionary algorithms on numerical benchmark problems', 'Building a question answering test collection', 'Universal adversarial triggers for attacking and analyzing nlp', 'Hint-enhanced in-context learning wakes large language models up for knowledge-intensive tasks', 'Tournament selection — Wikipedia, the free encyclopedia', 'Optimizing statistical machine translation for text simplification', "Why johnny can't prompt: how non-ai experts try (and fail) to design llm prompts", 'Jade: Adaptive differential evolution with optional external archive', 'Differentiable prompt makes pre-trained language models better few-shot learners', 'Opt: Open pre-trained transformer language models', 'Tempera: Test-time prompt editing via reinforcement learning', 'Sentiment analysis in the era of large language models: A reality check', 'Character-level convolutional networks for text classification', 'Multi-task instruction tuning of llama for specific scenarios: A preliminary study on writing assistance', 'Can gpt-4 perform neural architecture search?', 'Large language models are human-level prompt engineers', 'Promptbench: Towards evaluating the robustness of large language models on adversarial prompts'], 'Unified Demonstration Retriever for In-Context Learning': ['In-context examples selection for machine translation', 'Beyond opinion mining: Summarizing opinions of customer reviews', 'Task-oriented dialogue as dataflow synthesis', 'Benchmarking applied semantic inference: The PASCAL recognising textual entailment challenges', 'On the dangers of stochastic parrots: Can language models be too big?', 'GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-TensorFlow', 'A large annotated corpus for learning natural language inference', 'Language models are few-shot learners', 'From RankNet to LambdaRank to LambdaMART: An overview', 'Evaluating large language models trained on code', 'On the relation between sensitivity and accuracy in in-context learning', 'Improving contrastive learning of sentence embeddings from AI feedback', 'A discourse-aware attention model for abstractive summarization of long documents', 'Cross-lingual language model pretraining', 'Case-based reasoning for natural language queries over knowledge bases', 'BERT: Pre-training of deep bidirectional transformers for language understanding', 'A survey for in-context learning', 'Semantic Noise Matters for Neural Natural Language Generation', 'Deberta: Decoding-enhanced BERT with disentangled attention', 'Teaching machines to read and comprehend', 'In-context learning for few-shot dialogue state tracking', 'Cosmos QA: Machine reading comprehension with contextual commonsense reasoning', 'Neural CRF model for sentence alignment in text simplification', 'Billion-scale similarity search with GPUs', 'Dense passage retrieval for open-domain question answering', 'Abstractive summarization of Reddit posts with multi-level memory networks', 'Dbpedia: A large-scale, multilingual knowledge base extracted from Wikipedia', 'MTOP: A comprehensive multilingual task-oriented semantic parsing benchmark', 'Finding supporting examples for in-context learning', 'Mot: Pre-thinking and recalling enable chatgpt to self-improve with memory-of-thoughts', 'CommonGen: A constrained text generation challenge for generative commonsense reasoning', 'What makes good in-context examples for gpt-3?', 'Roberta: A robustly optimized BERT pretraining approach', 'Decoupled weight decay regularization', 'Codexglue: A machine learning benchmark dataset for code understanding and generation', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'Hidden factors and hidden topics: understanding rating dimensions with review text', 'Noisy channel language model prompting for few-shot text classification', 'A corpus and cloze evaluation for deeper understanding of commonsense stories', 'TSATC: Twitter Sentiment Analysis Training Corpus', 'DART: Open-domain structured data record to text generation', 'Training language models to follow instructions with human feedback', 'A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts', 'Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales', 'Synchromesh: Reliable code generation from pre-trained language models', 'Language models are unsupervised multitask learners', 'SentenceBERT: Sentence embeddings using Siamese BERT-networks', 'The probabilistic relevance framework: BM25 and beyond', 'Choice of plausible alternatives: An evaluation of commonsense causal reasoning', 'Learning to retrieve prompts for in-context learning', 'XRICL: cross-lingual retrieval-augmented in-context learning for cross-lingual text-to-SQL semantic parsing', 'Recursive deep models for semantic compositionality over a sentiment treebank', 'One embedder, any task: Instruction-finetuned text embeddings', 'Attention is all you need', 'Building a question answering test collection', 'GLUE: A multi-task benchmark and analysis platform for natural language understanding', 'GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model', 'Does it make sense? And why? A pilot study for sense making and explanation', 'A broad-coverage challenge corpus for sentence understanding through inference', 'Break it down: A question understanding benchmark', 'Approximate nearest neighbor negative contrastive learning for dense text retrieval', 'knn prompting: Beyond-context learning with calibration-free nearest neighbor inference', 'Character-level convolutional networks for text classification', 'Active example selection for in-context learning'], 'Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations': ['Towards a human-like open-domain chatbot', 'Maximum satisfiability problem', 'Abductive commonsense reasoning', 'Flexible generation of natural language deductions', 'Learning to rationalize for nonmonotonic reasoning with distant supervision', 'Language models are few-shot learners', 'e-snli: Natural language inference with natural language explanations', 'Can rationalization improve robustness?', 'Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension', 'Training verifiers to solve math word problems', 'Towards teachable reasoning systems', 'Techniques for interpretable machine learning', 'Measuring and improving consistency in pretrained language models', 'Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies', 'Explaining self-explaining: A contrast between content and generation', 'The curious case of neural text degeneration', "Surface form competition: Why the highest probability answer isn't always right", 'Contrastive explanations for model interpretability', 'Negated and misprimed probes for pretrained language models: Birds can talk, but cannot fly', 'Beliefbank: Adding memory to a pre-trained language model for a systematic notion of belief', 'Unifiedqa: Crossing format boundaries with a single qa system', 'Self-attention between datapoints: Going beyond individual input-output pairs in deep learning', "Computing krippendorff's alpha-reliability", 'Can language models learn from explanations in context?', 'Generated knowledge prompting for commonsense reasoning', 'Roberta: A robustly optimized bert pretraining approach', 'Unicorn on rainbow: A universal commonsense reasoning model on a new multitask benchmark', 'Neurologic decoding: (un)supervised neural text generation with predicate logic constraints', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'Adversarially regularising neural nli models to integrate logical background knowledge', 'Core-guided maxsat with soft cardinality constraints', 'Wt5?! training text-to-text models to explain their predictions', 'Show your work: Scratchpads for intermediate computation with language models', 'Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning', 'Creak: A dataset for commonsense reasoning over entity knowledge', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'Explain yourself! leveraging language models for commonsense reasoning', 'Unsupervised commonsense question answering with self-talk', 'COM2SENSE: A commonsense reasoning benchmark with complementary sentences', 'CommonsenseQA 2.0: Exposing the limits of AI through gamification', 'Socrates, ironist and moral philosopher', 'What if we simply swap the two text fragments? a straightforward yet effective way to test the robustness of methods to confounding signals in nature language inference tasks', 'Self-consistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'Consistency of a recurrent language model with respect to incomplete decoding', 'Teach me to explain: A review of datasets for explainable nlp', 'A broad-coverage challenge corpus for sentence understanding through inference', 'The unreliability of explanations in few-shot in-context learning', 'Calibrate before use: Improving few-shot performance of language models'], 'Enhancing Large Language Models Against Inductive Instructions with Dual-critique Prompting': ['Constitutional ai: Harmlessness from ai feedback', 'Language models are few-shot learners', 'Exploring the use of large language models for reference-free text quality evaluation: A preliminary empirical study', 'Chatgpt goes to law school', 'GlM: General language model pretraining with autoregressive blank infilling', 'Gptscore: Evaluate as you desire', 'The capacity for moral self-correction in large language models', 'The curious case of neural text degeneration', 'Lora: Low-rank adaptation of large language models', 'CHEF: A pilot Chinese dataset for evidence-based fact-checking', 'Will chatgpt get you caught? rethinking of plagiarism detection', '(qa)2: Question answering with questionable assumptions', 'Which linguist invented the lightbulb? presupposition verification for question-answering', 'Holistic evaluation of language models', 'TruthfulQA: Measuring how models mimic human falsehoods', 'Prompt injection attack against LLM-integrated applications', 'Jailbreaking ChatGPT via prompt engineering: An empirical study', 'When not to trust language models: Investigating effectiveness and limitations of parametric and nonparametric memories', 'SelfCheck: Using LLMs to zero-shot check their own step-by-step reasoning', 'Training language models to follow instructions with human feedback', 'Red teaming language models with language models', "Know what you don't know: Unanswerable questions for squad", 'Safety assessment of chinese large language models', 'Improving factual consistency for knowledge-grounded dialogue systems via knowledge enhancement and alignment', 'Crepe: Open-domain question answering with false presuppositions', 'GLM130b: An open bilingual pre-trained model', 'Judging LLM-as-a-judge with MT-bench and chatbot arena', 'A comprehensive survey on pretrained foundation models: A history from bert to chatgpt'], 'Complementary Explanations for Effective In-Context Learning': ['Explanations for CommonsenseQA: New Dataset and Models', 'PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts', 'Language models are few-shot learners', 'e-snli: Natural language inference with natural language explanations', 'The Use of MMR, Diversity-Based Reranking for Reordering Documents and Producing Summaries', 'Evaluating large language models trained on code', 'Meta-learning via language model in-context tuning', 'Palm: Scaling language modeling with pathways', 'Training verifiers to solve math word problems', 'BERT: Pre-training of deep bidirectional transformers for language understanding', 'Prototypical calibration for few-shot learning of language models', "Surface form competition: Why the highest probability answer isn't always right", 'Maieutic prompting: Logically consistent reasoning with recursive explanations', 'Large language models are zero-shot reasoners', 'What makes good in-context examples for gpt-3?', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'Language models of code are few-shot commonsense learners', 'Noisy channel language model prompting for few-shot text classification', 'MetaICL: Learning to learn in context', 'Rethinking the role of demonstrations: What makes in-context learning work?', 'Show your work: Scratchpads for intermediate computation with language models', 'Training language models to follow instructions with human feedback', 'Measuring and narrowing the compositionality gap in language models', 'Evaluating the impact of model scale for compositional generalization in semantic parsing', 'Learning to retrieve prompts for in-context learning', 'Constrained language models yield few-shot semantic parsers', 'Selective annotation makes language models better few-shot learners', 'Rationale-augmented ensembles in language models', 'Self-consistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'An explanation of in-context learning as implicit Bayesian inference', 'The unreliability of explanations in few-shot prompting for textual reasoning', 'OPT: Open Pre-trained Transformer Language Models', 'BERTScore: Evaluating Text Generation with BERT', 'Calibrate before use: Improving few-shot performance of language models', 'Least-to-most prompting enables complex reasoning in large language models', 'Teaching algorithmic reasoning via in-context learning'], 'Reflexion: Language Agents with Verbal Reinforcement Learning': ['Do as i can, not as i say: Grounding language in robotic affordances', 'Program synthesis with large language models', 'In-context policy iteration', 'Multipl-e: A scalable and extensible approach to benchmarking neural code generation', 'Codet: Code generation with generated tests', 'Evaluating large language models trained on code', 'Teaching large language models to self-debug', 'Textworld: A learning environment for text-based games', 'Meta-prompt: A simple self-improving language agent', 'Language models can solve computer tasks', 'A large-scale longitudinal study of flaky tests', 'Coderl: Mastering code generation through pretrained models and deep reinforcement learning', 'Starcoder: may the source be with you!', 'Competition-level code generation with alphacode', 'Self-refine: Iterative refinement with self-feedback', 'Dera: Enhancing large language model completions with dialog-enabled resolving agents', 'Webgpt: Browser-assisted question-answering with human feedback', 'Gpt-4 technical report', 'Generative agents: Interactive simulacra of human behavior', 'Refiner: Reasoning feedback on intermediate representations', 'Automatic prompt optimization with" gradient descent" and beam search', 'Toolformer: Language models can teach themselves to use tools', 'Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface', 'ALFWorld: Aligning Text and Embodied Environments for Interactive Learning', 'Reinforcement Learning: An Introduction', 'Chain of thought prompting elicits reasoning in large language models', 'Decomposition enhances reasoning via self-evaluation guided decoding', 'HotpotQA: A dataset for diverse, explainable multi-hop question answering', 'Webshop: Towards scalable real-world web interaction with grounded language agents', 'ReAct: Synergizing reasoning and acting in language models', 'Answering questions by meta-reasoning over multiple chains of thought'], 'Synthetic prompting: generating chain-of-thought demonstrations for large language models': ['Language models are few-shot learners', 'Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks', 'Palm: Scaling language modeling with pathways', 'Scaling instruction-finetuned language models', 'Training verifiers to solve math word problems', 'Compositional semantic parsing with large language models', 'Complexity-based prompting for multi-step reasoning', 'Rarr: Researching and revising what language models say, using language models', 'PAL: program-aided language models', 'The curious case of neural text degeneration', 'Large language models can self-improve', 'Decomposed prompting: A modular approach for solving complex tasks', 'Large language models are zero-shot reasoners', 'MAWPS: A math word problem repository', 'On the advance of making language models better reasoners', 'WANLI: worker and AI collaboration for natural language inference dataset creation', 'What makes good in-context examples for gpt-3?', 'Z-ICL: zero-shot in-context learning with pseudodemonstrations', 'A diverse corpus for evaluating and developing english math word problem solvers', 'Training language models to follow instructions with human feedback', 'Are NLP models really able to solve simple math word problems?', 'Reasoning like program executors', 'Measuring and narrowing the compositionality gap in language models', 'Sentence-BERT: Sentence embeddings using Siamese BERT-networks', 'Multitask prompted training enables zero-shot task generalization', 'On the effect of pretraining corpora on in-context learning by a large-scale language model', 'Challenging big-bench tasks and whether chain-of-thought can solve them', 'Lamda: Language models for dialog applications', 'Self-consistency improves chain of thought reasoning in language models', 'Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks', 'Finetuned language models are zero-shot learners', 'Chain of thought prompting elicits reasoning in large language models', 'Symbolic knowledge distillation: from general language models to commonsense models', 'DOC: improving long story coherence with detailed outline control', 'Zerogen: Efficient zero-shot learning via dataset generation', 'Complementary explanations for effective in-context learning', 'OPT: open pre-trained transformer language models', 'Automatic chain of thought prompting in large language models', 'Least-to-most prompting enables complex reasoning in large language models'], 'LARGE LANGUAGE MODELS ARE HUMAN-LEVEL PROMPT ENGINEERS': ['Deep reinforcement learning at the edge of the statistical precipice', 'Do as i can, not as i say: Grounding language in robotic affordances', 'A general language assistant as a laboratory for alignment', 'Program synthesis with large language models', 'Efficient training of language models to fill in the middle', 'PADA: A prompt-based autoregressive approach for adaptation to unseen domains', 'Thinking aloud: Dynamic context generation improves zero-shot reasoning performance of GPT-2', 'Language models are few-shot learners', 'Evaluating large language models trained on code', 'Training verifiers to solve math word problems', 'Commonsense knowledge mining from pretrained models', 'Neural program meta-induction', 'Bert: Pre-training of deep bidirectional transformers for language understanding', 'GLM: General language model pretraining with autoregressive blank infilling', 'Learning libraries of subroutines for neurally–guided Bayesian program induction', 'Dreamcoder: Bootstrapping inductive program synthesis with wake-sleep library learning', 'Prompting: Better ways of using language models for nlp tasks', 'Making pre-trained language models better few-shot learners', 'Program synthesis', 'Instruction induction: From few examples to natural language task descriptions', 'Jigsaw: Large language models meet program synthesis', 'How can we know what language models know?', 'Scaling laws for neural language models', 'Large language models are zero-shot reasoners', 'Accelerating search-based program synthesis using learned probabilistic models', 'The power of scale for parameter-efficient prompt tuning', 'Competition-level code generation with alphacode', 'Learning programs: A hierarchical Bayesian approach', 'TruthfulQA: Measuring how models mimic human falsehoods', 'GPT understands, too', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'Firefly Monte Carlo: Exact MCMC with subsets of data', 'A machine learning framework for programming by example', 'Show your work: Scratchpads for intermediate computation with language models', 'Training language models to follow instructions with human feedback', 'True few-shot learning with language models', 'Learning how to ask: Querying LMs with mixtures of soft prompts', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'Hierarchical text-conditional image generation with clip latents', 'Prompt programming for large language models: Beyond the few-shot paradigm', 'High-resolution image synthesis with latent diffusion models', 'Solving general arithmetic word problems', 'Multitask prompted training enables zero-shot task generalization', 'Exploiting cloze-questions for few-shot text classification and natural language inference', 'AutoPrompt: Eliciting knowledge from language models with automatically generated prompts', 'Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'Challenging BIG-bench tasks and whether chain-of-thought can solve them', 'Attention is all you need', 'Do prompt-based models really understand the meaning of their prompts?', 'Finetuned language models are zero-shot learners', 'Emergent abilities of large language models', 'Chain of thought prompting elicits reasoning in large language models', 'Leveraging language to learn program abstractions and search heuristics', 'BARTScore: Evaluating generated text as text generation', 'STAR: Bootstrapping reasoning with reasoning', 'GLM-130B: An open bilingual pre-trained model', 'OPT: Open pre-trained transformer language models', 'Fine-tuning language models from human preferences'], 'BOOSTING OF THOUGHTS: TRIAL-AND-ERROR PROBLEM SOLVING WITH LARGE LANGUAGE MODELS': ['Graph of thoughts: Solving elaborate problems with large language models', 'Language models are few-shot learners', 'Xgboost: A scalable tree boosting system', 'Training verifiers to solve math word problems', 'Active prompting with chain-of-thought for large language models', 'Experiments with a new boosting algorithm', 'Complexity-based prompting for multi-step reasoning', 'Measuring massive multitask language understanding', 'Measuring mathematical problem solving with the math dataset', 'Promptboosting: Black-box text classification with ten forward passes', 'Lightgbm: A highly efficient gradient boosting decision tree', 'Large language models are zero-shot reasoners', 'Solving quantitative reasoning problems with language models', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'Self-refine: Iterative refinement with self-feedback', 'Gpt-4 technical report', 'Are nlp models really able to solve simple math word problems?', 'Refiner: Reasoning feedback on intermediate representations', 'Boosted prompt ensembles for large language models', "Automatic prompt optimization with 'gradient descent' and beam search", 'Autoprompt: Eliciting knowledge from language models with automatically generated prompts', 'Llama 2: Open foundation and fine-tuned chat models', 'Self-consistency improves chain of thought reasoning in language models', 'Chain-of-thought prompting elicits reasoning in large language models', 'Large language models are better reasoners with self-verification', 'Tree of thoughts: Deliberate problem solving with large language models', 'Prefer: Prompt ensemble learning via feedback-reflect-refine', 'Cumulative reasoning with large language models', 'Automatic chain of thought prompting in large language models', 'Automatic model selection with large language models for reasoning', 'Progressive-hint prompting improves reasoning in large language models', 'Solving challenging math word problems using gpt-4 code interpreter with code-based self-verification', 'Least-to-most prompting enables complex reasoning in large language models'], 'ASK ME ANYTHING: A SIMPLE STRATEGY FOR PROMPTING LANGUAGE MODELS': ['Can foundation models help us achieve perfect secrecy?', 'Promptsource: An integrated development environment and repository for natural language prompts', 'Semantic parsing on Freebase from question-answer pairs', 'GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow', 'On the opportunities and risks of foundation models', 'Language models are few-shot learners', 'Robust principal component analysis?', 'Palm: Scaling language modeling with pathways', 'Boolq: Exploring the surprising difficulty of natural yes/no questions', 'Training verifiers to solve math word problems', 'Selection-inference: Exploiting large language models for interpretable logical reasoning', 'The commitmentbank: Investigating projection in naturally occurring discourse', 'DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs', 'How contextual are contextualized word representations? comparing the geometry of bert, elmo, and gpt-2 embeddings', 'Fast and three-rious: Speeding up weak supervision with triplet methods', 'The pile: An 800gb dataset of diverse text for language modeling', 'Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering', 'Training compute-optimal large language models', "Surface form competition: Why the highest probability answer isn't always right", 'How can we know what language models know?', 'Maieutic prompting: Logically consistent reasoning with recursive explanations', 'Scaling laws for neural language models', "Realtime qa: What's the answer right now?", 'Looking beyond the surface: A challenge set for reading comprehension over multiple sentences', 'Natural questions: a benchmark for question answering research', 'Can language models learn from explanations in context?', 'The winograd schema challenge', 'ROUGE: A package for automatic evaluation of summaries', 'What makes good in-context examples for gpt-3?', "Reframing instructional prompts to gptk's language", 'Lsdsem 2017 shared task: The story cloze test', 'Can foundation models wrangle your data?', 'Adversarial nli: A new benchmark for natural language understanding', 'Training language models to follow instructions with human feedback', 'Wic: the word-in-context dataset for evaluating context-sensitive meaning representations', "Know what you don't know: Unanswerable questions for squad", 'Snorkel: Rapid training data creation with weak supervision', 'Training complex models with multi-task weak supervision', 'Data programming: Creating large training sets, quickly', 'Choice of plausible alternatives: An evaluation of commonsense causal reasoning', 'Multitask prompted training enables zero-shot task generalization', "It's not just size that matters: Small language models are also few-shot learners", 'Natural language to code translation with execution', 'Language models in the loop: Incorporating prompting into weak supervision', 'Recursive deep models for semantic compositionality over a sentiment treebank', 'Learning dependency structures for weak supervision models', 'SuperGLUE: A stickier benchmark for general-purpose language understanding systems', 'Gpt-j-6b: A 6 billion parameter autoregressive language model', 'Self-consistency improves chain of thought reasoning in language models', 'Benchmarking generalization via in-context instructions on 1,600+ language tasks', 'Finetuned language models are zero-shot learners', 'Emergent abilities of large language models', 'Chain of thought prompting elicits reasoning in large language models', 'Ethical and social risks of harm from language models', 'Ai chains: Transparent and controllable human-ai interaction by chaining large language model prompts', 'Seqzero: Few-shot compositional semantic parsing with sequential prompts and zero-shot models', 'Star: Self-taught reasoner bootstrapping reasoning with reasoning', 'ReCoRD: Bridging the gap between human and machine commonsense reading comprehension', 'Opt: Open pre-trained transformer language models', 'Character-level convolutional networks for text classification', 'Calibrate before use: Improving few-shot performance of language models', 'Least-to-most prompting enables complex reasoning in large language models'], 'Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts': ['Language models are few-shot learners', 'Chatgpt: Optimizing language models for dialogue', 'Bert: Pre-training of deep bidirectional transformers for language understanding', 'Making pre-trained language models better few-shot learners', 'Ppt: Pre-trained prompt tuning for few-shot learning', 'Mining and summarizing customer reviews', 'How can we know what language models know?', "Reframing instructional prompts to gptk's language", 'Prefix-tuning: Optimizing continuous prompts for generation', 'Roberta: A robustly optimized bert pretraining approach', 'Wordnet: a lexical database for english', 'Thumbs up? sentiment classification using machine learning techniques', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'Exploiting cloze-questions for few-shot text classification and natural language inference', 'Autoprompt: Eliciting knowledge from language models with automatically generated prompts', 'Recursive deep models for semantic compositionality over a sentiment treebank', 'Transprompt: Towards an automatic transferable prompting framework for few-shot text classification', 'Towards unified prompt tuning for few-shot text classification', 'Discrete and soft prompting for multilingual models', 'Adapting language models for zeroshot learning by meta-tuning on dataset and prompt collections', 'Factual probing is [mask]: Learning vs. learning to recall'], 'A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT': ['On the opportunities and risks of foundation models', 'A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity', 'How well does chatgpt do when taking the medical licensing exams?', 'Architecting the future of software engineering', 'Github copilot · your ai pair programmer', "Is github's copilot as bad as humans at introducing vulnerabilities in code?", "Asleep at the keyboard? assessing the security of github copilot's code contributions", 'IntelliJ IDEA Essentials', 'Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing', 'Design patterns: elements of reusable object-oriented software', 'Pattern-oriented software architecture, patterns for concurrent and networked objects', 'ChatGPT: Large-Scale Generative Language Models for Automated Content Creation', 'DALL·E 2: Creating Images from Text', 'Least-to-most prompting enables complex reasoning in large language models', 'Graphviz and dynagraph—static and dynamic graph drawing tools', 'Building a virtual machine inside a javascript library', 'Applying software patterns to address interoperability in blockchain-based healthcare apps', 'A pattern collection for blockchain-based applications', 'Chatgpt: five priorities for research', 'Prompt programming for large language models: Beyond the few-shot paradigm', 'Chain of thought prompting elicits reasoning in large language models', 'Emergent abilities of large language models', 'Large language models are human-level prompt engineers', 'Autoprompt: Eliciting knowledge from language models with automatically generated prompts', 'Language models are unsupervised multitask learners', 'Least-to-most prompting enables complex reasoning in large language models', 'Maieutic prompting: Logically consistent reasoning with recursive explanations', 'Ask me anything: A simple strategy for prompting language models', 'Design guidelines for prompt engineering text-to-image generative models', 'Chat2vis: Generating data visualisations via natural language using chatgpt, codex and gpt-3 large language models', 'Ptr: Prompt tuning with rules for text classification', 'Can chatgpt write a good boolean query for systematic review literature search?', 'Conversational automated program repair', 'Chatgpt goes to law school', 'Mathematical capabilities of chatgpt'], 'Active Example Selection for In-Context Learning': ['A Brief Survey of Deep Reinforcement Learning', 'Dynamic Programming, first edition', 'The dangers of underclaiming: Reasons for caution when reporting how NLP systems fail', 'Language Models are Few-Shot Learners', 'Committeebased sampling for training probabilistic classifiers', 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding', 'Learning how to Active Learn: A Deep Reinforcement Learning Approach', 'Making Pre-trained Language Models Better Few-shot Learners', 'Double Q-learning', 'Rainbow: Combining Improvements in Deep Reinforcement Learning', "Surface Form Competition: Why the Highest Probability Answer Isn't Always Right", 'A Survey of Generalisation in Deep Reinforcement Learning', 'Large Language Models are Zero-Shot Reasoners', 'Conservative Q-Learning for Offline Reinforcement Learning', 'The Power of Scale for Parameter-Efficient Prompt Tuning', 'Self-Improving Reactive Agents Based on Reinforcement Learning, Planning and Teaching', 'What Makes Good In-Context Examples for GPT-$3$?', 'Learning How to Actively Learn: A Deep Imitation Learning Approach', 'RoBERTa: A Robustly Optimized BERT Pretraining Approach', 'Fantastically Ordered Prompts and Where to Find Them: Overcoming FewShot Prompt Order Sensitivity', 'Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?', "Reframing Instructional Prompts to GPTk's Language", 'Playing Atari with Deep Reinforcement Learning', 'WebGPT: Browser-assisted question-answering with human feedback', 'Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping', 'Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales', 'Curiosity-Driven Exploration by Self-Supervised Prediction', 'True Few-Shot Learning with Language Models', 'A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems', 'Language models are unsupervised multitask learners', 'Scaling Language Models: Methods, Analysis & Insights from Training Gopher', 'Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer', 'Learning To Retrieve Prompts for In-Context Learning', 'Active learning literature survey', 'Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank', 'Natural Value', 'Building a question answering test collection', 'SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer', 'Emergent abilities of large language models', 'IDPG: An Instance-Dependent Prompt Generation Method', 'An Explanation of In-context Learning as Implicit Bayesian Inference', 'OPT: Open Pretrained Transformer Language Models', 'Character-level Convolutional Networks for Text Classification', 'Calibrate Before Use: Improving Few-Shot Performance of Language Models'], 'AUTOMATIC CHAIN OF THOUGHT PROMPTING IN LARGE LANGUAGE MODELS': ['Language models are fewshot learners', 'Evaluating large language models trained on code', 'Palm: Scaling language modeling with pathways', 'Training verifiers to solve math word problems', 'Complexity-based prompting for multi-step reasoning', 'Did Aristotle use a laptop? A question answering benchmark with implicit reasoning strategies', "Surface form competition: Why the highest probability answer isn't always right", 'Learning to solve arithmetic word problems with verb categorization', 'Large language models are zero-shot reasoners', 'Parsing algebraic word problems into equations', 'MAWPS: A math word problem repository', 'On the advance of making language models better reasoners', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning', 'What makes good in-context examples for gpt-3?', 'What makes pre-trained language models better zero/few-shot learners?', 'Learn to explain: Multimodal reasoning via thought chains for science question answering', 'Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'Noisy channel language model prompting for few-shot text classification', 'Rethinking the role of demonstrations: What makes in-context learning work?', 'Cross-task generalization via natural language crowdsourcing instructions', 'Show your work: Scratchpads for intermediate computation with language models', 'Training language models to follow instructions with human feedback', 'Are NLP models really able to solve simple math word problems?', 'Self-consistency improves chain of thought reasoning in language models', 'Rationale-augmented ensembles in language models', 'Do prompt-based models really understand the meaning of their prompts?', 'Finetuned language models are zero-shot learners', 'Chain of thought prompting elicits reasoning in large language models', 'Star: Bootstrapping reasoning with reasoning', 'Calibrate before use: Improving few-shot performance of language models', 'Least-to-most prompting enables complex reasoning in large language models', 'Large language models are human-level prompt engineers'], 'What Makes Good In-Context Examples for GPT-3?': ['Semantic parsing on freebase from question-answer pairs', 'A large annotated corpus for learning natural language inference', 'Language models are few-shot learners', 'Skeleton-to-response: Dialogue generation guided by retrieval memory', 'Faithful to the original: Fact aware neural abstractive summarization', 'Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation', 'Bert: Pre-training of deep bidirectional transformers for language understanding', 'Handling divergent reference texts when evaluating table-to-text generation', 'Making pre-trained language models better few-shot learners', 'Search engine guided neural machine translation', 'Generating sentences by editing prototypes', 'A retrieve-and-edit framework for predicting structured outputs', 'Measuring massive multitask language understanding', 'Generalization and similarity in exemplar models of categorization: Insights from machine learning', 'Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension', 'Dense passage retrieval for open-domain question answering', 'Bertknn: Adding a knn search component to pretrained language models for better qa', 'Nearest neighbor machine translation', 'Generalization through memorization: Nearest neighbor language models', 'Natural questions: a benchmark for question answering research', 'Crosslingual language model pretraining', 'Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension', 'Retrieval-augmented generation for knowledge-intensive nlp tasks', 'Delete, retrieve, generate: A simple approach to sentiment and style transfer', 'Roberta: A robustly optimized bert pretraining approach', 'Learning word vectors for sentiment analysis', 'Generation-augmented retrieval for open-domain question answering', 'Exemplar encoder-decoder for neural conversation generation', 'Bleu: a method for automatic evaluation of machine translation', 'ToTTo: A controlled table-to-text generation dataset', 'Text generation with exemplar-based adaptive decoding', 'Improving language understanding by generative pre-training', 'Language models are unsupervised multitask learners', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'Explaining and improving model behavior with k nearest neighbor representations', 'Sentence-bert: Sentence embeddings using siamese bert-networks', 'Making monolingual sentence embeddings multilingual using knowledge distillation', 'Autoprompt: Eliciting knowledge from language models with automatically generated prompts', 'Recursive deep models for semantic compositionality over a sentiment treebank', 'Two are better than one: An ensemble of retrieval-and generation-based dialog systems', 'Experiments and prospects of example-based machine translation', 'Attention is all you need', 'Glue: A multi-task benchmark and analysis platform for natural language understanding', 'Retrieve and refine: Improved sequence generation models for dialogue', 'A broad-coverage challenge corpus for sentence understanding through inference', "Huggingface's transformers: State-of-the-art natural language processing", 'Response generation by context-aware prototype editing', 'mt5: A massively multilingual pre-trained text-to-text transformer', 'Learning to respond with deep neural networks for retrieval-based human-computer conversation system', 'Xlnet: Generalized autoregressive pretraining for language understanding', 'Calibrate before use: Improving few-shot performance of language models', 'Example-based named entity recognition'], 'Metacognitive Prompting Improves Understanding in Large Language Models': ['KBot: a Knowledge graph based chatBot for natural language understanding over linked data', 'Natural language understanding', 'Palm 2 technical report', 'Spoken language understanding for natural interaction: The siri experience', 'Language models are few-shot learners', 'Jumping NLP curves: A review of natural language processing research', 'SemEval-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation', 'Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality', 'The pascal recognising textual entailment challenge', 'The commitmentbank: Investigating projection in naturally occurring discourse', 'Foundations of computational linguistics', 'Towards reasoning in large language models: A survey', 'Large language models are zero-shot reasoners', 'The winograd schema challenge', 'Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing', 'Recent advances in natural language processing via large pre-trained language models: A survey', 'Language model is all you need: Natural language understanding as question answering', 'What can we learn from collective human opinions on natural language inference data?', 'GPT-4 Technical Report', 'Cognitive modules of an NLP knowledge base for language understanding', 'WiC: the Word-in-Context Dataset for Evaluating Context-Sensitive Meaning Representations', 'Scaling language models: Methods, analysis & insights from training gopher', 'Squad: 100,000+ questions for machine comprehension of text', 'Choice of plausible alternatives: An evaluation of commonsense causal reasoning', 'Metacognition', 'First quora dataset release: question pairs (2017)', 'Recursive deep models for semantic compositionality over a sentiment treebank', 'Use chat gpt to solve programming bugs', 'Llama 2: Open foundation and fine-tuned chat models', 'Superglue: A stickier benchmark for general-purpose language understanding systems', 'Glue: A multi-task benchmark and analysis platform for natural language understanding', 'SelfConsistency Improves Chain of Thought Reasoning in Language Models', 'Integrating Physiological Time Series and Clinical Notes with Transformer for Early Prediction of Sepsis', 'Are Large Language Models Ready for Healthcare? A Comparative Study on Clinical Language Understanding', 'An empirical study on the robustness of the segment anything model (sam)', 'Chain-of-thought prompting elicits reasoning in large language models', 'Ethical and social risks of harm from language models', 'Automatic chain of thought prompting in large language models', 'A survey of large language models', 'Empirical quantitative analysis of covid-19 forecasting models', 'Progressive-hint prompting improves reasoning in large language models', 'Least-to-Most Prompting Enables Complex Reasoning in Large Language Models', 'Exploring ai ethics of chatgpt: A diagnostic analysis'], 'LARGE LANGUAGE MODELS AS OPTIMIZERS': ['Backpropagation and stochastic gradient descent method', 'Palm 2 technical report', 'Concorde tsp solver', 'An overview of evolutionary algorithms for parameter optimization', 'Constitutional ai: Harmlessness from ai feedback', 'Large language models as tool makers', 'Evoprompting: Language models for code-level neural architecture search', 'Improving code generation by training with natural language feedback', 'When do you need chain-of-thought prompting for chatgpt?', 'Instructzero: Efficient instruction optimization for black-box large language models', 'Learning to perform local rewriting for combinatorial optimization', 'Teaching large language models to self-debug', 'Towards learning universal hyperparameter optimizers with transformers', 'Training verifiers to solve math word problems', 'Rlprompt: Optimizing discrete text prompts with reinforcement learning', 'Learning heuristics for the tsp by policy gradient', 'Promptbreeder: Self-referential self-improvement via prompt evolution', 'The capacity for moral self-correction in large language models', 'Making pre-trained language models better few-shot learners', 'Approximate traveling salesman algorithms', 'Connecting large language models with evolutionary algorithms yields powerful prompt optimizers', 'The traveling salesman problem and its variations', 'An extension of the lin-kernighan-helsgaun tsp solver for constrained traveling salesman and vehicle routing problems', 'The traveling salesman problem', 'Language models can solve computer tasks', 'Adam: A method for stochastic optimization', 'Large language models are zero-shot reasoners', 'Attention, learn to solve routing problems!', 'Evolution through large models', 'The power of scale for parameter-efficient prompt tuning', 'Prefix-tuning: Optimizing continuous prompts for generation', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'Gpt understands, too', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', "Let's do a thought experiment: Using counterfactuals to improve moral reasoning", 'Text and patterns: For effective chain of thought, it takes two to tango', 'Self-refine: Iterative refinement with self-feedback', 'Language model crossover: Variation through few-shot prompting', 'Large language models as general pattern machines', 'Dera: Enhancing large language model completions with dialog-enabled resolving agents', 'Reinforcement learning for solving the vehicle routing problem', 'Demystifying gpt self-repair for code generation', 'Gurobi optimizer reference manual', 'Grips: Gradient-free, edit-based instruction search for prompting large language models', 'Automatic prompt optimization with"gradient descent" and beam search', 'On the momentum term in gradient descent learning algorithms', 'Learning how to ask: Querying lms with mixtures of soft prompts', 'Modern heuristic techniques for combinatorial problems', 'Prompt programming for large language models: Beyond the few-shot paradigm', 'Derivative-free optimization: a review of algorithms and comparison of software implementations', 'An analysis of several heuristics for the traveling salesman problem', 'Solving general arithmetic word problems', 'Toolformer: Language models can teach themselves to use tools', 'Autoprompt: Eliciting knowledge from language models with automatically generated prompts', 'Reflexion: an autonomous agent with dynamic memory and self-reflection', 'Challenging big-bench tasks and whether chain-of-thought can solve them', 'Voyager: An open-ended embodied agent with large language models', 'Self-consistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'Larger language models do in-context learning differently', 'Hard prompts made easy: Gradient-based discrete optimization for prompt tuning and discovery', 'Wizardlm: Empowering large language models to follow complex instructions', 'Gps: Genetic prompt search for efficient few-shot learning', 'System-level natural language feedback', 'Tempera: Test-time prompt editing via reinforcement learning', 'Calibrate before use: Improving few-shot performance of language models', 'Least-to-most prompting enables complex reasoning in large language models', 'Large language models are human-level prompt engineers'], 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models': ['Do as I can, not as I say: Grounding language in robotic affordances', 'MathQA: Towards interpretable math word problem solving with operation-based formalisms', 'Giving BERT a calculator: Finding operations and arguments with reading comprehension', 'Learning with latent language', 'Program synthesis with large language models', 'Beyond the imitation game: Measuring and extrapolating the capabilities of language models', 'Flexible generation of natural language deductions', 'Language models are few-shot learners', 'Making neural programming architectures generalize via recursion', 'e-SNLI: Natural language inference with natural language explanations', 'Can rationalization improve robustness?', 'Evaluating large language models trained on code', 'Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension', 'Semantically-aligned equation generation for solving and reasoning math word problems', 'Transformers as soft reasoners over language', 'Training verifiers to solve math word problems', 'BERT: Pre-training of deep bidirectional transformers for language understanding', 'Neural logic machines', 'Benefits of intermediate annotations in reading comprehension', 'Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies', 'DREAM: Uncovering mental models behind language models', 'Training classifiers with natural language explanations', 'When can models learn from explanations? A formal framework for understanding the roles of explanation data', 'Measuring mathematical problem solving with the math dataset', 'Learning to solve arithmetic word problems with verb categorization', 'Learning to reason deductively: Math word problem solving as complex relation extraction', 'Scaling laws for neural language models', 'MAWPS: A math word problem repository', 'Can language models learn from explanations in context?', 'MWPToolkit: An open-source framework for deep learning-based math word problem solvers', 'How many data points is a prompt worth?', 'The power of scale for parameter-efficient prompt tuning', 'Solving logic puzzles: From robust processing to precise semantics', 'Prefix-tuning: Optimizing continuous prompts for generation', 'Explainable multi-hop verbal reasoning through internal monologue', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing', 'Rationale-inspired natural language explanations with commonsense', 'Few-shot self-rationalization with natural language prompts', 'On faithfulness and factuality in abstractive summarization', 'A diverse corpus for evaluating and developing English math word problem solvers', 'Rethinking the role of demonstrations: What makes in-context learning work?', 'WT5?! Training text-to-text models to explain their predictions', 'Show your work: Scratchpads for intermediate computation with language models', 'Training language models to follow instructions with human feedback', 'Are NLP models really able to solve simple math word problems?', 'Deep contextualized word representations', 'Reasoning like program executors', "Measuring and improving BERT's mathematical abilities by predicting the order of reasoning", 'Scaling language models: Methods, analysis & insights from training Gopher', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'SelfExplain: A self-explaining architecture for neural text classifiers', 'Explain yourself! Leveraging language models for commonsense reasoning', 'NumNet: Machine reading comprehension with numerical reasoning', 'Measuring attribution in natural language generation models', 'Teaching autoregressive language models complex tasks by demonstration', 'A recipe for arbitrary text style transfer with large language models', 'Prompt programming for large language models: Beyond the few-shot paradigm', 'Solving general arithmetic word problems', 'Reasoning about Quantities in Natural Language', 'RuleBERT: Teaching soft rules to pre-trained language models', 'Multitask prompted training enables zero-shot task generalization', 'Generate & rank: A multi-task framework for math word problems', 'CommonsenseQA: A question answering challenge targeting commonsense knowledge', 'Leap-of-thought: Teaching pre-trained models to systematically reason over implicit knowledge', 'CommonsenseQA 2.0: Exposing the limits of ai through gamification', 'Unifying language learning paradigms', 'LaMDA: Language models for dialog applications', 'Self-consistency improves chain of thought reasoning in language models', 'Benchmarking generalization via in-context instructions on 1,600+ language tasks', 'Finetuned language models are zero-shot learners', 'Emergent abilities of large language models', 'Reframing human-AI collaboration for generating free-text explanations', 'Teach me to explain: A review of datasets for explainable NLP', 'Measuring association between labels and free-text rationales', 'PromptChainer: Chaining large language model prompts through visual programming', 'AI chains: Transparent and controllable human-AI interaction by chaining large language model prompts', 'Neural execution engines: Learning to execute subroutines', 'Refining language models with compositional explanations', 'The unreliability of explanations in few-shot in-context learning', 'Few-shot out-of-domain transfer learning of natural language explanations', 'Using “annotator rationales” to improve machine learning for text categorization', 'Learning to execute', 'STaR: Bootstrapping reasoning with reasoning', 'Calibrate before use: Improving few-shot performance of language models', 'Towards interpretable natural language understanding with explanations as latent variables'], 'An Information-theoretic Approach to Prompt Engineering Without Ground Truth Labels': ['Word Sense Induction with Neural biLM and Symmetric Patterns', 'GPT-Neo: Large Scale Autoregressive Language Modeling with MeshTensorflow', 'COMET : Commonsense Transformers for Automatic Knowledge Graph Construction', 'Inducing Relational Knowledge from BERT', 'Class-based n-gram models of natural language', 'Language models are few-shot learners', 'Boolq: Exploring the surprising difficulty of natural yes/no questions', 'Elements of Information Theory 2nd Edition (Wiley Series in Telecommunications and Signal Processing)', 'BERT: Pre-training of deep bidirectional transformers for language understanding', 'SemEval-2012 task 7: Choice of plausible alternatives: An evaluation of commonsense causal reasoning', 'PPT: Pre-trained Prompt Tuning for Few-shot Learning', 'Earlystopped neural networks are consistent', 'A mutual information maximization perspective of language representation learning', 'The Power of Scale for Parameter-Efficient Prompt Tuning', 'Prefix-Tuning: Optimizing Continuous Prompts for Generation', 'Linguistic knowledge and transferability of contextual representations', 'Pretrain, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing', 'GPT Understands, Too', 'Fantastically Ordered Prompts and Where to Find Them: Overcoming FewShot Prompt Order Sensitivity', 'Learning word vectors for sentiment analysis', 'A corpus and evaluation framework for deeper understanding of commonsense stories', 'Distributional generalization: A new kind of generalization', 'The LAMBADA dataset: Word prediction requiring a broad discourse context', 'True Few-Shot Learning with Language Models', 'Language models as knowledge bases?', 'Wic: 10,000 example pairs for evaluating context-sensitive representations', 'Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer', "Know what you don't know: Unanswerable questions for squad", 'Prompt programming for large language models: Beyond the few-shot paradigm', 'Mutual information maximization for simple and accurate part-of-speech induction', 'Commonsenseqa: A question answering challenge targeting commonsense knowledge', 'Information-Theoretic Probing with Minimum Description Length', 'GPTJ-6B: A 6 Billion Parameter Autoregressive Language Model', 'Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners', 'Calibrate Before Use: Improving Few-Shot Performance of Language Models', 'Representation Learning of Knowledge Graphs with Entity Attributes and Multimedia Descriptions'], 'Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery': ['Language Models are Few-Shot Learners', 'Reproducible scaling laws for contrastive language-image learning', 'Scaling instruction-finetuned language models', 'Binaryconnect: Training deep neural networks with binary weights during propagations', 'Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1', 'Discovering the hidden vocabulary of dalle-2', 'RLPrompt: Optimizing discrete text prompts with reinforcement learning', 'OpenPrompt: An open-source framework for prompt-learning', 'HotFlip: White-box adversarial examples for text classification', 'An image is worth one word: Personalizing text-to-image generation using textual inversion', 'Gradient-based adversarial attacks against text transformers', 'Scaling up vision-language pre-training for image captioning', 'Prompt waywardness: The curious case of discretized interpretation of continuous prompts', 'Gradient-based constrained sampling from language models', 'The power of scale for parameter-efficient prompt tuning', 'Training quantized nets: A deeper understanding', 'Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation', 'Prefix-tuning: Optimizing continuous prompts for generation', 'Microsoft coco: Common objects in context', 'Deep learning face attributes in the wild', 'Decoupled weight decay regularization', 'Hidden factors and hidden topics: Understanding rating dimensions with review text', 'Grips: Gradient-free, edit-based instruction search for prompting large language models', 'Multitask prompted training enables zero-shot task generalization', 'Laion-5b: An open large-scale dataset for training next generation image-text models', 'Adafactor: Adaptive learning rates with sublinear memory cost', "Toward human readable prompt tuning: Kubrick's the shining is a good movie, and a good prompt too?", 'AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts', 'Recursive deep models for semantic compositionality over a sentiment treebank', 'Vinvl: Revisiting visual representations in vision-language models', 'Opt: Open pre-trained transformer language models', 'Character-level convolutional networks for text classification'], 'Prompting Large Language Models With the Socratic Method': ['Socratic irony and argumentation', 'Language models are few-shot learners', 'Asking the right questions, a guide to critical thinking', 'A few-shot semantic parser for wizard-of-oz dialogues with the precise thingtalk representation', 'CRIT: An inquisitive prompt template for critical reading (extended)', 'Natural language processing (almost) from scratch', 'Bert: Pre-training of deep bidirectional transformers for language understanding', 'Word-level coreference resolution', 'Coarse-to-fine decoding for neural semantic parsing', "The Thinker's Guide to the Art of Asking Essential Questions", 'How close is ChatGPT to human experts? comparison corpus, evaluation, and detection', 'Ptr: Prompt tuning with rules for text classification', 'Bertese: Learning to speak to bert', 'Towards reasoning in large language models: A survey', 'How Can We Know What Language Models Know?', 'Maieutic prompting: Logically consistent reasoning with recursive explanations', 'Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition', 'RACE: Largescale ReAding comprehension dataset from examinations', 'Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension', 'Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing', '501 Critical Reading Questions', 'Augmented language models: a survey', 'ChatGPT', 'The pagerank citation ranking: Bringing order to the web', 'Compositional semantic parsing on semistructured tables', 'Critical Thinking: What Every Person Needs to Survive in a Rapidly Changing World', 'Critical thinking: The art of socratic questioning, part iii', 'Counterfactuals and Causal Inference: Methods and Principles for Social Research', 'Model ensemble instead of prompt fusion: a sample-specific knowledge transfer method for few-shot prompt tuning', 'How to Win Every Argument', 'The republic', 'Four problems of abduction: A brief history', 'Cross-Examination: Science and Techniques', 'Exploiting cloze-questions for few-shot text classification and natural language inference', 'Would socrates have actually used the "socratic method" for clinical teaching?', 'Mediating between the muse and the masses: Inspiration and the actualization of creative ideas', 'Attention is all you need', 'Self-consistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'Socratic method', 'Transfertransfo: A transfer learning approach for neural network based conversational agents', 'Internet encyclopedia of philosophy', 'Socratic models: Composing zero-shot multimodal reasoning with language', 'A static and dynamic attention framework for multi-turn dialogue generation', 'Structure-aware fine-tuning of sequence-to-sequence transformers for transition-based AMR parsing'], 'Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning': ['NLTK: The natural language toolkit', 'Language models are few-shot learners', 'Vicuna: An opensource chatbot impressing gpt-4 with 90%* chatgpt quality', 'Palm: Scaling language modeling with pathways', 'Beyond i.i.d.: Three levels of generalization for question answering on knowledge bases', 'Realm: Retrievalaugmented language model pre-training', 'Constructing a multihop QA dataset for comprehensive evaluation of reasoning steps', 'Hover: A dataset for many-hop fact extraction and claim verification', 'TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension', 'Dense passage retrieval for opendomain question answering', 'Large language models are zero-shot reasoners', 'Natural questions: A benchmark for question answering research', 'Retrieval-augmented generation for knowledge-intensive nlp tasks', 'Self-prompting large language models for opendomain qa', 'A survey on multi-hop question answering and generation', 'Gpt-4 technical report', 'Training language models to follow instructions with human feedback', 'Measuring and narrowing the compositionality gap in language models', 'SentenceBERT: Sentence embeddings using Siamese BERTnetworks', 'How much knowledge can you pack into the parameters of a language model?', 'The web as a knowledge-base for answering complex questions', 'Stanford alpaca: An instruction-following llama model', 'Llama: Open and efficient foundation language models', 'Musique: Multihop questions via single-hop question composition', 'Iteratively prompt pre-trained language models for chain of thought', 'Self-consistency improves chain of thought reasoning in language models', 'Chain-of-thought prompting elicits reasoning in large language models', 'Wizardlm: Empowering large language models to follow complex instructions', 'HotpotQA: A dataset for diverse, explainable multi-hop question answering', 'Generate rather than retrieve: Large language models are strong context generators', 'Star: Bootstrapping reasoning with reasoning', 'Automatic chain of thought prompting in large language models', 'Least-to-most prompting enables complex reasoning in large language models'], 'ART: Automatic multi-step reasoning and tool-use for large language models': ['Ask me anything: A simple strategy for prompting language models', 'Prompting is programming: A query language for large language models', 'Language models are few-shot learners', 'Evaluating large language models trained on code', 'Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks', 'Palm: Scaling language modeling with pathways', 'Scaling instruction-finetuned language models', 'Training verifiers to solve math word problems', 'Successive prompting for decomposing complex questions', 'Pal: Program-aided language models', 'Measuring massive multitask language understanding', 'Unifiedqa: Crossing format boundaries with a single QA system', 'Decomposed prompting: A modular approach for solving complex tasks', 'Large language models are zero-shot reasoners', 'Internet-augmented dialogue generation', 'Internet-augmented language models through few-shot prompting for open-domain question answering', 'Few-shot parameter-efficient finetuning is better and cheaper than in-context learning', 'Cross-task generalization via natural language crowdsourcing instructions', 'Webgpt: Browser-assisted question-answering with human feedback', 'Training language models to follow instructions with human feedback', 'Talm: Tool augmented language models', 'Are NLP models really able to solve simple math word problems?', 'Measuring and narrowing the compositionality gap in language models', 'Multitask prompted training enables zero-shot task generalization', 'Toolformer: Language models can teach themselves to use tools', 'Language models that seek for knowledge: Modular search & generation for dialogue and prompt completion', 'Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'Challenging big-bench tasks and whether chain-of-thought can solve them', 'Lamda: Language models for dialog applications', 'Self-consistency improves chain of thought reasoning in language models', 'Finetuned language models are zero-shot learners', 'Chain of thought prompting elicits reasoning in large language models', 'An explanation of in-context learning as implicit bayesian inference', 'Automatic chain of thought prompting in large language models', 'Least-to-most prompting enables complex reasoning in large language models'], 'Graph of Thoughts: Solving Elaborate Problems with Large Language Models': ['Practice of Streaming Processing of Dynamic Graphs: Concepts, Models, and Systems', 'GDI: A Graph Database Interface Standard', 'The Graph Database Interface: Scaling Online Transactional and Analytical Graph Workloads to Hundreds of Thousands of Cores', 'Demystifying Graph Databases: Analysis and Taxonomy of Data Organization, System Designs, and Graph Queries', 'Motif Prediction with Graph Neural Networks', 'Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency Analysis', 'Neural Graph Databases', 'SISA: Set-Centric Instruction Set Architecture for Graph Mining on Processing-in-Memory Systems', 'Communication-Efficient Jaccard Similarity for HighPerformance Distributed Genome Comparisons', 'ProbGraph: High-Performance and High-Accuracy Graph Mining with Probabilistic Set Representations', 'GraphMineSuite: Enabling HighPerformance and Programmable Graph Mining Algorithms with Set Algebra', 'Geometric Deep Learning: Going beyond Euclidean data', 'Language Models are Few-Shot Learners', 'Sparks of Artificial General Intelligence: Early experiments with GPT-4', 'Graph Mining: Laws, Generators, and Algorithms', 'Machine Learning on Graphs: A Model and Comprehensive Taxonomy', 'Teaching Large Language Models to Self-Debug', 'Fast Graph Pattern Matching', 'PaLM: Scaling Language Modeling with Pathways', 'Mining Graph Data', 'Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning', 'LowLatency Graph Streaming Using Compressed PurelyFunctional Trees', 'Language Model Cascades', 'A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level', 'Graph Pattern Matching: From Intractable to Polynomial Time', 'DISTINGER: A distributed graph data structure for massive dynamic graph processing', 'Triangles to Capture Social Cohesion', 'Hierarchical Models in the Brain', 'Complexity-Based Prompting for Multi-Step Reasoning', 'Learning Combinatorial Node Labeling Algorithms', 'Lifting Sequential Graph Algorithms for Distributed-Memory Parallel Computation', 'The Parallel BGL: A generic library for distributed graph computations', 'Representation Learning on Graphs: Methods and Applications', 'A survey on improving NLP models with human explanations', 'Cyclic Pattern Kernels for Predictive Graph Mining', 'Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents', 'Inner Monologue: Embodied Reasoning through Planning with Language Models', 'A survey of frequent subgraph mining algorithms', 'Language Models can Solve Computer Tasks', 'Explanation-Based Human Debugging of NLP Models: A Survey', 'The Power of Scale for Parameter-Efficient Prompt Tuning', 'Prefix-Tuning: Optimizing Continuous Prompts for Generation', 'Large Language Model Guided Treeof-Thought', 'Challenges in Parallel Graph Processing', 'Self-Refine: Iterative Refinement with Self-Feedback', 'Pregel: A System for Large-Scale Graph Processing', 'Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding', 'Show Your Work: Scratchpads for Intermediate Computation with Language Models', 'REFINER: Reasoning Feedback on Intermediate Representations', 'Shaping Communities out of Triangles', 'Reasoning with Language Model Prompting: A Survey', 'graph-of-thoughts Repository', 'Improving Language Understanding by Generative Pre-Training', 'Language Models are Unsupervised Multitask Learners', 'Graph Databases: New Opportunities for Connected Data', 'The Future is Big Graphs: A Community View on Graph Processing Systems', 'The Graph Neural Network Model', 'Graph clustering', 'AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts', 'Reflexion: Language Agents with Verbal Reinforcement Learning', 'Automatic Prompt Augmentation and Selection with Chain-of-Thought from Labeled Data', 'Arabesque: A System for Distributed Graph Mining', 'LLaMA: Open and Efficient Foundation Language Models', 'Llama 2: Open Foundation and Fine-Tuned Chat Models', 'Attention is All you Need', 'Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models', 'Self-Consistency Improves Chain of Thought Reasoning in Language Models', 'Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents', 'Interactive Natural Language Processing', 'Putting Humans in the Natural Language Processing Loop: A Survey', 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models', 'PromptChainer: Chaining Large Language Model Prompts through Visual Programming', 'AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts', 'A Comprehensive Survey on Graph Neural Networks', 'Self-Evaluation Guided Beam Search for Reasoning', 'Foundation Models for Decision Making: Problems, Methods, and Opportunities', 'Tree of Thoughts: Deliberate Problem Solving with Large Language Models', 'ReAct: Synergizing Reasoning and Acting in Language Models', 'Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in Large Language Models', 'STaR: Bootstrapping Reasoning With Reasoning', 'Planning with Large Language Models for Code Generation', 'Deep Learning on Graphs: A Survey', 'Graph neural networks: A review of methods and applications', 'Large Language Models Are Human-Level Prompt Engineers', 'Solving Math Word Problems via Cooperative Reasoning induced Language Models'], 'REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS': ['Imitating interactive intelligence', 'Do as i can, not as i say: Grounding language in robotic affordances', 'Inner speech: development, cognitive functions, phenomenology, and neurobiology', 'Working memory', 'Language models are few-shot learners', 'Palm: Scaling language modeling with pathways', 'Faithful reasoning using large language models', 'Selection-inference: Exploiting large language models for interpretable logical reasoning', 'ELI5: Long form question answering', 'Vygotsky, luria, and the social brain', 'Improving alignment of dialogue agents via targeted human judgements', 'A simple language model for task-oriented dialogue', 'Language models as zero-shot planners: Extracting actionable knowledge for embodied agents', 'Inner monologue: Embodied reasoning through planning with language models', 'Lila: Language-informed latent actions', 'Large language models are zero-shot reasoners', 'Internet-augmented language models through few-shot prompting for open-domain question answering', 'Retrieval-augmented generation for knowledge-intensive nlp tasks', 'Pre-trained language models for interactive decision-making', 'Ls vygotsky and the problem of localization of functions', 'Text and patterns: For effective chain of thought, it takes two to tango', 'Language models are few-shot butlers', 'Webgpt: Browser-assisted question-answering with human feedback', 'Show your work: Scratchpads for intermediate computation with language models', 'A generalist agent', 'Alfred: A benchmark for interpreting grounded instructions for everyday tasks', 'Alfworld: Aligning text and embodied environments for interactive learning', 'Language models that seek for knowledge: Modular search & generation for dialogue and prompt completion', 'Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage', 'Fever: a large-scale dataset for fact extraction and verification', 'Thinking and speech', 'Self-consistency improves chain of thought reasoning in language models', 'Rationale-augmented ensembles in language models', 'Chain of thought prompting elicits reasoning in large language models', 'Hotpotqa: A dataset for diverse, explainable multi-hop question answering', 'Keep CALM and explore: Language models for action generation in text-based games', 'Webshop: Towards scalable real-world web interaction with grounded language agents', 'Star: Bootstrapping reasoning with reasoning', 'Least-to-most prompting enables complex reasoning in large language models', 'Adaptive information seeking for open-domain question answering'], 'SELF-REFINE: Iterative Refinement with Self-Feedback': ['NLTK: The natural language toolkit', 'Training a helpful and harmless assistant with reinforcement learning from human feedback', 'Constitutional ai: Harmlessness from ai feedback', 'Triangulating Python Performance Issues with SCALENE', 'Large language models can implement policy iteration', 'Interval estimation for a binomial proportion', 'Language models are few-shot learners', 'Evaluating Large Language Models Trained on Code', 'Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality', 'Training verifiers to solve math word problems', 'Teaching a black-box learner', 'Read, revise, repeat: A system demonstration for human-in-the-loop iterative text revision', 'NL-EDIT: Correcting semantic parse errors through natural language interaction', 'A cognitive process theory of writing', 'Gptscore: Evaluate as you desire', 'Pal: Program-aided language models', 'Koala: A dialogue model for academic research', 'Language models can solve computer tasks', 'CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning', 'Delete, retrieve, generate: a simple approach to sentiment and style transfer', 'CommonGen: A constrained text generation challenge for generative commonsense reasoning', 'Rainier: Reinforced knowledge introspector for commonsense question answering', 'Quark: Controllable text generation with reinforced unlearning', 'Learning performance-improving code edits', 'Memory-assisted prompt editing to improve gpt-3 after deployment', 'Think about it! improving defeasible reasoning by first modeling the question scenario', 'Unsupervised evaluation of interactive dialog with DialoGPT', 'Codegen: An open large language model for code with multi-turn program synthesis', 'Model index for researchers', 'Training language models to follow instructions with human feedback', 'Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback', 'Style transfer through back-translation', 'Measuring and narrowing the compositionality gap in language models', 'Codenet: A large-scale ai for code dataset for learning a diversity of coding tasks', 'Learning to model editing processes', 'Self-critiquing models for assisting human evaluators', 'Training language models with natural language feedback', 'Peer: A collaborative language model', 'Reflexion: an autonomous agent with dynamic memory and self-reflection', 'The architecture of complexity', 'Learning to summarize with human feedback', 'Principle-driven self-alignment of language models from scratch with minimal human supervision', 'Challenging big-bench tasks and whether chain-of-thought can solve them', 'Interscript: A dataset for interactive learning of scripts through error feedback', 'Learning to repair: Repairing model output errors after deployment using a dynamic memory of feedback', 'Llama: Open and efficient foundation language models', 'Chain of Thought Prompting Elicits Reasoning in Large Language Models', 'Generating sequences by learning to self-correct', 'Re3: Generating longer stories with recursive reprompting and revision', 'Graph-based, self-supervised program repair from diagnostic feedback', 'Character-level convolutional networks for text classification'], 'Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method': ['METEOR: An automatic metric for MT evaluation with improved correlation with human judgments', 'Language models are few-shot learners', 'Gpt-3 and instructgpt: technological dystopianism, utopianism, and “contextual” perspectives in ai ethics and industry', 'Unisumm: Unified few-shot summarization with multi-task pre-training and prefix-tuning', 'Palm: Scaling language modeling with pathways', 'BERT: Pre-training of deep bidirectional transformers for language understanding', 'Multi-news: A large-scale multi-document summarization dataset and abstractive hierarchical model', 'SummEval: Re-evaluating summarization evaluation', 'Bottom-up abstractive summarization', 'News summarization and evaluation in the era of gpt-3', 'Newsroom: A dataset of 1.3 million summaries with diverse extractive strategies', 'The effects of human variation in DUC summarization evaluation', 'Ctrlsum: Towards generic controllable text summarization', 'Teaching machines to read and comprehend', 'Large language models are zero-shot reasoners', 'Wikihow: A large scale text summarization dataset', 'Neural text summarization: A critical evaluation', 'The structure and function of communication in society', 'BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension', 'Reader-aware multi-document summarization: An enhanced model and the first dataset', 'A technique for the measurement of attitudes', 'ROUGE: A package for automatic evaluation of summaries', 'Fine-tune bert for extractive summarization', 'Roberta: A robustly optimized bert pretraining approach', 'Revisiting the gold standard: Grounding summarization evaluation with robust human evaluation', 'BRIO: Bringing order to abstractive summarization', 'Explicitly modeling importance and coherence for timeline summarization', 'On faithfulness and factuality in abstractive summarization', 'Abstractive text summarization using sequence-to-sequence RNNs and beyond', 'Annotated Gigaword', "Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization", 'A well-composed text is half done! composition sampling for diverse conditional generation', 'Planning with learned entity prompts for abstractive summarization', 'Better summarization evaluation with word embeddings for ROUGE', 'Show your work: Scratchpads for intermediate computation with language models', 'Training language models to follow instructions with human feedback', 'Overview of the tac 2011 summarization track: Guided task and aesop task', 'Bleu: a method for automatic evaluation of machine translation', 'The inverted pyramid—when and why did it appear?', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'COMET: A neural framework for MT evaluation', 'The new york times annotated corpus', 'Multitask prompted training enables zero-shot task generalization', 'BLEURT: Learning robust metrics for text generation', 'Language models are multilingual chain-of-thought reasoners', 'Learning to summarize with human feedback', 'Sequence to sequence learning with neural networks', 'Lamda: Language models for dialog applications', 'Attention is all you need', 'Pointer networks', 'Self-consistency improves chain of thought reasoning in language models', 'Emergent abilities of large language models', 'Chain of thought prompting elicits reasoning in large language models', 'PEGASUS: pre-training with extracted gap-sentences for abstractive summarization', 'Bertscore: Evaluating text generation with BERT', 'Benchmarking large language models for news summarization', 'HIBERT: Document level pre-training of hierarchical bidirectional transformers for document summarization', 'Automatic chain of thought prompting in large language models', 'Multimodal chain-of-thought reasoning in language models', 'MoverScore: Text generation evaluating with contextualized embeddings and earth mover distance', 'Least-to-most prompting enables complex reasoning in large language models'], 'kNN PROMPTING: BEYOND-CONTEXT LEARNING WITH CALIBRATION-FREE NEAREST NEIGHBOR INFERENCE': ['Language (technology) is power: A critical survey of “bias” in NLP', 'On the opportunities and risks of foundation models', 'Improving language models by retrieving from trillions of tokens', 'Language models are few-shot learners', 'Decoupling knowledge from memorization: Retrieval-augmented prompt learning', 'Meta-learning via language model in-context tuning', 'Palm: Scaling language modeling with pathways', 'Lamda: Language models for dialog applications', 'The pascal recognising textual entailment challenge', 'Why can gpt learn in-context? language models secretly perform gradient descent as meta optimizers', 'The commitmentbank: Investigating projection in naturally occurring discourse', 'A survey for in-context learning', 'Discriminatory analysis. nonparametric discrimination: Consistency properties', 'SimCSE: Simple contrastive learning of sentence embeddings', 'Mitigating gender bias in distilled language models via counterfactual role reversal', 'Generating sentences by editing prototypes', 'Measuring massive multitask language understanding', 'Deep learning scaling is predictable, empirically', "Surface form competition: Why the highest probability answer isn't always right", 'Mining and summarizing customer reviews', 'Few-shot learning with retrieval augmented language models', 'How can we know what language models know?', 'How can we know when language models know? on the calibration of language models for question answering', 'Learning to remember rare events', 'Generalization through memorization: Nearest neighbor language models', 'Nearest neighbor machine translation', 'Large language models are zero-shot reasoners', 'Retrieval-augmented generation for knowledge-intensive nlp tasks', 'Trans-encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations', 'What makes good in-context examples for GPT-3?', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'Noisy channel language model prompting for few-shot text classification', 'MetaICL: Learning to learn in context', 'StereoSet: Measuring stereotypical bias in pretrained language models', 'A simple cache model for image recognition', 'A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts', 'Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales', 'Deep k-nearest neighbors: Towards confident, interpretable and robust deep learning', 'Language models are unsupervised multitask learners', 'Scaling language models: Methods, analysis & insights from training gopher', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'Sentence-BERT: Sentence embeddings using Siamese BERTnetworks', 'A constructive prediction of the generalization error across scales', 'Learning to retrieve prompts for in-context learning', 'Multitask prompted training enables zero-shot task generalization', 'Exploiting cloze-questions for few-shot text classification and natural language inference', 'Nearest neighbor zero-shot inference', 'Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model', 'Recursive deep models for semantic compositionality over a sentiment treebank', 'Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'A simple method for commonsense reasoning', 'Improvements to bm25 and language models examined', 'Visualizing data using t-sne', 'Building a question answering test collection', 'Training data is more valuable than you think: A simple and effective method by retrieving from training data', 'Finetuned language models are zero-shot learners', 'Emergent abilities of large language models', 'Chain of thought prompting elicits reasoning in large language models', 'Retrieve and refine: Improved sequence generation models for dialogue', 'Annotating expressions of opinions and emotions in language', 'An explanation of in-context learning as implicit bayesian inference', 'Opt: Open pre-trained transformer language models', 'Character-level convolutional networks for text classification', 'Calibrate before use: Improving few-shot performance of language models'], 'MoT: Memory-of-Thought Enables ChatGPT to Self-Improve': ['Incontext examples selection for machine translation', 'Palm 2 technical report', 'On the dangers of stochastic parrots: Can language models be too big?', 'Language models are few-shot learners for prognostic prediction', 'Palm: Scaling language modeling with pathways', 'Scaling instruction-finetuned language models', 'BoolQ: Exploring the surprising difficulty of natural yes/no questions', 'Case-based reasoning for natural language queries over knowledge bases', 'A theory of unconscious thought', 'A survey for in-context learning', 'DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs', 'Metacognition', 'The role of consciousness in memory', 'Specializing smaller language models towards multi-step reasoning', 'Zerogen+: Self-guided high-quality data generation in efficient zero-shot learning', 'Large language models are reasoning teachers', 'Training compute-optimal large language models', 'Unnatural instructions: Tuning language models with (almost) no human labor', 'Incontext learning for few-shot dialogue state tracking', 'Large language models can self-improve', 'Towards reasoning in large language models: A survey', 'Language models (mostly) know what they know', 'Can language models learn from explanations in context?', 'Diverse demonstrations improve in-context compositional generalization', 'Self-prompting large language models for open-domain QA', 'Unified demonstration retriever for incontext learning', 'Finding supporting examples for in-context learning', 'Generating with confidence: Uncertainty quantification for black-box large language models', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'What makes good in-context examples for gpt-3?', 'Fastbert: a self-distilling BERT with adaptive inference time', 'Large language model guided tree-of-thought', 'Z-ICL: zero-shot in-context learning with pseudo-demonstrations', 'Teaching small language models to reason', 'Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models', 'Augmented language models: a survey', 'Can a suit of armor conduct electricity? a new dataset for open book question answering', 'Adversarial NLI: A new benchmark for natural language understanding', 'GPT-4 technical report', 'Training language models to follow instructions with human feedback', 'Measuring and narrowing the compositionality gap in language models', 'Pre-trained models for natural language processing: A survey', 'Sentence-bert: Sentence embeddings using siamese bert-networks', 'The probabilistic relevance framework: BM25 and beyond', 'Learning to retrieve prompts for in-context learning', 'Multitask prompted training enables zero-shot task generalization', 'The cognitive neuroscience of constructive memory: Remembering the past and imagining the future', 'Toolformer: Language models can teach themselves to use tools', 'Synthetic prompting: Generating chain-of-thought demonstrations for large language models', 'XRICL: cross-lingual retrieval-augmented in-context learning for cross-lingual text-to-sql semantic parsing', 'Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'Selective annotation makes language models better few-shot learners', 'One embedder, any task: Instruction-finetuned text embeddings', 'Unifying language learning paradigms', 'Simple Heuristics That Make Us Smart', 'Llama: Open and efficient foundation language models', 'Episodic memory: From mind to brain', 'Does it make sense? and why? A pilot study for sense making and explanation', 'Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models', 'Rationale-augmented ensembles in language models', 'Self-consistency improves chain of thought reasoning in language models', 'Self-instruct: Aligning language model with self generated instructions', 'Finetuned language models are zero-shot learners', 'Emergent abilities of large language models', 'Chain of thought prompting elicits reasoning in large language models', 'Large language models are reasoners with self-verification', 'Deebert: Dynamic early exiting for accelerating BERT inference', 'Zerogen: Efficient zero-shot learning via dataset generation', 'Progen: Progressive zero-shot dataset generation via in-context feedback', 'Compositional exemplars for in-context learning', 'Ground-truth labels matter: A deeper look into input-label demonstrations', 'Star: Bootstrapping reasoning with reasoning', 'OPT: open pre-trained transformer language models', 'Automatic chain of thought prompting in large language models', 'A survey of large language models', 'Progressive-hint prompting improves reasoning in large language models', 'Least-to-most prompting enables complex reasoning in large language models'], 'CHAIN-OF-TABLE: EVOLVING TABLES IN THE REASONING CHAIN FOR TABLE UNDERSTANDING': ['Table-to-text generation and pre-training with TabT5', 'Palm 2 technical report', 'Language models are few-shot learners', 'Webtables: Exploring the power of tables on the web', 'Large language models are few(1)-shot table reasoners', 'Tabfact: A large-scale dataset for table-based fact verification', 'Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks', 'Binding language models in symbolic languages', 'Bert: Pre-training of deep bidirectional transformers for language understanding', 'Handling divergent reference texts when evaluating table-to-text generation', 'Understanding tables with intermediate pre-training', 'PAL: Program-aided language models', 'PASTA: Table-operations aware fact verification via sentence-table cloze pre-training', 'Reasoning with language model is planning with world model', 'TaPas: Weakly supervised table parsing via pre-training', 'Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes', 'MathPrompter: Mathematical reasoning using large language models', 'OmniTab: Pretraining with natural and synthetic data for few-shot table-based question answering', 'A survey on table question answering: recent advances', 'Tab-cot: Zero-shot tabular chain of thought', 'A survey on deep learning approaches for text-to-sql', 'Decomposed prompting: A modular approach for solving complex tasks', 'ROUGE: A package for automatic evaluation of summaries', 'Lost in the middle: How language models use long contexts', 'TAPEX: Table pre-training via learning a neural sql executor', 'From zero to hero: Examining the power of symbolic tasks in instruction tuning', 'Benchmarking large language model capabilities for conditional generation', 'FeTaQA: Free-form table question answering', 'Lever: Learning to verify language-to-code generation with execution', 'Bleu: a method for automatic evaluation of machine translation', 'Compositional semantic parsing on semi-structured tables', "'favourite'sql-statements—an empirical analysis of sql-usage in commercial applications", 'Evaluating the text-to-sql capabilities of large language models', 'On the potential of lexico-logical alignments for semantic parsing to sql queries', "Large language models still can't plan (a benchmark for llms on planning and reasoning about change)", 'TUTA: Treebased transformers for generally structured table pre-training', 'Chain-of-thought prompting elicits reasoning in large language models', 'Tree of thoughts: Deliberate problem solving with large language models', 'Large language models are versatile decomposers: Decompose evidence and questions for table-based reasoning', 'Least-to-most prompting enables complex reasoning in large language models'], 'PROMPTAGATOR : FEW-SHOT DENSE RETRIEVAL FROM 8 EXAMPLES': ['Synthetic QA corpora generation with roundtrip consistency', 'Inpars: Unsupervised dataset generation for information retrieval', 'Language models are few-shot learners', 'Pre-training tasks for embedding-based large-scale retrieval', 'Maximum likelihood from incomplete data via the em algorithm', 'SPLADE v2: Sparse lexical and expansion model for information retrieval', 'Condenser: a pre-training architecture for dense retrieval', 'COIL: Revisit exact lexical match in information retrieval with contextualized inverted list', 'Making pre-trained language models better few-shot learners', 'Dbpedia-entity v2: A test collection for entity search', 'Improving efficient neural ranking models with cross-architecture knowledge distillation', 'Poly-encoders: Architectures and pre-training strategies for fast and accurate multi-sentence scoring', 'Unsupervised dense information retrieval with contrastive learning', 'Few-shot learning with retrieval augmented language models', 'Dense passage retrieval for open-domain question answering', 'ColBERT: Efficient and effective passage search via contextualized late interaction over BERT', 'Natural questions: A benchmark for question answering research', 'Latent retrieval for weakly supervised open domain question answering', 'Neural data augmentation via example extrapolation', 'PAQ: 65 million probably-asked questions and what you can do with them', 'Cutting down on prompts and parameters: Simple few-shot learning with language models', 'Multi-stage training with improved negative contrast for neural passage retrieval', 'Sparse, Dense, and Attentional Representations for Text Retrieval', 'Zero-shot neural passage retrieval via domain-targeted synthetic question generation', "Www'18 open challenge: financial opinion mining and question answering", 'Text and code embeddings by contrastive pre-training', 'Ms marco: A human generated machine reading comprehension dataset', 'Large dual encoders are generalizable retrievers', 'Passage re-ranking with bert', 'Document ranking with a pretrained sequence-to-sequence model', 'Domain-matched pre-training tasks for dense retrieval', 'RocketQA: An optimized training approach to dense passage retrieval for open-domain question answering', 'Rankdistil: Knowledge distillation for ranking', 'PAIR: Leveraging passage-centric similarity relation for improving dense passage retrieval', 'A thorough examination on zero-shot dense retrieval', 'No parameter left behind: How distillation and model size affect zero-shot retrieval', 'Improving passage retrieval with zero-shot question generation', 'Multitask prompted training enables zero-shot task generalization', 'ColBERTv2: Effective and efficient retrieval via lightweight late interaction', 'Exploiting cloze-questions for few-shot text classification and natural language inference', "It's not just size that matters: Small language models are also few-shot learners", 'Few-shot text generation with natural language instructions', 'End-to-end synthetic data generation for domain adaptation of question answering systems', 'BEIR: A heterogeneous benchmark for zero-shot evaluation of information retrieval models', 'Lamda: Language models for dialog applications', 'FEVER: a large-scale dataset for fact extraction and VERification', 'GPL: Generative pseudo labeling for unsupervised domain adaptation of dense retrieval', 'Finetuned language models are zero-shot learners', 'Emergent abilities of large language models', 'Approximate nearest neighbor negative contrastive learning for dense text retrieval', 'HotpotQA: A dataset for diverse, explainable multi-hop question answering', 'Learning discriminative projections for text similarity measures', 'Adversarial retriever-ranker for dense text retrieval'], 'Generated Knowledge Prompting for Commonsense Reasoning': ['Benchmarking knowledge-enhanced commonsense question answering via knowledge-to-text transformation', 'Dynamic neuro-symbolic knowledge graph construction for zero-shot commonsense question answering', 'COMET: Commonsense transformers for automatic knowledge graph construction', 'Language models are few-shot learners', 'Incorporating commonsense knowledge graph in pretrained models for social commonsense tasks', 'Commonsense knowledge mining from pretrained models', 'Training products of experts by minimizing contrastive divergence', 'The curious case of neural text degeneration', 'How can we know what language models know?', 'UNIFIEDQA: Crossing format boundaries with a single QA system', 'Qasc: A dataset for question answering via sentence composition', 'The measurement of observer agreement for categorical data', 'Explaining question answering models through text generation', 'KagNet: Knowledge-aware graph networks for commonsense reasoning', 'Birds have four legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-Trained Language Models', 'Unicorn on rainbow: A universal commonsense reasoning model on a new multitask benchmark', 'Graphbased reasoning over heterogeneous external knowledge for commonsense question answering', 'Towards generalizable neuro-symbolic systems for commonsense question answering', 'Knowledge-driven data construction for zero-shot evaluation in commonsense question answering', 'How additional knowledge can improve natural language commonsense question answering?', 'Prompting contrastive explanations for commonsense reasoning tasks', 'Language models as knowledge bases?', 'Zero-shot text classification with generative language models', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'Explain yourself! leveraging language models for commonsense reasoning', 'Atomic: An atlas of machine commonsense for if-then reasoning', 'Social IQa: Commonsense reasoning about social interactions', 'Exploiting cloze-questions for few-shot text classification and natural language inference', 'AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts', 'Unsupervised commonsense question answering with self-talk', 'Conceptnet 5.5: An open multilingual graph of general knowledge', 'CommonsenseQA: A question answering challenge targeting commonsense knowledge', 'Commonsenseqa 2.0: Exposing the limits of ai through gamification', 'A simple method for commonsense reasoning', 'Usc ink submission on numersense', 'Designing templates for eliciting commonsense knowledge from pretrained sequence-to-sequence models', 'QA-GNN: Reasoning with language models and knowledge graphs for question answering', 'Stanford submission on numersense', 'Improving question answering by commonsense-based pre-training'], "Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs": ['Have llms advanced enough? a challenging problem solving benchmark for large language models', 'Program synthesis with large language models', 'Adaptive importance sampling to accelerate training of a neural probabilistic language model', 'An adaptive sampling scheme to efficiently train fully convolutional networks for semantic segmentation', 'Optimal testing for crowd workers', 'Language models are few-shot learners', 'Codet: Code generation with generated tests', 'Frugalgpt: How to use large language models while reducing cost and improving performance', 'Evaluating large language models trained on code', 'Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality', 'Training verifiers to solve math word problems', 'Pomdp-based control of workflows for crowdsourcing', 'Maximum likelihood estimation of observer error-rates using the em algorithm', 'Crowdsourcing systems on the world-wide web', 'Reducing transformer depth on demand with structured dropout', 'Pal: Program-aided language models', 'Romebert: Robust training of multiexit bert', 'Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies', 'Measuring coding challenge competence with apps', 'Dynabert: Dynamic bert with adaptive width and depth', 'Top-kast: Top-k always sparse training', 'Large Language Models are Zero-Shot Reasoners', 'Solving quantitative reasoning problems with language models', 'Competition-level code generation with alphacode', 'Crowdsourcing control: Moving beyond multiple choice', 'Fastbert: a self-distilling bert with adaptive inference time', 'Automix: Automatically mixing language models', 'Learning performance-improving code edits', 'Flowgen: Fast and slow graph generation', 'A diverse corpus for evaluating and developing English math word problem solvers', 'Towards teachable reasoning systems: Using a dynamic memory of user feedback for continual system improvement', 'Revisiting prompt engineering via declarative crowdsourcing', 'Are nlp models really able to solve simple math word problems?', 'Sampling bias in deep active classification: An empirical study', 'Human computation: a survey and taxonomy of a growing field', 'Learning from crowds', 'Confident adaptive language modeling', 'Consistent accelerated inference via confident adaptive transformers', 'Datasets for Studying Generalization from Easy to Hard Examples', 'Can You Learn an Algorithm? Generalizing from Easy to Hard Problems with Recurrent Networks', 'Stanford alpaca: An instruction-following llama model', 'Llama: Open and efficient foundation language models', 'RationaleAugmented Ensembles in Language Models', 'Selfconsistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'Artificial intelligence and collective intelligence', 'The multidimensional wisdom of crowds', 'Hyperparameter estimation in dirichlet process mixture models', 'Whose vote should count more: Optimal integration of labels from labelers of unknown expertise', 'Deebert: Dynamic early exiting for accelerating bert inference', 'Early exit or not: Resource-efficient blind quality enhancement for compressed images', 'Adaptive computation with elastic input sequence', 'Bert loses patience: Fast and robust inference with early exit'], 'Language Models are Few-Shot Learners': ['Learning to learn by gradient descent by gradient descent', 'Massively multilingual neural machine translation', 'Language (technology) is power: A critical survey of “bias” in nlp', 'Sentiwordnet 3.0: an enhanced lexical resource for sentiment analysis and opinion mining', 'Experience grounds language', 'Estimating or propagating gradients through stochastic neurons for conditional computation', 'Multitask learning', 'Think you have solved question answering? try arc, the ai2 reasoning challenge', 'Generating long sequences with sparse transformers', 'Uniter: Learning universal image-text representations', 'The trouble with bias', 'BERT: Pretraining of deep bidirectional transformers for language understanding', 'Universal transformers', "Edinburgh's phrase-based machine translation systems for wmt-14", 'Semi-supervised sequence learning', 'Rl2: Fast reinforcement learning via slow reinforcement learning', 'Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs', 'Transformer-xl: Attentive language models beyond a fixed-length context', 'Understanding backtranslation at scale', 'Model-agnostic meta-learning for fast adaptation of deep networks', 'Lipstick on a pig: Debiasing methods cover up systematic gender biases in word embeddings but do not remove them', 'Adaptive computation time for recurrent neural networks', 'Annotation artifacts in natural language inference data', 'Gltr: Statistical detection and visualization of generated text', 'Meta-learning for low-resource neural machine translation', 'Ai and efficiency', 'Deep learning scaling is predictable, empirically', 'Distilling the knowledge in a neural network', 'Learning to Learn Using Gradient Descent', 'Reducing sentiment bias in language models via counterfactual evaluation', 'Automatic detection of generated text is easiest when humans are fooled', 'TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension', 'Numeric transformer - albert', 'TinyBERT: Distilling BERT for natural language understanding', 'Technical report on conversational question answering', 'Unifiedqa: Crossing format boundaries with a single qa system', "All the news that's fit to fabricate: Ai-generated text as a tool of media misinformation", 'Scaling laws for neural language models', 'Natural questions: a benchmark for question answering research', 'Sequence-level knowledge distillation', 'Nltk: The natural language toolkit', 'Cross-lingual language model pretraining', 'ALBERT: A lite BERT for self-supervised learning of language representations', 'Adversarial training for large neural language models', 'SummAE: Zero-shot abstractive text summarization using length-agnostic auto-encoders', 'Story ending prediction by transferable bert', 'Multilingual denoising pre-training for neural machine translation', 'Representation learning using multi-task deep neural networks for semantic classification and information retrieval', 'Improving multi-task deep neural networks via knowledge distillation for natural language understanding', 'Multi-task deep neural networks for natural language understanding', 'Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension', 'Learning to optimize neural nets', 'RoBERTa: A robustly optimized BERT pretraining approach', 'Retrieval-augmented generation for knowledge-intensive nlp tasks', 'Train large, then compress: Rethinking model size for efficient training and inference of transformers', 'A corpus and evaluation framework for deeper understanding of commonsense stories', 'An empirical model of large-batch training', 'The penn treebank: annotating predicate argument structure', 'The natural language decathlon: Multitask learning as question answering', 'Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference', 'Model cards for model reporting', 'Stereoset: Measuring stereotypical bias in pretrained language models', 'Probing neural network comprehension of natural language arguments', 'Fair is better than sensational: Man is to doctor as woman is to doctor', 'Fascha', 'Sentence encoders on STILTs: Supplementary training on intermediate labeled-data tasks', 'The lambada dataset: Word prediction requiring a broad discourse context', 'A call for clarity in reporting BLEU scores', 'Reducing gender bias in word-level language models with a gender-equalizing loss function', 'Coqa: A conversational question answering challenge', 'Few-shot autoregressive density estimation: Towards learning to learn distributions', 'Optimization as a model for few-shot learning', 'NumNet: Machine reading comprehension with numerical reasoning', 'Gender bias in coreference resolution', 'Guide for conducting risk assessments', 'A constructive prediction of the generalization error across scales', 'How much knowledge can you pack into the parameters of a language model?', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'Language models are unsupervised multitask learners', 'Release strategies and the social impacts of language models', 'The woman worked as a babysitter: On biases in language generation', 'DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter', 'Green AI', 'Improving neural machine translation models with monolingual data', 'Outrageously large neural networks: The sparsely-gated mixture-of-experts layer', 'Megatron-lm: Training multi-billion parameter language models using model parallelism', 'Exploiting cloze questions for few-shot text classification and natural language inference', 'MASS: Masked sequence to sequence pre-training for language generation', 'Matching Networks for One Shot Learning', 'Attention is all you need', 'Superglue: A stickier benchmark for general-purpose language understanding systems', 'Multi-agent dual learning', 'Unsupervised data augmentation for consistency training', 'XLNet: Generalized autoregressive pretraining for language understanding', 'Hellaswag: Can a machine really finish your sentence?', 'Defending against neural fake news', 'Fine-tuning language models from human preferences'], 'Boosting Language Models Reasoning with Chain-of-Knowledge Prompting': ['Logic-guided data augmentation and regularization for consistent question answering', 'Training a helpful and harmless assistant with reinforcement learning from human feedback', 'Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'Language models are few-shot learners', 'Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks', 'Meta-learning via language model in-context tuning', 'Palm: Scaling language modeling with pathways', 'BoolQ: Exploring the surprising difficulty of natural yes/no questions', 'Think you have solved question answering? try arc, the ai2 reasoning challenge', 'Training verifiers to solve math word problems', 'BERT: pre-training of deep bidirectional transformers for language understanding', 'A survey for in-context learning', 'Pal: Program-aided language models', 'Simcse: Simple contrastive learning of sentence embeddings', 'Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies', 'Inductive and deductive reasoning', 'Accelerating large-scale inference with anisotropic vector quantization', 'Large language models can self-improve', 'Towards faithfully interpretable NLP systems: How should we define and evaluate faithfulness?', 'Survey of hallucination in natural language generation', 'Large language models are zero-shot reasoners', 'Internet-augmented dialogue generation', 'Making language models better reasoners with step-aware verifier', 'Guided generation of cause and effect', 'Learning entity and relation embeddings for knowledge graph completion', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'What makes good in-context examples for GPT-3?', 'Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing', "Mind's eye: Grounded language model reasoning through simulation", 'Chameleon: Plug-and-play compositional reasoning with large language models', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'Faithful chain-of-thought reasoning', 'Can a suit of armor conduct electricity? a new dataset for open book question answering', 'Metaicl: Learning to learn in context', 'Rethinking the role of demonstrations: What makes in-context learning work?', 'GLUCOSE: GeneraLized and COntextualized story explanations', 'Webgpt: Browser-assisted question-answering with human feedback', 'What in-context learning “learns” in-context: Disentangling task recognition and task learning', 'Knowledge-incontext: Towards knowledgeable semi-parametric language models', 'Are NLP models really able to solve simple math word problems?', "How context affects language models' factual predictions", 'Scaling language models: Methods, analysis & insights from training gopher', 'Solving general arithmetic word problems', 'Atomic: An atlas of machine commonsense for if-then reasoning', 'Bloom: A 176b-parameter open-access multilingual language model', 'Toolformer: Language models can teach themselves to use tools', 'On the effect of pretraining corpora on in-context learning by a large-scale language model', 'Prompting GPT-3 to be reliable', 'Conceptnet 5.5: An open multilingual graph of general knowledge', 'CommonsenseQA: A question answering challenge targeting commonsense knowledge', 'Lamda: Language models for dialog applications', 'Llama: Open and efficient foundation language models', 'Towards understanding chain-of-thought prompting: An empirical study of what matters', 'Kepler: A unified model for knowledge embedding and pre-trained language representation', 'Rationale-augmented ensembles in language models', 'Self-consistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'The unreliability of explanations in few-shot prompting for textual reasoning', "Do large language models know what they don't know?", 'Ground-truth labels matter: A deeper look into input-label demonstrations', 'ASER: A large-scale eventuality knowledge graph', 'ASER: towards large-scale commonsense knowledge acquisition via higher-order selectional preference over eventualities', 'Opt: Open pre-trained transformer language models', 'Automatic chain of thought prompting in large language models', 'Calibrate before use: Improving few-shot performance of language models', 'Least-to-most prompting enables complex reasoning in large language models'], 'Tree of Thoughts: Deliberate Problem Solving with Large Language Models': ['Language models are few-shot learners', 'A survey of monte carlo tree search methods', 'Deep blue', 'Teaching large language models to self-debug', 'Palm: Scaling language modeling with pathways', 'Faithful reasoning using large language models', 'Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control', 'Pal: Program-aided language models', 'Reasoning with language model is planning with world model', 'A formal basis for the heuristic determination of minimum cost paths', 'Language models as zero-shot planners: Extracting actionable knowledge for embodied agents', 'Inner monologue: Embodied reasoning through planning with language models', 'Maieutic prompting: Logically consistent reasoning with recursive explanations', 'Thinking, fast and slow', 'Representativeness revisited: Attribute substitution in intuitive judgment', 'Language models can solve computer tasks', 'Llm+p: Empowering large language models with optimal planning proficiency', 'Neurologic a*esque decoding: Constrained text generation with lookahead heuristics', 'Self-refine: Iterative refinement with self-feedback', 'Report on a general problem solving program', 'Human problem solving', 'Gpt-4 technical report', 'Refiner: Reasoning feedback on intermediate representations', 'Improving language understanding by generative pre-training', 'Language models are unsupervised multitask learners', 'Large language model programs', 'Reflexion: an autonomous agent with dynamic memory and self-reflection', 'Mastering the game of go without human knowledge', 'The empirical case for two systems of reasoning', 'Who is rational? Studies of individual differences in reasoning', 'Llama: Open and efficient foundation language models', 'Chai: A chatbot ai for task-oriented dialogue with offline reinforcement learning', 'Automated crossword solving', 'Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models', 'Self-consistency improves chain of thought reasoning in language models', 'Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents', 'Chain of thought prompting elicits reasoning in large language models', 'Decomposition enhances reasoning via self-evaluation guided decoding', 'Foundation models for decision making: Problems, methods, and opportunities', 'ReAct: Synergizing reasoning and acting in language models', 'Planning with large language models for code generation', 'Least-to-most prompting enables complex reasoning in large language models', 'Solving math word problem via cooperative reasoning induced language models'], 'Demystifying Prompts in Language Models via Perplexity Estimation': ['Promptsource: An integrated development environment and repository for natural language prompts', 'TweetEval: Unified Benchmark and Comparative Evaluation for Tweet Classification', 'Language models are few-shot learners', 'On the relation between sensitivity and accuracy in in-context learning', 'No language left behind: Scaling human-centered machine translation', 'Northeuralex: a wide-coverage lexical database of northern eurasia', 'Rlprompt: Optimizing discrete text prompts with reinforcement learning', "Measuring causal effects of data statistics on language model's 'factual' predictions", 'Making pre-trained language models better few-shot learners', 'Orca: Interpreting prompted language models via locating supporting data evidence in the ocean of pretraining data', "Surface form competition: Why the highest probability answer isn't always right", 'Large language models struggle to learn long-tail knowledge', "Reframing instructional prompts to gptk's language", 'Prompt waywardness: The curious case of discretized interpretation of continuous prompts', 'How many data points is a prompt worth?', 'Dbpedia-a large-scale, multilingual knowledge base extracted from wikipedia', 'The power of scale for parameter-efficient prompt tuning', 'Prefix-tuning: Optimizing continuous prompts for generation', 'Estimating the carbon footprint of bloom, a 176b parameter language model', 'Learning word vectors for sentiment analysis', 'Wordnet: a lexical database for english', 'Multi-source social feedback of online news feeds', 'Learning how to ask: Querying lms with mixtures of soft prompts', 'Impact of pretraining term frequencies on few-shot reasoning', 'CARER: Contextualized affect representations for emotion recognition', "It's not just size that matters: Small language models are also few-shot learners", "Toward human readable prompt tuning: Kubrick's the shining is a good movie, and a good prompt too?", 'Autoprompt: Eliciting knowledge from language models with automatically generated prompts', 'Neural network acceptability judgments', 'Learning paraphrastic sentence embeddings from back-translated bitext', 'Opt: Open pre-trained transformer language models', 'Character-level convolutional networks for text classification'], 'Self-Evaluation Guided Beam Search for Reasoning': ['A learning algorithm for boltzmann machines', 'Language models are few-shot learners', 'Language gans falling short', 'Evaluating large language models trained on code', 'Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks', 'Palm: Scaling language modeling with pathways', 'Training verifiers to solve math word problems', 'Hierarchical neural story generation', 'PAL: program-aided language models', 'Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies', 'Sequence transduction with recurrent neural networks', 'On calibration of modern neural networks', 'Long text generation via adversarial training with leaked information', 'The curious case of neural text degeneration', 'Large language models can self-improve', 'How can we know When language models know? on the calibration of language models for question answering', 'Speech and language processing : an introduction to natural language processing, computational linguistics, and speech recognition', 'Language models (mostly) know what they know', 'Large language models are zero-shot reasoners', 'Stochastic beams and where to find them: The gumbel-top-k trick for sampling sequences without replacement', 'Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation', 'Solving quantitative reasoning problems with language models', 'On the advance of making language models better reasoners', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning', 'Self-refine: Iterative refinement with self-feedback', 'Conditional poisson stochastic beam search', 'Best-first beam search', 'A diverse corpus for evaluating and developing english math word problem solvers', 'Show your work: Scratchpads for intermediate computation with language models', 'GPT-4 technical report', 'Are NLP models really able to solve simple math word problems?', 'REFINER: reasoning feedback on intermediate representations', 'Scaling language models: Methods, analysis & insights from training gopher', 'Reflexion: an autonomous agent with dynamic memory and self-reflection', 'Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'On NMT search errors and model errors: Cat got your tongue?', 'CommonsenseQA: A question answering challenge targeting commonsense knowledge', 'Llama: Open and efficient foundation language models', 'Llama 2: Open foundation and fine-tuned chat models', 'Solving math word problems with process- and outcome-based feedback', 'Shepherd pre-trained language models to develop a train of thought: An iterative prompting approach', 'Self-consistency improves chain of thought reasoning in language models', 'Consistency of a recurrent language model with respect to incomplete decoding', 'Exploiting reasoning chains for multi-hop science question answering', 'Human parity on commonsenseQA: Augmenting self-attention with external attention', 'HotpotQA: A dataset for diverse, explainable multi-hop question answering', 'The unreliability of explanations in few-shot prompting for textual reasoning', 'Diversifying content generation for commonsense reasoning with mixture of knowledge graph experts', 'Calibrate before use: Improving few-shot performance of language models', 'Least-to-most prompting enables complex reasoning in large language models', 'Towards interpretable natural language understanding with explanations as latent variables'], 'Making Large Language Models Better Reasoners with Step-Aware Verifier': ['Giving BERT a calculator: Finding operations and arguments with reading comprehension', 'Logic-guided data augmentation and regularization for consistent question answering', 'Commonsense for generative multi-hop question answering tasks', 'Abductive commonsense reasoning', 'Language models are few-shot learners', 'Zero-shot transfer learning with synthesized data for multidomain dialogue state tracking', 'HybridQA: A dataset of multi-hop question answering over tabular and textual data', 'Palm: Scaling language modeling with pathways', 'Training verifiers to solve math word problems', 'Selection-inference: Exploiting large language models for interpretable logical reasoning', 'ReasonBERT: Pretrained to reason with distant supervision', 'Cognitive graph for multi-hop reading comprehension at scale', 'DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs', 'Scalable multi-hop relational reasoning for knowledge-aware question answering', 'Injecting numerical reasoning skills into language models', 'Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies', 'Towards a unified view of parameter-efficient transfer learning', 'Deberta: Decoding-enhanced bert with disentangled attention', "Surface form competition: Why the highest probability answer isn't always right", 'Parameter-efficient transfer learning for nlp', 'Lora: Low-rank adaptation of large language models', 'A multi-type multi-span network for reading comprehension that requires discrete reasoning', 'A good prompt is worth millions of parameters: Low-resource prompt-based learning for vision-language models', 'Large language models are zero-shot reasoners', 'Parsing algebraic word problems into equations', 'Exploiting explicit paths for multi-hop reading comprehension', 'Can language models learn from explanations in context?', 'How many data points is a prompt worth?', 'KagNet: Knowledge-aware graph networks for commonsense reasoning', 'What makes good in-context examples for GPT3?', 'Logiqa: A challenge dataset for machine reading comprehension with logical reasoning', 'Roberta: A robustly optimized bert pretraining approach', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'A diverse corpus for evaluating and developing english math word problem solvers', 'Knowledgeable reader: Enhancing cloze-style reading comprehension with external commonsense knowledge', 'Metaicl: Learning to learn in context', 'Rethinking the role of demonstrations: What makes in-context learning work?', 'Are nlp models really able to solve simple math word problems?', 'Reasoning like program executors', 'Language models are unsupervised multitask learners', 'Solving general arithmetic word problems', 'Learning to retrieve prompts for in-context learning', 'Generate & rank: A multi-task framework for math word problems', 'Clutrr: A diagnostic benchmark for inductive reasoning from text', 'Commonsenseqa: A question answering challenge targeting commonsense knowledge', 'Logic-driven context extension and data augmentation for logical reasoning of text', 'Improving natural language inference using external knowledge in the science questions domain', 'Multi-level recommendation reasoning over knowledge graphs with reinforcement learning', 'Self-consistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'Human parity on commonsenseqa: Augmenting self-attention with external attention', 'HotpotQA: A dataset for diverse, explainable multi-hop question answering', 'Turning tables: Generating examples from semistructured tables for endowing language models with reasoning skills', 'Reclor: A reading comprehension dataset requiring logical reasoning', 'Star: Bootstrapping reasoning with reasoning', 'SWAG: A large-scale adversarial dataset for grounded commonsense inference', 'Calibrate before use: Improving few-shot performance of language models', 'Least-to-most prompting enables complex reasoning in large language models', 'Tat-qa: A question answering benchmark on a hybrid of tabular and textual content in finance'], 'Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference': ['Snowball: Extracting relations from large plain-text collections', 'Semi-supervised bootstrapping of relationship extractors with distributional semantics', 'Inducing relational knowledge from BERT', 'Extracting patterns and relations from the world wide web', 'MixText: Linguistically-informed interpolation of hidden space for semi-supervised text classification', 'An embarrassingly simple approach for transfer learning from pretrained language models', 'Unsupervised cross-lingual representation learning at scale', 'Commonsense knowledge mining from pretrained models', 'BERT: Pre-training of deep bidirectional transformers for language understanding', 'Investigating meta-learning algorithms for low-resource natural language understanding tasks', 'What BERT is not: Lessons from a new suite of psycholinguistic diagnostics for language models', 'Meta-learning for low-resource neural machine translation', 'On calibration of modern neural networks', 'Revisiting self-training for neural sequence generation', 'Distilling the knowledge in a neural network', 'Iterative backtranslation for neural machine translation', 'Universal language model fine-tuning for text classification', 'Self-training PCFG grammars with latent annotations across languages', 'How can we know what language models know?', 'Negated and misprimed probes for pretrained language models: Birds can talk, but cannot fly', 'RoBERTa: A robustly optimized BERT pretraining approach', 'The natural language decathlon: Multitask learning as question answering', 'Effective self-training for parsing', 'Argumentative relation classification as plausibility ranking', 'Automatic differentiation in PyTorch', 'Language models as knowledge bases?', 'Zero-shot text classification with generative language models', 'Domain adaptive dialog generation via meta learning', 'Improving language understanding by generative pre-training', 'Language models are unsupervised multitask learners', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'Self-training for enhancement and domain adaptation of statistical parsers trained on small datasets', 'An embarrassingly simple approach to zero-shot learning', 'WinoGrande: An adversarial winograd schema challenge at scale', 'Rare words: A major problem for contextualized embeddings and how to fix it by attentive mimicking', 'Improving neural machine translation models with monolingual data', 'Zero-shot learning of classifiers from natural language quantification', 'How to fine-tune BERT for text classification?', 'oLMpics – on what language model pre-training captures', 'A simple method for commonsense reasoning', 'X-stance: A multilingual multi-target dataset for stance detection', 'Improving language understanding by generative pre-training', 'Unsupervised data augmentation for consistency training', 'XLNet: Generalized autoregressive pretraining for language understanding', 'Unsupervised word sense disambiguation rivaling supervised methods', 'Zero-shot text classification: Datasets, evaluation and entailment approach', 'Benchmarking zero-shot text classification: Datasets, evaluation and entailment approach', 'Diverse few-shot text classification with multiple metrics', 'Character-level convolutional networks for text classification'], 'PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents': ['Language models are few-shot learners', 'Long context question answering via supervised contrastive learning', 'Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks', 'Scaling instruction-finetuned language models', 'Training verifiers to solve math word problems', 'A dataset of information-seeking questions and answers anchored in research papers', 'Successive prompting for decomposing complex questions', 'Pal: Program-aided language models', 'Constructing inferences during narrative text comprehension', 'Large language models can self-improve', 'Towards reasoning in large language models: A survey', 'Decomposed prompting: A modular approach for solving complex tasks', 'Language models can solve computer tasks', 'The NarrativeQA reading comprehension challenge', 'Hurdles to progress in long-form question answering', 'Natural questions: A benchmark for question answering research', 'Large language model guided tree-of-thought', 'Chameleon: Plug-and-play compositional reasoning with large language models', 'Self-refine: Iterative refinement with self-feedback', 'Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning', 'Gpt-4 technical report', 'Training language models to follow instructions with human feedback', 'QuALITY: Question answering with long input texts, yes!', 'Measuring and narrowing the compositionality gap in language models', 'Summarization programs: Interpretable abstractive summarization with neural modular trees', 'Toolformer: Language models can teach themselves to use tools', 'SCROLLS: Standardized CompaRison over long language sequences', 'Reflexion: an autonomous agent with dynamic memory and self-reflection', 'ASQA: Factoid questions meet long-form answers', 'Self-checkgpt: Zero-resource black-box hallucination detection for generative large language models', 'Augmented language models: a survey', 'ConditionalQA: A complex reading comprehension dataset with conditional answers', 'Iterative hierarchical attention for answering complex questions over long documents', 'CommonsenseQA: A question answering challenge targeting commonsense knowledge', 'Llama: Open and efficient foundation language models', 'Asking and answering questions to evaluate the factual consistency of summaries', 'Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models', 'Self-consistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'How do we answer complex questions: Discourse structure of long-form answers', 'Tree of thoughts: Deliberate problem solving with large language models', 'React: Synergizing reasoning and acting in language models', 'Answering questions by meta-reasoning over multiple chains of thought', 'OPT: Open pretrained transformer language models', 'Least-to-most prompting enables complex reasoning in large language models'], 'PAL: Program-aided Language Models': ['Do as I Can, not as I Say: Grounding Language in Robotic Affordances', 'MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms', 'Giving bert a calculator: Finding operations and arguments with reading comprehension', 'Language Models are Few-Shot Learners', 'Evaluating Large Language Models Trained on Code', 'Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks', 'Binding language models in symbolic languages', 'PaLM: Scaling Language Modeling with Pathways', 'Training Verifiers to Solve Math Word Problems', 'Just add functions: A neural-symbolic language model', 'Language model cascades', 'Neurosymbolic ai: the 3rd wave', 'The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics', 'An investigation of procedure and variable names as beacons during program comprehension', 'Injecting numerical reasoning skills into language models', 'Neural module networks for reasoning over text', 'Measuring mathematical problem solving with the MATH dataset', 'The Curious Case of Neural Text Degeneration', 'Mawps: A math word problem repository', 'Solving quantitative reasoning problems with language models', 'Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems', 'Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing', 'Text and patterns: For effective chain of thought, it takes two to tango', 'Language models of code are few-shot commonsense learners', 'Deep learning: A critical appraisal', 'The next decade in ai: four steps towards robust artificial intelligence', 'A diverse corpus for evaluating and developing English math word problem solvers', 'Lila: A unified benchmark for mathematical reasoning', 'Investigating the limitations of transformers with simple arithmetic tasks', 'Show your Work: Scratchpads for Intermediate Computation with Language Models', 'Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning', 'Are NLP Models Really Able to Solve Simple Math Word Problems?', 'Reasoning like program executors', 'Limitations of language models in arithmetic and symbolic induction', 'A Recipe for Arbitrary Text Style Transfer with Large Language Models', 'Multitask Prompted Training Enables Zero-Shot Task Generalization', 'Few-shot semantic parsing with language models trained on code', 'Constrained language models yield few-shot semantic parsers', 'Challenging big-bench tasks and whether chain-of-thought can solve them', 'The effects of comments and identifier names on program comprehensibility: an experimental investigation', 'Rationale-Augmented Ensembles in Language Models', 'Self-Consistency Improves Chain of Thought Reasoning in Language Models', 'Finetuned Language Models are Zero-shot Learners', 'Chain of Thought Prompting Elicits Reasoning in Large Language Models', 'Autoformalization with Large Language Models', 'React: Synergizing reasoning and acting in language models', 'Least-to-Most Prompting Enables Complex Reasoning in Large Language Models'], 'STaR: Self-Taught Reasoner Bootstrapping Reasoning With Reasoning': ['The principles of psychology, volume 1', 'Protocol analysis: Verbal reports as data', 'Explain yourself! leveraging language models for commonsense reasoning', 'Unsupervised commonsense question answering with self-talk', 'Show your work: Scratchpads for intermediate computation with language models', 'Chain of thought prompting elicits reasoning in large language models', 'Few-shot self-rationalization with natural language prompts', 'Can language models learn from explanations in context?', 'Training verifiers to solve math word problems', 'Commonsenseqa: A question answering challenge targeting commonsense knowledge', 'Language models are few-shot learners', 'Finetuned language models are zero-shot learners', 'An explanation of in-context learning as implicit bayesian inference', 'In-context learning and induction heads', 'The power of scale for parameter-efficient prompt tuning', 'Formal mathematics statement curriculum learning', 'The lean theorem prover (system description)', 'Generative language modeling for automated theorem proving', 'Towards interpretable natural language understanding with explanations as latent variables', 'Sub-task decomposition enables learning in sequence to sequence tasks', 'Thinking fast and slow with deep learning and tree search', 'Iterated learning for emergent systematicity in vqa', 'Learning context-dependent mappings from sentences to logical form', 'Weakly supervised semantic parsing with abstract examples', 'From language to programs: Bridging reinforcement learning and maximum marginal likelihood', 'e-snli: Natural language inference with natural language explanations', 'Generate natural language explanations for recommendation', 'Proximal policy optimization algorithms', 'Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer Language Model with JAX', 'Rethinking the role of demonstrations: What makes in-context learning work?', 'Conceptnet 5.5: An open multilingual graph of general knowledge', 'Human parity on commonsenseqa: Augmenting self-attention with external attention', 'Lamda: Language models for dialog applications', 'Prolific.ac—a subject pool for online experiments', 'Selfconsistency improves chain of thought reasoning in language models', 'Explanation in artificial intelligence: Insights from the social sciences', 'The promise and peril of human evaluation for model interpretability', 'Towards faithfully interpretable nlp systems: How should we define and evaluate faithfulness?', 'Palm: Scaling language modeling with pathways', 'Solving quantitative reasoning problems with language models', 'The pile: An 800gb dataset of diverse text for language modeling', 'Adam: A method for stochastic optimization'], 'Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks': ['MS MARCO: A Human Generated MAchine Reading COmprehension Dataset', 'Modeling of the question answering task in the yodaqa system', 'Semantic Parsing on Freebase from Question-Answer Pairs', 'Palm: Pre-training an autoencoding&autoregressive language model for context-conditioned generation', 'Reading Wikipedia to Answer Open-Domain Questions', 'Coarse-to-fine question answering for long documents', 'Simple and Effective Multi-Paragraph Reading Comprehension', 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding', 'Wizard of wikipedia: Knowledge-powered conversational agents', 'SearchQA: A New Q&A Dataset Augmented with Context from a Search Engine', 'Hierarchical neural story generation', 'ELI5: Long form question answering', 'Augmenting transformers with KNN-based composite memory', 'Entities as experts: Sparse memory access with entity supervision', 'A knowledge-grounded neural conversation model', 'When will AI exceed human performance? evidence from AI experts', 'Search engine guided neural machine translation', 'Generating sentences by editing prototypes', 'REALM: Retrieval-augmented language model pre-training', 'A retrieve-and-edit framework for predicting structured outputs', 'Simple and effective retrieve-edit-rerank text generation', 'Billion-scale similarity search with gpus', 'TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension', 'Inferring algorithmic patterns with stackaugmented recurrent nets', 'Dense passage retrieval for open-domain question answering', 'Generalization through memorization: Nearest neighbor language models', 'Adam: A method for stochastic optimization', 'Natural Questions: a Benchmark for Question Answering Research', 'Large memory layers with product keys', 'Latent retrieval for weakly supervised open domain question answering', 'BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension', 'A diversity-promoting objective function for neural conversation models', 'Acute-eval: Improved dialogue evaluation with optimized questions and multi-turn comparisons', 'Robust neural machine translation with joint textual and phonetic embedding', 'Generating wikipedia by summarizing long sequences', 'Efficient and robust approximate nearest neighbor search using hierarchical navigable small world graphs', 'The next decade in ai: four steps towards robust artificial intelligence', 'How decoding strategies affect the verifiability of generated text', 'Mixed precision training', 'Towards exploiting background knowledge for building conversation systems', 'Towards a better metric for evaluating question generation systems', 'MS MARCO: A human generated machine reading comprehension dataset', 'Passage re-ranking with BERT', 'fairseq: A fast, extensible toolkit for sequence modeling', 'Finding generalizable evidence by learning to convince q&a models', 'Language models as knowledge bases?', "How context affects language models' factual predictions", 'Improving Language Understanding by Generative Pre-Training', 'Language models are unsupervised multitask learners', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'How much knowledge can you pack into the parameters of a language model?', 'The probabilistic relevance framework: Bm25 and beyond', 'Release strategies and the social impacts of language models', 'End-to-end memory networks', 'FEVER: a large-scale dataset for fact extraction and VERification', 'Avoiding catastrophic forgetting in mitigating model biases in sentence-pair classification with elastic weight consolidation', 'Attention is all you need', 'Diverse beam search for improved description of complex scenes', 'GLUE: A multi-task benchmark and analysis platform for natural language understanding', 'SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding Systems', 'R3: Reinforced ranker-reader for open-domain question answering', 'Evidence aggregation for answer reranking in open-domain question answering', 'Memory networks', 'Retrieve and refine: Improved sequence generation models for dialogue', "Huggingface's transformers: State-of-the-art natural language processing", 'Addressing semantic drift in question generation for semi-supervised question answering', 'Reasoning over semantic-level graph for fact checking'], 'COMPOSITIONAL SEMANTIC PARSING WITH LARGE LANGUAGE MODELS': ['Do as I can, not as I say: Grounding language in robotic affordances', 'Lexicon learning for few shot sequence modeling', 'Learning to recombine and resample data for compositional generalization', 'Good-enough compositional data augmentation', 'CLOSURE: Assessing systematic generalization of CLEVR models', 'Language models are few-shot learners', 'Extracting training data from large language models', 'Compositional generalization via neural-symbolic stack machines', 'Syntactic structures', 'Palm: Scaling language modeling with pathways', 'Meta-learning to compositionally generalize', 'The compositionality papers', 'Compositional generalization in semantic parsing: Pre-training vs. specialized architectures', 'Grounded graph decoding improves compositional generalization in question answering', 'Measuring and improving compositional generalization in text-to-SQL via component alignment', 'Permutation equivariant models for compositional generalization in language', 'Hierarchical poset decoding for compositional generalization in language', 'Span-based semantic parsing for compositional generalization', 'Unlocking compositional generalization in pre-trained models using intermediate representations', 'CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning', 'Measuring compositional generalization: A comprehensive method on realistic data', 'COGS: A compositional generalization challenge based on semantic interpretation', 'Sequence-to-sequence learning with latent neural grammars', 'Thieves on sesame street! Model extraction of bert-based apis', 'Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks', 'Compositional generalization through meta sequence-to-sequence learning', 'Building machines that learn and think like people', 'On the advance of making language models better reasoners', 'Compositional generalization for primitive substitutions', 'Compositional generalization by learning analytical expressions', 'Rearranging the familiar: Testing compositional generalization in recurrent networks', 'Universal grammar', 'Compositional generalization in image captioning', 'Learning compositional rules via neural program synthesis', 'Training language models to follow instructions with human feedback', 'Improving compositional generalization with latent structure and data augmentation', 'Evaluating the impact of model scale for compositional generalization in semantic parsing', 'A benchmark for systematic generalization in grounded language understanding', 'Compositional generalization in a deep seq2seq model by separating syntax and semantics', 'Compositional generalization and natural language variation: Can a semantic parsing approach handle both?', 'Natural language to code translation with execution', 'An introduction to unification-based approaches to grammar', 'Few-shot semantic parsing with language models trained on code', 'Constrained language models yield few-shot semantic parsers', 'Self-consistency improves chain of thought reasoning in language models', 'Emergent abilities of large language models', 'Chain of thought prompting elicits reasoning in large language models', 'Learning synchronous grammars for semantic parsing with lambda calculus', 'SEQZERO: Few-shot compositional semantic parsing with sequential prompts and zero-shot models', 'Compositional generalization for neural semantic parsing via span-level supervised attention', 'STaR: Bootstrapping reasoning with reasoning', 'Least-to-most prompting enables complex reasoning in large language models'], 'CHAIN-OF-NOTE: ENHANCING ROBUSTNESS IN RETRIEVAL-AUGMENTED LANGUAGE MODELS': ['Semantic parsing on freebase from question-answer pairs', 'Improving language models by retrieving from trillions of tokens', 'Reading wikipedia to answer open-domain questions', 'Unitedqa: A hybrid approach for open domain question answering', 'Selection-inference: Exploiting large language models for interpretable logical reasoning', 'Time-aware language models as temporal knowledge bases', 'Chain-of-verification reduces hallucination in large language models', 'Realm: Retrieval-augmented language model pre-training', 'Chain of explanation: New prompting method to generate quality natural language explanation for implicit hate speech', 'Leveraging passage retrieval with generative models for open domain question answering', 'Few-shot learning with retrieval augmented language models', 'Survey of hallucination in natural language generation', 'Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension', 'Dense passage retrieval for open-domain question answering', "Realtime qa: What's the answer right now?", 'Generalization through memorization: Nearest neighbor language models', 'Large language models are zero-shot reasoners', 'Natural questions: A benchmark for question answering research', 'Internet-augmented language models through few-shot prompting for open-domain question answering', 'Retrieval-augmented generation for knowledge-intensive nlp tasks', 'Are chatgpt and gpt-4 general-purpose solvers for financial text analytics? an examination on several typical tasks', 'Zero-shot neural passage retrieval via domain-targeted synthetic question generation', 'Chain-of-skills: A configurable model for open-domain question answering', 'When not to trust language models: Investigating effectiveness and limitations of parametric and non-parametric memories', 'Gpt-4 technical report', 'Is chatgpt a general-purpose natural language processing task solver?', 'Rocketqa: An optimized training approach to dense passage retrieval for open-domain question answering', 'Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters', 'Questions are all you need to train a dense passage retriever', 'Large language models can be easily distracted by irrelevant context', 'Language models are multilingual chain-of-thought reasoners', 'Replug: Retrieval-augmented black-box language models', 'End-to-end training of multi-document reader and retriever for open-domain question answering', 'Llama 2: Open foundation and fine-tuned chat models', 'Interleaving retrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions', 'Freshllms: Refreshing large language models with search engine augmentation', 'Boosting language models reasoning with chain-of-knowledge prompting', 'Knowledge-driven cot: Exploring faithful reasoning in llms for knowledge-intensive question answering', 'Chain of thought prompting elicits reasoning in large language models', 'Making retrieval-augmented language models robust to irrelevant context', 'Kg-fid: Infusing knowledge graph in fusion-in-decoder for open-domain question answering', 'A survey of knowledge-enhanced text generation', 'Generate rather than retrieve: Large language models are strong context generators', 'Improving language models via plug-and-play retrieval feedback', "Siren's song in the ai ocean: A survey on hallucination in large language models", 'Multimodal chain-of-thought reasoning in language models', 'Training language models with memory augmentation', 'Retrieving and reading: A comprehensive survey on open-domain question answering'], 'Large Language Models are Zero-Shot Reasoners': ['Do as i can, not as i say: Grounding language in robotic affordances', 'GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow', 'Language models are few-shot learners', 'On the measure of intelligence', 'Palm: Scaling language modeling with pathways', 'Training verifiers to solve math word problems', 'BERT: Pre-training of deep bidirectional transformers for language understanding', 'The pile: An 800gb dataset of diverse text for language modeling', 'Making pre-trained language models better few-shot learners', 'Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies', 'Learning to solve arithmetic word problems with verb categorization', 'The structure of human intelligence: It is verbal, perceptual, and image rotation (VPR), not fluid and crystallized', 'Parsing algebraic word problems into equations', 'MAWPS: A math word problem repository', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'What makes good in-context examples for gpt-3?', 'Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'The Cattell-Horn-Carroll theory of cognitive abilities: Past, present, and future', 'Pointer sentinel mixture models', 'Rethinking the role of demonstrations: What makes in-context learning work?', 'Show your work: Scratchpads for intermediate computation with language models', 'Training language models to follow instructions with human feedback', 'True few-shot learning with language models', 'Learning how to ask: Querying LMs with mixtures of soft prompts', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'Explain yourself! leveraging language models for commonsense reasoning', 'Prompt programming for large language models: Beyond the few-shot paradigm', 'Solving general arithmetic word problems', 'Multitask prompted training enables zero-shot task generalization', "It's not just size that matters: Small language models are also few-shot learners", 'AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts', 'Unsupervised commonsense question answering with self-talk', 'Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model', 'Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'Individual differences in reasoning: Implications for the rationality debate?', 'CommonsenseQA: A question answering challenge targeting commonsense knowledge', 'Lamda: Language models for dialog applications', 'Attention is all you need', 'GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model', 'Self-consistency improves chain of thought reasoning in language models', 'Do prompt-based models really understand the meaning of their prompts?', 'Chain of thought prompting elicits reasoning in large language models', 'Transformers: State-of-the-art natural language processing', 'STAR: Bootstrapping reasoning with reasoning', 'OPT: Open pre-trained transformer language models'], 'Measuring and Narrowing the Compositionality Gap in Language Models': ['Thinking aloud: Dynamic context generation improves zero-shot reasoning performance of gpt-2', 'Adaptive neural networks for efficient inference', 'Improving language models by retrieving from trillions of tokens', 'Language models are few-shot learners', 'Ask the right questions: Active question reformulation with reinforcement learning', 'The second conversational intelligence challenge (convai2)', 'Neural logic machines', 'Towards a human-like open-domain chatbot', 'Adaptive computation time for recurrent neural networks', 'Realm: Retrievalaugmented language model pre-training', 'Constructing a multihop QA dataset for comprehensive evaluation of reasoning steps', 'Multi-scale dense networks for resource efficient image classification', 'Compositionality decomposed: How do neural networks generalise?', 'Search-based neural structured learning for sequential question answering', 'Leveraging passage retrieval with generative models for open domain question answering', "Realtime qa: What's the answer right now?", 'Measuring compositional generalization: A comprehensive method on realistic data', 'Generalization through memorization: Nearest neighbor language models', 'Text modular networks: Learning to decompose tasks in the language of existing models', 'Decomposed prompting: A modular approach for solving complex tasks', 'Large language models are zero-shot reasoners', 'Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks', 'Retrieval-augmented generation for knowledgeintensive nlp tasks', 'A diversity-promoting objective function for neural conversation models', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'Generated knowledge prompting for commonsense reasoning', 'Teaching language models to support answers with verified quotes', 'Multi-hop reading comprehension through question decomposition and rescoring', "Reframing instructional prompts to GPTk's language", 'Webgpt: Browserassisted question-answering with human feedback', 'Show your work: Scratchpads for intermediate computation with language models', 'Is a question decomposition unit all we need?', 'Unsupervised question decomposition for question answering', 'Answering complex open-domain questions through iterative query generation', 'Answer-based Adversarial Training for Generating Clarification Questions', 'How much knowledge can you pack into the parameters of a language model?', 'Closed ai models make bad baselines', 'Recipes for building an open-domain chatbot', 'Knowledge-aware language model pretraining', 'The right tool for the job: Matching model and instance complexities', 'Can you learn an algorithm? generalizing from easy to hard problems with recurrent networks', 'Neural speed reading via skim-rnn', 'Generative deep neural networks for dialogue: A short review', 'Neural responding machine for short-text conversation', 'Unsupervised commonsense question answering with selftalk', 'A neural network approach to context-sensitive generation of conversational responses', 'Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'The web as a knowledge-base for answering complex questions', 'olmpics-on what language model pre-training captures', 'Lamda: Language models for dialog applications', 'Musique: Multihop questions via single-hop question composition', 'A neural conversational model', 'Shepherd pre-trained language models to develop a train of thought: An iterative prompting approach', 'Skipnet: Learning dynamic routing in convolutional networks', 'Not all images are worth 16x16 words: Dynamic transformers for efficient image recognition', 'Emergent abilities of large language models', 'Chain of thought prompting elicits reasoning in large language models', 'Break it down: A question understanding benchmark', 'React: Synergizing reasoning and acting in language models', 'The unreliability of explanations in few-shot in-context learning', 'Personalizing dialogue agents: I have a dog, do you have pets too?', 'Leastto-most prompting enables complex reasoning in large language models'], 'Explanation Selection Using Unlabeled Data for Chain-of-Thought Prompting': ['Explanations for CommonsenseQA: New Dataset and Models', 'Language models are few-shot learners', 'e-snli: Natural language inference with natural language explanations', 'Evaluating large language models trained on code', 'Palm: Scaling language modeling with pathways', 'Training verifiers to solve math word problems', 'Rlprompt: Optimizing discrete text prompts with reinforcement learning', 'Black-box prompt learning for pre-trained language models', 'Complexity-based prompting for multi-step reasoning', 'Pal: Program-aided language models', 'Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies', 'Demystifying prompts in language models via perplexity estimation', 'Knowledgeable prompt-tuning: Incorporating knowledge into prompt verbalizer for text classification', 'Large language models can self-improve', 'Maieutic prompting: Logically consistent reasoning with recursive explanations', 'Large language models are zero-shot reasoners', 'MAWPS: A math word problem repository', 'Can language models learn from explanations in context?', 'Explanations from large language models make small reasoners better', 'On the advance of making language models better reasoners', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'Text and patterns: For effective chain of thought, it takes two to tango', 'Few-shot self-rationalization with natural language prompts', "Reframing instructional prompts to GPTk's language", 'Show your work: Scratchpads for intermediate computation with language models', 'Training language models to follow instructions with human feedback', 'Are NLP models really able to solve simple math word problems?', 'Grips: Gradient-free, edit-based instruction search for prompting large language models', 'Prompt programming for large language models: Beyond the few-shot paradigm', 'Learning to retrieve prompts for in-context learning', 'Language models are multilingual chain-of-thought reasoners', 'AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts', 'Make prompt-based black-box tuning colorful: Boosting model generalization from three orthogonal perspectives', 'BBTv2: Towards a gradient-free future with large language models', 'Black-box tuning for language-model-as-a-service', 'CommonsenseQA: A question answering challenge targeting commonsense knowledge', 'Towards understanding chain-of-thought prompting: An empirical study of what matters', 'Pinto: Faithful language reasoning using prompt-generated rationales', 'Rationale-augmented ensembles in language models', 'Self-consistency improves chain of thought reasoning in language models', 'Chain of thought prompting elicits reasoning in large language models', 'The unreliability of explanations in few-shot prompting for textual reasoning', 'Complementary explanations for effective in-context learning', 'Star: Bootstrapping reasoning with reasoning', 'Tempera: Test-time prompting via reinforcement learning', 'Automatic chain of thought prompting in large language models', 'Least-to-most prompting enables complex reasoning in large language models', 'Large language models are human-level prompt engineers'], 'Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models': ['Language models are few-shot learners', 'Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks', 'PaLM: Scaling language modeling with pathways', 'Training verifiers to solve math word problems', 'BERT: Pre-training of deep bidirectional transformers for language understanding', 'Successive prompting for decomposing complex questions', 'Complexity-based prompting for multi-step reasoning', 'Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies', 'Towards a unified view of parameter-efficient transfer learning', 'Measuring mathematical problem solving with the math dataset', 'Learning to solve arithmetic word problems with verb categorization', 'Parameter-efficient transfer learning for nlp', 'Towards reasoning in large language models: A survey', 'Language models as zero-shot planners: Extracting actionable knowledge for embodied agents', 'Decomposed prompting: A modular approach for solving complex tasks', 'Large language models are zero-shot reasoners', 'Parsing algebraic word problems into equations', 'MAWPS: A math word problem repository', 'On the advance of making language models better reasoners', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'Llm+ p: Empowering large language models with optimal planning proficiency', 'Roberta: A robustly optimized bert pretraining approach', 'Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning', 'Are NLP models really able to solve simple math word problems?', 'Measuring and narrowing the compositionality gap in language models', 'Solving general arithmetic word problems', 'Language models are greedy reasoners: A systematic formal analysis of chain-of-thought', "On second thought, let's not think step by step! bias and toxicity in zero-shot reasoning", 'Pearl: Prompting large language models to plan and execute actions over long documents', 'Black-box tuning for language-model-as-a-service', 'Large language models can self-improve', 'Challenging big-bench tasks and whether chain-of-thought can solve them', 'Commonsenseqa: A question answering challenge targeting commonsense knowledge', 'Lamda: Language models for dialog applications', 'Towards understanding chain-of-thought prompting: An empirical study of what matters', 'Self-consistency improves chain of thought reasoning in language models', 'Describe, explain, plan and select: Interactive planning with large language models enables open-world multi-task agents', 'Emergent abilities of large language models', 'Chain of thought prompting elicits reasoning in large language models', 'Large language models are reasoners with self-verification', 'Tree of thoughts: Deliberate problem solving with large language models', 'React: Synergizing reasoning and acting in language models', 'Automatic chain of thought prompting in large language models', 'Least-to-most prompting enables complex reasoning in large language models'], 'SHOW YOUR WORK: SCRATCHPADS FOR INTERMEDIATE COMPUTATION WITH LANGUAGE MODELS': ['Learning to represent programs with graphs', 'Program synthesis with large language models', 'Pondernet: Learning to ponder', 'Climbing towards NLU: On meaning, form, and understanding in the age of data', 'Learning to execute programs with instruction pointer attention graph neural networks', 'Language models are few-shot learners', 'Evaluating large language models trained on code', 'Universal transformers', 'Robustfill: Neural program learning under noisy I/O', 'BERT: Pre-training of deep bidirectional transformers for language understanding', 'Adaptive computation time for recurrent neural networks', 'Neural turing machines', 'Hybrid computing using a neural network with dynamic external memory', 'Neural gpus learn algorithms', 'Neural random-access machines', 'Inducing probabilistic CCG grammars from logical form with higher-order unification', 'Implicit representations of meaning in neural language models', 'Pretrained transformers as universal computation engines', 'Project CodeNet: A Large-Scale AI for code dataset for learning a diversity of coding tasks', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'Neural programmer-interpreters', 'Analysing mathematical reasoning abilities of neural models', 'Long range arena: A benchmark for efficient transformers', 'Neural algorithmic reasoning', 'Pointer graph networks', 'Neural execution of graph algorithms', 'Learning semantic program embeddings with graph interval neural network', 'Learning for semantic parsing with statistical machine translation', 'Learning to execute', 'Learning to parse database queries using inductive logic programming', 'Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars'], 'SKELETON-OF-THOUGHT: PROMPTING LLMS FOR EFFICIENT PARALLEL GENERATION': ['Introducing claude', 'Graph of thoughts: Solving elaborate problems with large language models', 'Language models are few-shot learners', 'Once-for-all: Train one network and specialize it for efficient deployment', 'LangChain', 'Accelerating large language model decoding with speculative sampling', 'Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks', 'Dynamic n: M fine-grained structured sparse attention mechanism', 'LLM zoo: democratizing chatgpt', 'Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality', 'Scaling instruction-finetuned language models', 'Flashattention: Fast and memory-efficient exact attention with io-awareness', 'Exploiting linear structure within convolutional networks for efficient evaluation', 'Enhancing chat language models by scaling high-quality instructional conversations', 'GLM: General language model pretraining with autoregressive blank infilling', 'Neural architecture search: A survey', 'Hierarchical neural story generation', 'Turbotransformers: an efficient gpu serving system for transformer models', 'Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity', 'GPTQ: Accurate post-training quantization for generative pre-trained transformers', 'Compressing large-scale transformer-based models: A case study on bert', 'Assisted generation: a new direction toward low-latency text generation', 'Tensorflow serving', 'Non-autoregressive neural machine translation', 'Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding', 'Data-centric ai', 'Large language models can self-improve', 'GPipe: Efficient training of giant neural networks using pipeline parallelism', 'Data movement is all you need: A case study on optimizing transformers', 'LLMLingua: Compressing prompts for accelerated inference of large language models', 'Reformer: The efficient transformer', 'Quantizing deep convolutional networks for efficient inference: A whitepaper', 'One weird trick for parallelizing convolutional neural networks', 'Efficient memory management for large language model serving with pagedattention', 'GShard: Scaling giant models with conditional computation and automatic sharding', 'The power of scale for parameter-efficient prompt tuning', 'Fast inference from transformers via speculative decoding', "CAMEL: Communicative agents for 'mind' exploration of large scale language model society", 'A hierarchical neural autoencoder for paragraphs and documents', 'Prefix-tuning: Optimizing continuous prompts for generation', 'ALPACAeval: An automatic evaluator of instruction-following models', 'Making language models better reasoners with step-aware verifier', 'Terapipe: Token-level pipeline parallelism for training large-scale language models', 'AWQ: Activation-aware weight quantization for LLM compression and acceleration', 'Pretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing', 'Roberta: A robustly optimized bert pretraining approach', 'Decoupled weight decay regularization', 'FlexFlow: A flexible dataflow accelerator architecture for convolutional neural networks', 'SpecInfer: Accelerating generative LLM serving with speculative inference and token tree verification', 'Accelerating sparse deep neural networks', 'PipeDream: Generalized pipeline parallelism for DNN training', 'Memory-efficient pipeline-parallel DNN training', 'FasterTransformer', 'Triton inference server', 'Training language models to follow instructions with human feedback', 'StableVicuna-13b', 'Measuring and narrowing the compositionality gap in language models', 'Data-to-text generation with content selection and planning', 'Zero: Memory optimizations toward training trillion parameter models', 'ZeRO-Offload: Democratizing Billion-Scale model training', 'Accelerating transformer inference for translation via parallel decoding', 'Toolformer: Language models can teach themselves to use tools', 'Lightllm', 'Openppl', 'Long and diverse text generation with planning-based hierarchical variational model', 'Fast transformer decoding: One write-head is all you need', 'Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface', 'High-throughput generative inference of large language models with a single gpu', 'Autoprompt: Eliciting knowledge from language models with automatically generated prompts', 'Blockwise parallel decoding for deep autoregressive models', 'Spectr: Fast speculative decoding via optimal transport', 'Rethinking the inception architecture for computer vision', 'Alpaca: A strong, replicable instruction-following model', 'Llama: Open and efficient foundation language models', 'Llama 2: Open foundation and fine-tuned chat models', 'Openllms: Less is more for open-source models', 'Spatten: Efficient sparse attention architecture with cascade token and head pruning', 'Linformer: Self-attention with linear complexity', 'Self-consistency improves chain of thought reasoning in language models', 'Dice semimetric losses: Optimizing the dice score with soft labels', 'Finetuned language models are zero-shot learners', 'Chain-of-thought prompting elicits reasoning in large language models', 'Learning structured sparsity in deep neural networks', 'Smoothquant: Accurate and efficient post-training quantization for large language models', 'A survey on non-autoregressive generation for neural machine translation and beyond', 'Wizardlm: Empowering large language models to follow complex instructions', 'GSPMD: general and scalable parallelization for ml computation graphs', 'React: Synergizing reasoning and acting in language models', 'Tree of thoughts: Deliberate problem solving with large language models', 'Orca: A distributed serving system for Transformer-Based generative models', 'Big bird: Transformers for longer sequences', 'Star: Bootstrapping reasoning with reasoning', 'Data-centric artificial intelligence: A survey', 'Bytetransformer: A high-performance transformer boosted for variable-length inputs', 'Cumulative reasoning with large language models', 'Alpa: Automating inter-and IntraOperator parallelism for distributed deep learning', 'Judging llm-as-a-judge with mt-bench and chatbot arena', 'Lima: Less is more for alignment', 'PetS: A unified framework for Parameter-Efficient transformers serving', 'Ghost in the minecraft: Generally capable agents for open-world enviroments via large language models with text-based knowledge and memory', 'Neural architecture search with reinforcement learning'], 'SATLM: Satisfiability-Aided Language Models Using Declarative Prompting': ['Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'Language models are few-shot learners', 'Evaluating large language models trained on code', 'Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks', 'Teaching large language models to self-debug', 'PaLM: Scaling Language Modeling with Pathways', 'Training verifiers to solve math word problems', 'Selection-inference: Exploiting large language models for interpretable logical reasoning', 'A computing procedure for quantification theory', 'Z3: An Efficient SMT Solver', 'Just add functions: A neural-symbolic language model', 'On the foundations of noise-free selective classification', 'Complexity-based prompting for multi-step reasoning', 'Pal: Program-aided language models', 'Neurosymbolic AI: The 3rd wave', 'The GEM benchmark: Natural language generation, its evaluation and metrics', 'Demystifying prompts in language models via perplexity estimation', 'Solving math word problems by combining language models with symbolic solvers', 'Jigsaw: Large language models meet program synthesis', 'BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory Information', 'Decomposed prompting: A modular approach for solving complex tasks', 'Large language models are zero-shot reasoners', 'Explanations from large language models make small reasoners better', 'On the advance of making language models better reasoners', 'Holistic evaluation of language models', 'LLM+ P: Empowering Large Language Models with Optimal Planning Proficiency', 'Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing', 'Faithful chain-of-thought reasoning', 'Self-refine: Iterative refinement with self-feedback', 'The next decade in AI: four steps towards robust artificial intelligence', 'LEVER: Learning to Verify Language-to-Code Generation with Execution', 'Show your work: Scratchpads for intermediate computation with language models', 'Training language models to follow instructions with human feedback', 'Refiner: Reasoning feedback on intermediate representations', 'Synchromesh: Reliable code generation from pre-trained language models', 'Scaling Language Models: Methods, Analysis & Insights from Training Gopher', 'Multi-modal program inference: A marriage of pre-trained language models and component-based synthesis', 'A recipe for arbitrary text style transfer with large language models', 'STREET: A multi-task structured reasoning and explanation benchmark', 'Multitask prompted training enables zero-shot task generalization', 'Language models are greedy reasoners: A systematic formal analysis of chain-of-thought', 'Toolformer: Language models can teach themselves to use tools', 'CLUTRR: A diagnostic benchmark for inductive reasoning from text', 'ProofWriter: Generating implications, proofs, and abductive statements over natural language', "Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change)", 'Pinto: Faithful language reasoning using prompt-generated rationales', 'Self-consistency improves chain of thought reasoning in language models', 'Finetuned language models are zero-shot learners', 'Emergent abilities of large language models', 'Chain of thought prompting elicits reasoning in large language models', 'Benchmarking multimodal regex synthesis with complex structures', 'Optimal neural program synthesis from multimodal specifications', 'Explanation selection using unlabeled data for chain-of-thought prompting', 'Generate rather than retrieve: Large language models are strong context generators', 'Improved logical reasoning of language models via differentiable symbolic programming', 'OPT: Open Pre-trained Transformer Language Models', 'Analytical reasoning of text', 'Least-to-most prompting enables complex reasoning in large language models'], 'Compositional Exemplars for In-context Learning': ['In-context examples selection for machine translation', 'Cont: Contrastive neural text generation', 'Task-oriented dialogue as dataflow synthesis', 'Learning detection with diverse proposals', 'Semantic parsing on Freebase from question-answer pairs', 'GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow', 'Language models are few-shot learners', 'Fast greedy map inference for determinantal point process to improve recommendation diversity', 'Evaluating large language models trained on code', 'BERT: Pre-training of deep bidirectional transformers for language understanding', 'Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources', 'Human-level play in the game of diplomacy by combining language models with strategic reasoning', 'Improving text-to-SQL evaluation methodology', 'The pile: An 800gb dataset of diverse text for language modeling', 'Simcse: Simple contrastive learning of sentence embeddings', 'Near-optimal map inference for determinantal point processes', 'Diverse sequential subset selection for supervised video summarization', 'Faster greedy map inference for determinantal point processes', 'Question decomposition with dependency graphs', 'Momentum contrast for unsupervised visual representation learning', 'ActivityNet: A large-scale video benchmark for human activity understanding', 'The curious case of neural text degeneration', 'Towards unsupervised dense information retrieval with contrastive learning', 'Dense passage retrieval for open-domain question answering', 'Adam: A method for stochastic optimization', 'An exact algorithm for maximum entropy sampling', 'k-dpps: Fixed-size determinantal point processes', 'Determinantal point processes for machine learning', 'Metric learning: A survey', 'Diverse demonstrations improve in-context compositional generalization', 'Mtop: A comprehensive multilingual task-oriented semantic parsing benchmark', 'On the advance of making language models better reasoners', 'NL2Bash: A corpus and semantic parser for natural language interface to the linux operating system', 'What makes good in-context examples for GPT-3?', 'Learning to rank for information retrieval', 'Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity', 'WebGPT: Browser-assisted question-answering with human feedback', 'Representation learning with contrastive predictive coding', 'ChatGPT: Optimizing language models for dialogue', 'Improving compositional generalization with latent structure and data augmentation', 'Evaluating the impact of model scale for compositional generalization in semantic parsing', 'Language models are unsupervised multitask learners', 'The probabilistic relevance framework: BM25 and beyond', 'Movie Description', 'Learning to retrieve prompts for in-context learning', 'Learning with kernels: support vector machines, regularization, optimization, and beyond', 'Compositional generalization and natural language variation: Can a semantic parsing approach handle both?', 'Natural language to code translation with execution', 'Recursive deep models for semantic compositionality over a sentiment treebank', 'Selective annotation makes language models better few-shot learners', 'CommonsenseQA: A question answering challenge targeting commonsense knowledge', 'Attention is all you need', 'GLUE: A multi-task benchmark and analysis platform for natural language understanding', 'Self-consistency improves chain of thought reasoning in language models', 'Emergent abilities of large language models', 'A broad-coverage challenge corpus for sentence understanding through inference', 'Transformers: State-of-the-art natural language processing', 'Break it down: A question understanding benchmark', 'Self-adaptive in-context learning', 'Deep determinantal point process for large-scale multi-label classification', 'ProGen: Progressive zero-shot dataset generation via in-context feedback', 'Generating data for symbolic language with large language models', 'Complementary explanations for effective in-context learning', 'Compositional generalization for neural semantic parsing via span-level supervised attention', 'Extractive summarization as text matching'], 'CHAIN-OF-KNOWLEDGE: GROUNDING LARGE LANGUAGE MODELS VIA DYNAMIC KNOWLEDGE ADAPTING OVER HETEROGENEOUS SOURCES': ['Autoregressive entity retrieval', 'KQA pro: A dataset with explicit compositional programs for complex question answering over knowledge base', 'Reading Wikipedia to answer open-domain questions', "Chatgpt's one-year anniversary: Are open-source large language models catching up?", 'Is gpt-4 a good data analyst?', 'Palm: Scaling language modeling with pathways', 'Scaling instruction-finetuned language models', 'Is gpt-3 a good data annotator?', 'Can machine translation systems be evaluated by the crowd alone', 'Retrieval augmented language model pre-training', 'Medalpaca – an open-source collection of medical conversational ai models and training data', 'Measuring massive multitask language understanding', 'Lora: Low-rank adaptation of large language models', 'Survey of hallucination in natural language generation', 'Findings of the 2022 conference on machine translation (WMT22)', 'The measurement of observer agreement for categorical data', 'Retrieval-augmented generation for knowledge-intensive nlp tasks', 'Chain of hindsight aligns language models with feedback', 'Learn to explain: Multimodal reasoning via thought chains for science question answering', 'Augmented large language models with parametric knowledge guiding', 'Augmented language models: a survey', 'FeTaQA: Free-form table question answering', 'Gpt-4 technical report', 'Training language models to follow instructions with human feedback', 'Medmcqa : A large-scale multi-subject multi-choice dataset for medical domain question answering', 'Fact-checking complex claims with program-guided reasoning', 'KILT: a benchmark for knowledge intensive language tasks', 'Toolformer: Language models can teach themselves to use tools', 'Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface', 'Replug: Retrieval-augmented black-box language models', 'FEVER: a large-scale dataset for fact extraction and VERification', 'Llama 2: Open foundation and fine-tuned chat models', 'Lc-quad: A corpus for complex question answering over knowledge graphs', 'Self-consistency improves chain of thought reasoning in language models', 'Chain-of-thought prompting elicits reasoning in large language models', 'UnifiedSKG: Unifying and multi-tasking structured knowledge grounding with text-to-text language models', 'HotpotQA: A dataset for diverse, explainable multi-hop question answering', 'React: Synergizing reasoning and acting in language models', 'Retrieving multimodal information for augmented generation: A survey', 'Can chatgpt-like generative models guarantee factual accuracy? on the mistakes of new generation search engines', 'Verify-and-edit: A knowledge-enhanced chain-of-thought framework'], 'LARGE LANGUAGE MODELS AS ANALOGICAL REASONERS': ['Palm 2 technical report', 'Program synthesis with large language models', 'Knowledge-powered deep learning for word embedding', 'From machine learning to machine reasoning: An essay', 'Language models are few-shot learners', 'Large language models as tool makers', 'Learning by analogy: Formulating and generalizing plans from past experience', 'Evaluating large language models trained on code', 'Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks', 'Execution-guided neural program synthesis', 'Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension', 'Teaching large language models to self-debug', 'Binding language models in symbolic languages', 'Palm: Scaling language modeling with pathways', 'Scaling instruction-finetuned language models', 'Training verifiers to solve math word problems', 'BERT: Pre-training of deep bidirectional transformers for language understanding', 'Compositional semantic parsing with large language models', 'Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs', 'The analogical paradox: Why analogy is so easy in naturalistic settings yet so difficult in the psychological laboratory', 'Scalable multihop relational reasoning for knowledge-aware question answering', 'The pile: An 800gb dataset of diverse text for language modeling', 'Structure-mapping: A theoretical framework for analogy', 'Reasoning and learning by analogy: Introduction', 'Structure mapping in analogy and similarity', 'Synthesize, execute and debug: Learning to repair for neural program synthesis', 'Reasoning with language model is planning with world model', 'Exploring human-like translation strategy with large language models', 'Measuring coding challenge competence with apps', 'Measuring mathematical problem solving with the math dataset', 'Analogy and relational reasoning', 'In-context analogical reasoning with pre-trained language models', 'A diagnostic study of visual question answering with analogical reasoning', 'How can we know what language models know?', 'Maieutic prompting: Logically consistent reasoning with recursive explanations', 'Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp', 'Decomposed prompting: A modular approach for solving complex tasks', 'Language models can solve computer tasks', 'Self-generated in-context learning: Leveraging auto-regressive language models as a demonstration generator', 'Large language models are zero-shot reasoners', 'Spoc: Search-based pseudocode to code', 'Self-prompting large language models for open-domain qa', 'Competition-level code generation with alphacode', 'Holistic evaluation of language models', 'Improving mathematical reasoning with process supervision', 'Kagnet: Knowledge-aware graph networks for commonsense reasoning', 'What makes good in-context examples for gpt-3?', 'Data contamination: From memorization to exploitation', 'Cross-task generalization via natural language crowdsourcing instructions', 'Analogical reasoning in the context of acquiring problem solving expertise', 'Med-flamingo: a multimodal medical few-shot learner', 'Gpt-4 technical report', 'Training language models to follow instructions with human feedback', 'Generative agents: Interactive simulacra of human behavior', 'How to solve it: A new aspect of mathematical method', 'Measuring and narrowing the compositionality gap in language models', 'Is chatgpt a general-purpose natural language processing task solver?', 'Sentence-BERT: Sentence embeddings using Siamese BERT-networks', 'Lego: Latent execution-guided reasoning for multi-hop question answering on knowledge graphs', 'Toolformer: Language models can teach themselves to use tools', 'Replug: Retrieval-augmented black-box language models', 'Automatic prompt augmentation and selection with chain-of-thought from labeled data', 'Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'Selective annotation makes language models better few-shot learners', 'Recitation-augmented language models', 'Challenging big-bench tasks and whether chain-of-thought can solve them', 'Commonsenseqa: A question answering challenge targeting commonsense knowledge', 'Similarity and analogical reasoning', 'Self-consistency improves chain of thought reasoning in language models', 'Creative thought: An investigation of conceptual structures and processes', 'Emergent analogical reasoning in large language models', 'Finetuned language models are zero-shot learners', 'Chain of thought prompting elicits reasoning in large language models', 'Lime: Learning inductive bias for primitives of mathematical reasoning', 'Unifiedskg: Unifying and multi-tasking structured knowledge grounding with text-to-text language models', 'Hotpotqa: A dataset for diverse, explainable multi-hop question answering', 'React: Synergizing reasoning and acting in language models', 'Tree of thoughts: Deliberate problem solving with large language models', 'Graph-based, self-supervised program repair from diagnostic feedback', 'Break-it-fix-it: Unsupervised learning for program repair', 'QA-GNN: Reasoning with language models and knowledge graphs for question answering', 'Deep bidirectional language-knowledge graph pretraining', 'LinkBERT: Pretraining language models with document links', 'Retrieval-augmented multimodal language modeling', 'Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task', 'Parsel: A unified natural language framework for algorithmic reasoning', 'Improved logical reasoning of language models via differentiable symbolic programming', 'Greaselm: Graph reasoning enhanced language models for question answering', 'Automatic chain of thought prompting in large language models', 'Complex reasoning in natural language', 'Solving challenging math word problems using gpt-4 code interpreter with code-based self-verification', 'Least-to-most prompting enables complex reasoning in large language models'], 'PROMPTING GPT-3 TO BE RELIABLE': ['Types of out-of-distribution texts and how to detect them', 'On the dangers of stochastic parrots: Can language models be too big?', 'Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'Unobserved local structures make compositional generalization hard', 'Evaluating the susceptibility of pretrained language models via handcrafted adversarial examples', 'Verification of forecasts expressed in terms of probability', 'Language models are few-shot learners', 'Editing factual knowledge in language models', 'On the intrinsic and extrinsic fairness evaluation metrics for contextualized language representations', 'Quantifying memorization across neural language models', 'Evaluating large language models trained on code', 'A dataset for answering time-sensitive questions', 'Palm: Scaling language modeling with pathways', 'Calibration of pre-trained transformers', 'Bert: Pre-training of deep bidirectional transformers for language understanding', 'MRQA 2019 shared task: Evaluating generalization in reading comprehension', 'Single-dataset experts for multi-dataset question answering', 'Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned', 'Attributed text generation via post-hoc research and revision', "Evaluating models' local decision boundaries via contrast sets", 'Realtoxicityprompts: Evaluating neural toxic degeneration in language models', 'On calibration of modern neural networks', 'Annotation artifacts in natural language inference data', 'REALM: Retrieval-augmented language model pre-training', 'Exploring the role of grammar and word choice in bias toward african american english (aae) in hate speech classification', 'Pretrained transformers improve out-of-distribution robustness', 'Unsupervised dense information retrieval with contrastive learning', 'Few-shot learning with retrieval augmented language models', 'Adversarial examples for evaluating reading comprehension systems', 'How can we know when language models know?', 'Is bert really robust? A strong baseline for natural language attack on text classification and entailment', 'Language models (mostly) know what they know', 'Scaling laws for neural language models', 'Dense passage retrieval for open-domain question answering', "RealTime QA: What's the answer right now?", 'Measuring compositional generalization: A comprehensive method on realistic data', 'COGS: A compositional generalization challenge based on semantic interpretation', 'WILDS: A benchmark of in-the-wild distribution shifts', 'Large language models are zero-shot reasoners', 'End-to-end neural coreference resolution', 'The power of scale for parameter-efficient prompt tuning', 'Zero-shot relation extraction via reading comprehension', 'Retrieval-augmented generation for knowledge-intensive nlp tasks', 'D-net: A pretraining and fine-tuning framework for improving the generalization of machine reading comprehension', 'Bert-attack: Adversarial attack against bert using bert', 'Teaching models to express their uncertainty in words', 'Truthfulqa: Measuring how models mimic human falsehoods', 'Roberta: A robustly optimized bert pretraining approach', 'An exploration of data augmentation and sampling techniques for domain-agnostic question answering', 'Entity-based knowledge conflicts in question answering', 'Gender and representation bias in gpt-3 generated stories', 'Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference', "Reducing conversational agents' overconfidence through linguistic calibration", 'Rethinking the role of demonstrations: What makes in-context learning work?', 'Fast model editing at scale', 'Memory-based model editing at scale', 'Stereoset: Measuring stereotypical bias in pretrained language models', 'Obtaining well calibrated probabilities using bayesian binning', 'Crows-pairs: A challenge dataset for measuring social biases in masked language models', 'BBQ: A hand-built bias benchmark for question answering', 'Red teaming language models with language models', 'Language models as knowledge bases?', 'Kilt: A benchmark for knowledge intensive language tasks', 'Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods', 'Hypothesis only baselines in natural language inference', 'Scaling language models: Methods, analysis & insights from training gopher', 'Semantically equivalent adversarial rules for debugging nlp models', 'How much knowledge can you pack into the parameters of a language model?', 'Gender bias in coreference resolution', 'What does bert learn from multiple-choice reading comprehension datasets?', 'Benchmarking robustness of machine reading comprehension models', 'Better robustness by more coverage: Adversarial training with mixup augmentation for robust fine-tuning', 'Revisiting calibration for question answering', 'Process for adapting language models to society (palms) with values-targeted datasets', 'MultiQA: An empirical investigation of generalization and transfer in reading comprehension', "It's morphin' time! combating linguistic discrimination with inflectional perturbations", 'Reliability testing for natural language processing systems', 'The risks of machine learning systems', 'Do multi-hop question answering systems know how to answer the single-hop sub-questions?', 'FEVER: A large-scale dataset for fact extraction and verification', 'Glue: A multi-task benchmark and analysis platform for natural language understanding', 'Adversarial GLUE: A multi-task benchmark for robustness evaluation of language models', 'Self-consistency improves chain of thought reasoning in language models', 'Emergent abilities of large language models', 'Chain of thought prompting elicits reasoning in large language models', 'HotpotQA: A dataset for diverse, explainable multi-hop question answering', 'Can explanations be useful for calibrating black box models?', 'OPT: Open pre-trained transformer language models', 'PAWS: Paraphrase adversaries from word scrambling', 'Gender bias in coreference resolution: Evaluation and debiasing methods', 'Ethical-advice taker: Do language models understand natural language interventions?', 'Calibrate before use: Improving few-shot performance of language models', 'Value: Understanding dialect disparity in nlu'], 'From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting': ['Generating EDU extracts for plan-guided summary re-ranking', 'Learning to revise references for faithful summarization', 'A meta-evaluation of faithfulness metrics for long-form hospital-course summarization', 'Multilingual summarization with factual consistency evaluation', 'Prompted opinion summarization with GPT-3.5', 'Hallucinated but factual! inspecting the factuality of hallucinations in abstractive summarization', 'Re-examining system-level correlations of automatic summarization evaluation metrics', 'GSum: A general framework for guided neural abstractive summarization', 'SummEval: Re-evaluating summarization evaluation', 'Measuring nominal scale agreement among many raters', 'Gptscore: Evaluate as you desire', 'Chatgpt outperforms crowd-workers for text-annotation tasks', 'News summarization and evaluation in the era of gpt-3', 'Newsroom: A dataset of 1.3 million summaries with diverse extractive strategies', 'CTRLsum: Towards generic controllable text summarization', 'Challenges and applications of large language models', 'Keywords-guided abstractive sentence summarization', 'Gpteval: Nlg evaluation using gpt-4 with better human alignment', 'Revisiting the gold standard: Grounding summarization evaluation with robust human evaluation', 'Controllable neural dialogue summarization with personal named entity planning', 'Nltk: The natural language toolkit', 'EntSUM: A data set for entity-centric extractive summarization', 'Abstractive text summarization using sequence-to-sequence RNNs and beyond', 'Entity-level factual consistency of abstractive text summarization', 'Planning with learned entity prompts for abstractive summarization', 'Gpt-4 technical report', 'ChatGPT vs human-authored text: Insights into controllable text summarization and sentence style transfer', 'Learning to summarize with human feedback', 'Llama 2: Open foundation and fine-tuned chat models', 'Benchmarking large language models for news summarization', 'Neural document summarization by jointly learning to score and select sentences'], 'LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models': ['Types of out-of-distribution texts and how to detect them', 'Token merging: Your vit but faster', 'Adapting language models to compress contexts', 'Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality', 'Training verifiers to solve math word problems', 'Language modeling is compression', 'GPT3.int8(): 8-bit matrix multiplication for transformers at scale', 'SparseGPT: Massive language models can be accurately pruned in one-shot', 'OPTQ: Accurate quantization for generative pre-trained transformers', "Chain-of-thought hub: A continuous effort to measure large language models' reasoning performance", 'Complexity-based prompting for multi-step reasoning', 'Extensible prompts for language models', 'In-context autoencoder for context compression in a large language model', 'Semantic compression with large language models', 'Power-bert: Accelerating BERT inference via progressive word-vector elimination', 'LoRA: Low-rank adaptation of large language models', 'Lengthadaptive transformer: Train once with length drop, use anytime with search', 'Learned token pruning for transformers', 'Unlocking context constraints of llms: Enhancing context efficiency of llms with self-information-based content filtering', 'ROUGE: A package for automatic evaluation of summaries', 'Decoupled weight decay regularization', 'Self-supervised losses for one-class textual anomaly detection', 'AdapLeR: Speeding up inference by adaptive length reduction', 'Learning to compress prompts with gist tokens', 'Bleu: a method for automatic evaluation of machine translation', 'Source coding algorithms for fast data compression', 'Dynamicvit: Efficient vision transformers with dynamic token sparsification', 'Generalized kraft inequality and arithmetic coding', 'Prediction and entropy of printed english', 'A theory of unsupervised learning', 'Challenging big-bench tasks and whether chain-of-thought can solve them', 'Stanford alpaca: An instruction-following llama model', 'Chain of thought prompting elicits reasoning in large language models', 'Prompt compression and contrastive conditioning for controllability and toxicity reduction in language models', 'Multi-level knowledge distillation for out-of-distribution detection in text', 'Smoothquant: Accurate and efficient post-training quantization for large language models', 'Wizardlm: Empowering large language models to follow complex instructions', 'Inference with reference: Lossless acceleration of large language models', 'Xlnet: Generalized autoregressive pretraining for language understanding', 'Mlcopilot: Unleashing the power of large language models in solving machine learning tasks', 'Bertscore: Evaluating text generation with BERT', 'Efficient prompting via dynamic in-context learning'], 'Language Models are Unsupervised Multitask Learners': ['Character-level language modeling with deeper self-attention', 'A bert baseline for the natural questions', 'Strike (with) a pose: Neural networks are easily fooled by strange poses of familiar objects', 'Deep speech 2: End-to-end speech recognition in english and mandarin', 'Unsupervised neural machine translation', 'An effective approach to unsupervised machine translation', 'Layer normalization', 'Embracing data abundance: Booktest dataset for reading comprehension', 'Do we train on test data? purging cifar of near-duplicates', 'A neural probabilistic language model', "Looking for elmo's friends: Sentence-level pretraining beyond language modeling", 'Multitask learning', 'One billion word benchmark for measuring progress in statistical language modeling', 'Natural language processing (almost) from scratch', 'Supervised learning of universal sentence representations from natural language inference data', 'Word translation without parallel data', 'Semi-supervised sequence learning', 'Transformer-xl: Attentive language models beyond a fixed-length context', 'The 14 billion word iweb corpus', 'Universal transformers', 'Bert: Pretraining of deep bidirectional transformers for language understanding', 'Wizard of wikipedia: Knowledge-powered conversational agents', 'Hierarchical neural story generation', 'Model-agnostic metalearning for fast adaptation of deep networks', 'Bottom-up abstractive summarization', 'Multilingual language processing from bytes', 'Frage: frequency-agnostic word representation', 'Improving neural language models with a continuous cache', 'Identity mappings in deep residual networks', 'Deep learning scaling is predictable, empirically', "The goldilocks principle: Reading children's books with explicit memory representations", 'Learning distributed representations of sentences from unlabelled data', 'Entity tracking improves cloze-style reading comprehension', 'Universal language model fine-tuning for text classification', 'Interpolated estimation of markov source parameters from sparse data', 'Adversarial examples for evaluating reading comprehension systems', 'Exploring the limits of language modeling', 'One model to learn them all', 'Visualizing and understanding recurrent networks', 'Overcoming catastrophic forgetting in neural networks', 'Skip-thought vectors', 'Imagenet classification with deep convolutional neural networks', 'Natural questions: a benchmark for question answering research', 'Building machines that learn and think like people', 'Unsupervised machine translation using monolingual corpora only', 'The winograd schema challenge', 'Neural word embedding as implicit matrix factorization', 'Generating wikipedia by summarizing long sequences', 'Learned in translation: Contextualized word vectors', 'The natural language decathlon: Multitask learning as question answering', 'Pointer sentinel mixture models', 'Distributed representations of words and phrases and their compositionality', 'Abstractive text summarization using sequence-to-sequence rnns and beyond', 'The lambada dataset: Word prediction requiring a broad discourse context', 'Glove: Global vectors for word representation', 'Content extraction using diverse feature sets', 'Deep contextualized word representations', 'Learning to generate reviews and discovering sentiment', 'Improving language understanding by generative pre-training', 'Unsupervised pretraining for sequence to sequence learning', 'Do cifar-10 classifiers generalize to cifar-10?', 'Coqa: A conversational question answering challenge', 'Story cloze task: Uw nlp system', 'Get to the point: Summarization with pointer-generator networks', 'Neural machine translation of rare words with subword units', 'Learning general purpose distributed sentence representations via large scale multi-task learning', 'Sequence to sequence learning with neural networks', 'Towards principled unsupervised learning', 'On the evaluation of common-sense reasoning in natural language understanding', 'A simple method for commonsense reasoning', 'Attention is all you need', 'A neural conversational model', 'Pointer networks', 'Glue: A multi-task benchmark and analysis platform for natural language understanding', 'Dialog-based language learning', 'No training required: Exploring random encoders for sentence classification', 'Transfertransfo: A transfer learning approach for neural network based conversational agents', 'Learning and evaluating general linguistic intelligence'], 'Better Zero-Shot Reasoning with Self-Adaptive Prompting': ['Language models are few-shot learners', 'Ensemble selection from libraries of models', 'Evaluating large language models trained on code', 'Palm: Scaling language modeling with pathways', 'Training verifiers to solve math word problems', 'RLPrompt: Optimizing discrete text prompts with reinforcement learning', 'Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies', 'Semi-supervised learning by entropy minimization', 'Unnatural instructions: Tuning language models with (almost) no human labor', 'Learning to solve arithmetic word problems with verb categorization', 'Large language models can self-improve', 'OpenNMT: Open-source toolkit for neural machine translation', 'Large language models are zero-shot reasoners', 'Parsing algebraic word problems into equations', 'Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks', 'Self-prompting large language models for open-domain qa', 'On the advance of making language models better reasoners', 'What makes good in-context examples for GPT-3?', 'Text and patterns: For effective chain of thought, it takes two to tango', 'Sentence-t5: Scalable sentence encoders from pretrained text-to-text models', 'A deep reinforced model for abstractive summarization', 'Language models are unsupervised multitask learners', 'Scaling language models: Methods, analysis & insights from training gopher', 'Sentence-BERT: Sentence embeddings using Siamese BERT-networks', 'In defense of pseudo-labeling: An uncertainty-aware pseudo-label selection framework for semi-supervised learning', 'Solving general arithmetic word problems', 'Learning to retrieve prompts for in-context learning', 'ChatGPT: Optimizing language models for dialogue', 'Transductive semi-supervised deep learning using min-max features', 'Selective annotation makes language models better few-shot learners', 'CommonsenseQA: A question answering challenge targeting commonsense knowledge', 'Lamda: Language models for dialog applications', 'Learning values across many orders of magnitude', 'Superglue: A stickier benchmark for general-purpose language understanding systems', 'Self-consistency improves chain of thought reasoning in language models', 'Self-instruct: Aligning language model with self generated instructions', 'Emergent abilities of large language models', 'Chain of thought prompting elicits reasoning in large language models', 'Ethical and social risks of harm from language models', 'Large language models are reasoners with self-verification', 'Zero-shot learning-the good, the bad and the ugly', 'React: Synergizing reasoning and acting in language models', 'Star: Self-taught reasoner bootstrapping reasoning with reasoning', 'Automatic chain of thought prompting in large language models'], 'Thread of Thought Unraveling Chaotic Contexts': ['The reversal curse: Llms trained on "a is b" fail to learn "b is a"', 'Graph of thoughts: Solving elaborate problems with large language models', 'Language models are few-shot learners', 'Extending context window of large language models via positional interpolation', 'Vicuna: An opensource chatbot impressing gpt-4 with 90%* chatgpt quality', 'Longnet: Scaling transformers to 1, 000, 000, 000 tokens', 'Longllmlingua: Accelerating and enhancing llms in long context scenarios via prompt compression', 'Retrieval-augmented generation for knowledge-intensive NLP tasks', 'Lost in the middle: How language models use long contexts', 'When not to trust language models: Investigating effectiveness of parametric and non-parametric memories', 'Adaptive machine translation with large language models', 'GPT-4 technical report', 'Train short, test long: Attention with linear biases enables input length extrapolation', 'Parallel context windows for large language models', 'Chatgpt: Optimizing language models for dialogue', 'Simple entity-centric questions challenge dense retrievers', 'Evaluating the factual consistency of large language models through news summarization', 'Llama: Open and efficient foundation language models', 'Llama 2: Open foundation and fine-tuned chat models', 'Chatcad: Interactive computer-aided diagnosis on medical image using large language models', 'Self-consistency improves chain of thought reasoning in language models', 'Chain-of-thought prompting elicits reasoning in large language models', 'Efficient streaming language models with attention sinks', 'Beyond goldfish memory: Long-term open-domain conversation', 'Retrieval meets long context large language models', 'Tree of thoughts: Deliberate problem solving with large language models', 'Beyond chain-of-thought, effective graph-of-thought reasoning in large language models', 'Disc-lawllm: Fine-tuning large language models for intelligent legal services', 'Sentiment analysis in the era of large language models: A reality check', 'Least-to-most prompting enables complex reasoning in large language models'], 'Deductive Verification of Chain-of-Thought Reasoning': ['Why exposure bias matters: An imitation learning perspective of error accumulation in language generation', 'Natural language deduction through search over statement compositions', 'Language models are few-shot learners', 'Sparks of artificial general intelligence: Early experiments with gpt-4', 'Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks', 'Teaching large language models to self-debug', 'Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality', 'PaLM: Scaling language modeling with pathways', 'Scaling instruction-finetuned language models', 'Training verifiers to solve math word problems', 'Faithful reasoning using large language models', 'Selection-inference: Exploiting large language models for interpretable logical reasoning', 'Palm-e: An embodied multimodal language model', 'Compositional semantic parsing with large language models', 'Roscoe: A suite of metrics for scoring step-by-step reasoning', 'Hallucinations in large multilingual translation models', 'Measuring mathematical problem solving with the math dataset', 'Training compute-optimal large language models', 'Learning to solve arithmetic word problems with verb categorization', 'Survey of hallucination in natural language generation', 'Large language models are zero-shot reasoners', 'Learning to automatically solve algebra word problems', 'Can language models learn from explanations in context?', 'Program induction by rationale generation: Learning to solve and explain algebraic word problems', 'Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing', 'Learn to explain: Multimodal reasoning via thought chains for science question answering', 'Faithful chain-of-thought reasoning', 'Self-refine: Iterative refinement with self-feedback', 'Few-shot self-rationalization with natural language prompts', 'On faithfulness and factuality in abstractive summarization', 'Gpt-4 technical report', 'Training language models to follow instructions with human feedback', 'Refiner: Reasoning feedback on intermediate representations', 'Receval: Evaluating reasoning chains via correctness and informativeness', 'Street: A multi-task structured reasoning and explanation benchmark', 'Solving general arithmetic word problems', 'Multitask prompted training enables zero-shot task generalization', 'Bloom: A 176b-parameter open-access multilingual language model', 'Toolformer: Language models can teach themselves to use tools', 'Generate & rank: A multi-task framework for math word problems', 'Large language models can be easily distracted by irrelevant context', 'Language models are multilingual chain-of-thought reasoners', 'Reflexion: an autonomous agent with dynamic memory and self-reflection', 'Prompting gpt-3 to be reliable', 'Beyond the imitation game: Quantifying and extrapolating the capabilities of language models', 'Proofwriter: Generating implications, proofs, and abductive statements over natural language', 'Llama: Open and efficient foundation language models', 'Self-consistency improves chain of thought reasoning in language models', 'Emergent abilities of large language models', 'Chain of thought prompting elicits reasoning in large language models', 'Neural text generation with unlikelihood training', 'Large language models are reasoners with self-verification', 'Generating natural language proofs with verifier-guided search', 'React: Synergizing reasoning and acting in language models', 'Star: Self-taught reasoner bootstrapping reasoning with reasoning', 'Socratic models: Composing zero-shot multimodal reasoning with language', 'Opt: Open pre-trained transformer language models', 'Automatic chain of thought prompting in large language models', 'Least-to-most prompting enables complex reasoning in large language models', 'Teaching algorithmic reasoning via in-context learning'], 'SELF-INSTRUCT: Aligning Language Models with Self-Generated Instructions': ['Self-training: A survey', 'PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts', 'Language models are few-shot learners', 'Scaling instruction-finetuned language models', 'Self-training improves pre-training for natural language understanding', 'A survey of data augmentation approaches for nlp', 'Speaker-follower models for vision-and-language navigation', 'Revisiting self-training for neural sequence generation', 'Distilling the knowledge in a neural network', 'Unnatural instructions: Tuning language models with (almost) no human labor', 'Instruction induction: From few examples to natural language task descriptions', 'Large language models can self-improve', 'Large language models struggle to learn long-tail knowledge', 'Multilingual constituency parsing with self-attention and pre-training', 'Constituency parsing with a self-attentive encoder', 'The power of scale for parameter-efficient prompt tuning', 'WANLI: Worker and ai collaboration for natural language inference dataset creation', 'Teaching small language models to reason', 'Leveraging qa datasets to improve generative data augmentation', 'Tuning language models as training data generators for augmentation-enhanced few-shot learning', 'FILM: Following Instructions in Language with Modular Methods', 'Cross-Task Generalization via Natural Language Crowdsourcing Instructions', 'Training Language Models to Follow Instructions with Human Feedback', 'Exploring the limits of transfer learning with a unified text-to-text transformer', 'Impact of pretraining term frequencies on few-shot reasoning', 'Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter', 'Multitask Prompted Training Enables Zero-Shot Task Generalization', 'Generating datasets with pretrained language models', 'ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks', 'Explaining patterns in data with language models via interpretable autoprompting', 'Principle-driven selfalignment of language models from scratch with minimal human supervision', 'Stanford alpaca: An instruction-following llama model', 'Super-naturalinstructions: Generalization via declarative instructions on 1600+ tasks', 'Towards zero-label language learning', 'Finetuned Language Models are Zero-Shot Learners', 'One-Shot Learning from a Demonstration with Hierarchical Latent Language', 'Generating sequences by learning to selfcorrect', 'Learning from Task Descriptions', 'Symbolic knowledge distillation: from general language models to commonsense models', 'Self-training with noisy student improves imagenet classification', 'Baize: An open-source chat model with parameter-efficient tuning on self-chat data', 'Generative data augmentation for commonsense reasoning', 'Guess the instruction! making language models stronger zero-shot learners', 'STar: Self-taught reasoner bootstrapping reasoning with reasoning', 'Pre-trained language models can be fully zero-shot learners', 'Prompt Consistency for Zero-Shot Task Generalization', 'Large language models are human-level prompt engineers']}