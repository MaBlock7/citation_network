literature_titles = {
    "AUTOMATIC CHAIN OF THOUGHT PROMPTING IN LARGE LANGUAGE MODELS": [
        "Language models are fewshot learners",
        "Evaluating large language models trained on code",
        "Palm: Scaling language modeling with pathways",
        "Training verifiers to solve math word problems",
        "Complexity-based prompting for multi-step reasoning",
        "Did Aristotle use a laptop? A question answering benchmark with implicit reasoning strategies",
        "Surface form competition: Why the highest probability answer isn't always right",
        "Learning to solve arithmetic word problems with verb categorization",
        "Large language models are zero-shot reasoners",
        "Parsing algebraic word problems into equations",
        "MAWPS: A math word problem repository",
        "On the advance of making language models better reasoners",
        "Program induction by rationale generation: Learning to solve and explain algebraic word problems",
        "Few-shot parameter-efficient fine-tuning is better and cheaper than in-context learning",
        "What makes good in-context examples for gpt-3?",
        "What makes pre-trained language models better zero/few-shot learners?",
        "Learn to explain: Multimodal reasoning via thought chains for science question answering",
        "Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning",
        "Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity",
        "Noisy channel language model prompting for few-shot text classification",
        "Rethinking the role of demonstrations: What makes in-context learning work?",
        "Cross-task generalization via natural language crowdsourcing instructions",
        "Show your work: Scratchpads for intermediate computation with language models",
        "Training language models to follow instructions with human feedback",
        "Are NLP models really able to solve simple math word problems?",
        "Self-consistency improves chain of thought reasoning in language models",
        "Rationale-augmented ensembles in language models",
        "Do prompt-based models really understand the meaning of their prompts?",
        "Finetuned language models are zero-shot learners",
        "Chain of thought prompting elicits reasoning in large language models",
        "Star: Bootstrapping reasoning with reasoning",
        "Calibrate before use: Improving few-shot performance of language models",
        "Least-to-most prompting enables complex reasoning in large language models",
        "Large language models are human-level prompt engineers"
    ]
}