literature_titles = {
    "PAL: Program-aided Language Models": [
        "Do as I Can, not as I Say: Grounding Language in Robotic Affordances",
        "MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms",
        "Giving bert a calculator: Finding operations and arguments with reading comprehension",
        "Language Models are Few-Shot Learners",
        "Evaluating Large Language Models Trained on Code",
        "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks",
        "Binding language models in symbolic languages",
        "PaLM: Scaling Language Modeling with Pathways",
        "Training Verifiers to Solve Math Word Problems",
        "Just add functions: A neural-symbolic language model",
        "Language model cascades",
        "Neurosymbolic ai: the 3rd wave",
        "The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics",
        "An investigation of procedure and variable names as beacons during program comprehension",
        "Injecting numerical reasoning skills into language models",
        "Neural module networks for reasoning over text",
        "Measuring mathematical problem solving with the MATH dataset",
        "The Curious Case of Neural Text Degeneration",
        "Mawps: A math word problem repository",
        "Solving quantitative reasoning problems with language models",
        "Program Induction by Rationale Generation: Learning to Solve and Explain Algebraic Word Problems",
        "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing",
        "Text and patterns: For effective chain of thought, it takes two to tango",
        "Language models of code are few-shot commonsense learners",
        "Deep learning: A critical appraisal",
        "The next decade in ai: four steps towards robust artificial intelligence",
        "A diverse corpus for evaluating and developing English math word problem solvers",
        "Lila: A unified benchmark for mathematical reasoning",
        "Investigating the limitations of transformers with simple arithmetic tasks",
        "Show your Work: Scratchpads for Intermediate Computation with Language Models",
        "Improving coherence and consistency in neural sequence models with dual-system, neuro-symbolic reasoning",
        "Are NLP Models Really Able to Solve Simple Math Word Problems?",
        "Reasoning like program executors",
        "Limitations of language models in arithmetic and symbolic induction",
        "A Recipe for Arbitrary Text Style Transfer with Large Language Models",
        "Multitask Prompted Training Enables Zero-Shot Task Generalization",
        "Few-shot semantic parsing with language models trained on code",
        "Constrained language models yield few-shot semantic parsers",
        "Challenging big-bench tasks and whether chain-of-thought can solve them",
        "The effects of comments and identifier names on program comprehensibility: an experimental investigation",
        "Rationale-Augmented Ensembles in Language Models",
        "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
        "Finetuned Language Models are Zero-shot Learners",
        "Chain of Thought Prompting Elicits Reasoning in Large Language Models",
        "Autoformalization with Large Language Models",
        "React: Synergizing reasoning and acting in language models",
        "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"
    ]
}