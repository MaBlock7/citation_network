literature_titles = {
    "ASK ME ANYTHING: A SIMPLE STRATEGY FOR PROMPTING LANGUAGE MODELS": [
        "Can foundation models help us achieve perfect secrecy?",
        "Promptsource: An integrated development environment and repository for natural language prompts",
        "Semantic parsing on Freebase from question-answer pairs",
        "GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow",
        "On the opportunities and risks of foundation models",
        "Language models are few-shot learners",
        "Robust principal component analysis?",
        "Palm: Scaling language modeling with pathways",
        "Boolq: Exploring the surprising difficulty of natural yes/no questions",
        "Training verifiers to solve math word problems",
        "Selection-inference: Exploiting large language models for interpretable logical reasoning",
        "The commitmentbank: Investigating projection in naturally occurring discourse",
        "DROP: A reading comprehension benchmark requiring discrete reasoning over paragraphs",
        "How contextual are contextualized word representations? comparing the geometry of bert, elmo, and gpt-2 embeddings",
        "Fast and three-rious: Speeding up weak supervision with triplet methods",
        "The pile: An 800gb dataset of diverse text for language modeling",
        "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering",
        "Training compute-optimal large language models",
        "Surface form competition: Why the highest probability answer isn't always right",
        "How can we know what language models know?",
        "Maieutic prompting: Logically consistent reasoning with recursive explanations",
        "Scaling laws for neural language models",
        "Realtime qa: What's the answer right now?",
        "Looking beyond the surface: A challenge set for reading comprehension over multiple sentences",
        "Natural questions: a benchmark for question answering research",
        "Can language models learn from explanations in context?",
        "The winograd schema challenge",
        "ROUGE: A package for automatic evaluation of summaries",
        "What makes good in-context examples for gpt-3?",
        "Reframing instructional prompts to gptk's language",
        "Lsdsem 2017 shared task: The story cloze test",
        "Can foundation models wrangle your data?",
        "Adversarial nli: A new benchmark for natural language understanding",
        "Training language models to follow instructions with human feedback",
        "Wic: the word-in-context dataset for evaluating context-sensitive meaning representations",
        "Know what you don't know: Unanswerable questions for squad",
        "Snorkel: Rapid training data creation with weak supervision",
        "Training complex models with multi-task weak supervision",
        "Data programming: Creating large training sets, quickly",
        "Choice of plausible alternatives: An evaluation of commonsense causal reasoning",
        "Multitask prompted training enables zero-shot task generalization",
        "It's not just size that matters: Small language models are also few-shot learners",
        "Natural language to code translation with execution",
        "Language models in the loop: Incorporating prompting into weak supervision",
        "Recursive deep models for semantic compositionality over a sentiment treebank",
        "Learning dependency structures for weak supervision models",
        "SuperGLUE: A stickier benchmark for general-purpose language understanding systems",
        "Gpt-j-6b: A 6 billion parameter autoregressive language model",
        "Self-consistency improves chain of thought reasoning in language models",
        "Benchmarking generalization via in-context instructions on 1,600+ language tasks",
        "Finetuned language models are zero-shot learners",
        "Emergent abilities of large language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "Ethical and social risks of harm from language models",
        "Ai chains: Transparent and controllable human-ai interaction by chaining large language model prompts",
        "Seqzero: Few-shot compositional semantic parsing with sequential prompts and zero-shot models",
        "Star: Self-taught reasoner bootstrapping reasoning with reasoning",
        "ReCoRD: Bridging the gap between human and machine commonsense reading comprehension",
        "Opt: Open pre-trained transformer language models",
        "Character-level convolutional networks for text classification",
        "Calibrate before use: Improving few-shot performance of language models",
        "Least-to-most prompting enables complex reasoning in large language models"
    ]
}