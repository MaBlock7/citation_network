literature_titles = {
    "Active Example Selection for In-Context Learning": [
        "A Brief Survey of Deep Reinforcement Learning",
        "Dynamic Programming, first edition",
        "The dangers of underclaiming: Reasons for caution when reporting how NLP systems fail",
        "Language Models are Few-Shot Learners",
        "Committeebased sampling for training probabilistic classifiers",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
        "Learning how to Active Learn: A Deep Reinforcement Learning Approach",
        "Making Pre-trained Language Models Better Few-shot Learners",
        "Double Q-learning",
        "Rainbow: Combining Improvements in Deep Reinforcement Learning",
        "Surface Form Competition: Why the Highest Probability Answer Isn't Always Right",
        "A Survey of Generalisation in Deep Reinforcement Learning",
        "Large Language Models are Zero-Shot Reasoners",
        "Conservative Q-Learning for Offline Reinforcement Learning",
        "The Power of Scale for Parameter-Efficient Prompt Tuning",
        "Self-Improving Reactive Agents Based on Reinforcement Learning, Planning and Teaching",
        "What Makes Good In-Context Examples for GPT-$3$?",
        "Learning How to Actively Learn: A Deep Imitation Learning Approach",
        "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
        "Fantastically Ordered Prompts and Where to Find Them: Overcoming FewShot Prompt Order Sensitivity",
        "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?",
        "Reframing Instructional Prompts to GPTk's Language",
        "Playing Atari with Deep Reinforcement Learning",
        "WebGPT: Browser-assisted question-answering with human feedback",
        "Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping",
        "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales",
        "Curiosity-Driven Exploration by Self-Supervised Prediction",
        "True Few-Shot Learning with Language Models",
        "A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems",
        "Language models are unsupervised multitask learners",
        "Scaling Language Models: Methods, Analysis & Insights from Training Gopher",
        "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
        "Learning To Retrieve Prompts for In-Context Learning",
        "Active learning literature survey",
        "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
        "Natural Value",
        "Building a question answering test collection",
        "SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer",
        "Emergent abilities of large language models",
        "IDPG: An Instance-Dependent Prompt Generation Method",
        "An Explanation of In-context Learning as Implicit Bayesian Inference",
        "OPT: Open Pretrained Transformer Language Models",
        "Character-level Convolutional Networks for Text Classification",
        "Calibrate Before Use: Improving Few-Shot Performance of Language Models"
    ]
}