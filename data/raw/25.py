literature_titles = {
    "Decomposed Prompting : A MODULAR APPROACH FOR SOLVING COMPLEX TASKS": [
        "Neural module networks",
        "Language models are few-shot learners",
        "PaLM: Scaling language modeling with pathways",
        "Training verifiers to solve math word problems",
        "Selection-inference: Exploiting large language models for interpretable logical reasoning",
        "Language model cascades",
        "Successive prompting for decomposing complex questions",
        "PAL: Program-aided language models",
        "Neural module networks for reasoning over text",
        "Constructing a multi-hop QA dataset for comprehensive evaluation of reasoning steps",
        "Self-assembling modular networks for interpretable multi-hop reasoning",
        "Maieutic prompting: Logically consistent reasoning with recursive explanations",
        "Text modular networks: Learning to decompose tasks in the language of existing models",
        "Hey AI, can you solve complex tasks by talking to agents?",
        "Internet-augmented language models through few-shot prompting for open-domain question answering",
        "Standing on the shoulders of giant frozen language models",
        "Multi-hop reading comprehension through question decomposition and rescoring",
        "Show your work: Scratchpads for intermediate computation with language models",
        "Training language models to follow instructions with human feedback",
        "TALM: Tool augmented language models",
        "Unsupervised question decomposition for question answering",
        "True few-shot learning with language models",
        "Measuring and narrowing the compositionality gap in language models",
        "SQuAD: 100, 000+ questions for machine comprehension of text",
        "Solving general arithmetic word problems",
        "Toolformer: Language models can teach themselves to use tools",
        "The web as a knowledge-base for answering complex questions",
        "MuSiQue: Multihop questions via single-hop question composition",
        "Self-consistency improves chain of thought reasoning in language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "Break it down: A question understanding benchmark",
        "HotpotQA: A dataset for diverse, explainable multi-hop question answering",
        "Least-to-most prompting enables complex reasoning in large language models"
    ]
}