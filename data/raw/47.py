literature_titles = {
    "LARGE LANGUAGE MODELS AS OPTIMIZERS": [
        "Backpropagation and stochastic gradient descent method",
        "Palm 2 technical report",
        "Concorde tsp solver",
        "An overview of evolutionary algorithms for parameter optimization",
        "Constitutional ai: Harmlessness from ai feedback",
        "Large language models as tool makers",
        "Evoprompting: Language models for code-level neural architecture search",
        "Improving code generation by training with natural language feedback",
        "When do you need chain-of-thought prompting for chatgpt?",
        "Instructzero: Efficient instruction optimization for black-box large language models",
        "Learning to perform local rewriting for combinatorial optimization",
        "Teaching large language models to self-debug",
        "Towards learning universal hyperparameter optimizers with transformers",
        "Training verifiers to solve math word problems",
        "Rlprompt: Optimizing discrete text prompts with reinforcement learning",
        "Learning heuristics for the tsp by policy gradient",
        "Promptbreeder: Self-referential self-improvement via prompt evolution",
        "The capacity for moral self-correction in large language models",
        "Making pre-trained language models better few-shot learners",
        "Approximate traveling salesman algorithms",
        "Connecting large language models with evolutionary algorithms yields powerful prompt optimizers",
        "The traveling salesman problem and its variations",
        "An extension of the lin-kernighan-helsgaun tsp solver for constrained traveling salesman and vehicle routing problems",
        "The traveling salesman problem",
        "Language models can solve computer tasks",
        "Adam: A method for stochastic optimization",
        "Large language models are zero-shot reasoners",
        "Attention, learn to solve routing problems!",
        "Evolution through large models",
        "The power of scale for parameter-efficient prompt tuning",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Program induction by rationale generation: Learning to solve and explain algebraic word problems",
        "Gpt understands, too",
        "Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity",
        "Let's do a thought experiment: Using counterfactuals to improve moral reasoning",
        "Text and patterns: For effective chain of thought, it takes two to tango",
        "Self-refine: Iterative refinement with self-feedback",
        "Language model crossover: Variation through few-shot prompting",
        "Large language models as general pattern machines",
        "Dera: Enhancing large language model completions with dialog-enabled resolving agents",
        "Reinforcement learning for solving the vehicle routing problem",
        "Demystifying gpt self-repair for code generation",
        "Gurobi optimizer reference manual",
        "Grips: Gradient-free, edit-based instruction search for prompting large language models",
        "Automatic prompt optimization with\"gradient descent\" and beam search",
        "On the momentum term in gradient descent learning algorithms",
        "Learning how to ask: Querying lms with mixtures of soft prompts",
        "Modern heuristic techniques for combinatorial problems",
        "Prompt programming for large language models: Beyond the few-shot paradigm",
        "Derivative-free optimization: a review of algorithms and comparison of software implementations",
        "An analysis of several heuristics for the traveling salesman problem",
        "Solving general arithmetic word problems",
        "Toolformer: Language models can teach themselves to use tools",
        "Autoprompt: Eliciting knowledge from language models with automatically generated prompts",
        "Reflexion: an autonomous agent with dynamic memory and self-reflection",
        "Challenging big-bench tasks and whether chain-of-thought can solve them",
        "Voyager: An open-ended embodied agent with large language models",
        "Self-consistency improves chain of thought reasoning in language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "Larger language models do in-context learning differently",
        "Hard prompts made easy: Gradient-based discrete optimization for prompt tuning and discovery",
        "Wizardlm: Empowering large language models to follow complex instructions",
        "Gps: Genetic prompt search for efficient few-shot learning",
        "System-level natural language feedback",
        "Tempera: Test-time prompt editing via reinforcement learning",
        "Calibrate before use: Improving few-shot performance of language models",
        "Least-to-most prompting enables complex reasoning in large language models",
        "Large language models are human-level prompt engineers"
    ]
}