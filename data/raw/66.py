literature_titles = {
    "REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS": [
        "Imitating interactive intelligence",
        "Do as i can, not as i say: Grounding language in robotic affordances",
        "Inner speech: development, cognitive functions, phenomenology, and neurobiology",
        "Working memory",
        "Language models are few-shot learners",
        "Palm: Scaling language modeling with pathways",
        "Faithful reasoning using large language models",
        "Selection-inference: Exploiting large language models for interpretable logical reasoning",
        "ELI5: Long form question answering",
        "Vygotsky, luria, and the social brain",
        "Improving alignment of dialogue agents via targeted human judgements",
        "A simple language model for task-oriented dialogue",
        "Language models as zero-shot planners: Extracting actionable knowledge for embodied agents",
        "Inner monologue: Embodied reasoning through planning with language models",
        "Lila: Language-informed latent actions",
        "Large language models are zero-shot reasoners",
        "Internet-augmented language models through few-shot prompting for open-domain question answering",
        "Retrieval-augmented generation for knowledge-intensive nlp tasks",
        "Pre-trained language models for interactive decision-making",
        "Ls vygotsky and the problem of localization of functions",
        "Text and patterns: For effective chain of thought, it takes two to tango",
        "Language models are few-shot butlers",
        "Webgpt: Browser-assisted question-answering with human feedback",
        "Show your work: Scratchpads for intermediate computation with language models",
        "A generalist agent",
        "Alfred: A benchmark for interpreting grounded instructions for everyday tasks",
        "Alfworld: Aligning text and embodied environments for interactive learning",
        "Language models that seek for knowledge: Modular search & generation for dialogue and prompt completion",
        "Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage",
        "Fever: a large-scale dataset for fact extraction and verification",
        "Thinking and speech",
        "Self-consistency improves chain of thought reasoning in language models",
        "Rationale-augmented ensembles in language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "Hotpotqa: A dataset for diverse, explainable multi-hop question answering",
        "Keep CALM and explore: Language models for action generation in text-based games",
        "Webshop: Towards scalable real-world web interaction with grounded language agents",
        "Star: Bootstrapping reasoning with reasoning",
        "Least-to-most prompting enables complex reasoning in large language models",
        "Adaptive information seeking for open-domain question answering"
    ]
}