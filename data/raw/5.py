literature_titles = {
    "ART: Automatic multi-step reasoning and tool-use for large language models": [
        "Ask me anything: A simple strategy for prompting language models",
        "Prompting is programming: A query language for large language models",
        "Language models are few-shot learners",
        "Evaluating large language models trained on code",
        "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks",
        "Palm: Scaling language modeling with pathways",
        "Scaling instruction-finetuned language models",
        "Training verifiers to solve math word problems",
        "Successive prompting for decomposing complex questions",
        "Pal: Program-aided language models",
        "Measuring massive multitask language understanding",
        "Unifiedqa: Crossing format boundaries with a single QA system",
        "Decomposed prompting: A modular approach for solving complex tasks",
        "Large language models are zero-shot reasoners",
        "Internet-augmented dialogue generation",
        "Internet-augmented language models through few-shot prompting for open-domain question answering",
        "Few-shot parameter-efficient finetuning is better and cheaper than in-context learning",
        "Cross-task generalization via natural language crowdsourcing instructions",
        "Webgpt: Browser-assisted question-answering with human feedback",
        "Training language models to follow instructions with human feedback",
        "Talm: Tool augmented language models",
        "Are NLP models really able to solve simple math word problems?",
        "Measuring and narrowing the compositionality gap in language models",
        "Multitask prompted training enables zero-shot task generalization",
        "Toolformer: Language models can teach themselves to use tools",
        "Language models that seek for knowledge: Modular search & generation for dialogue and prompt completion",
        "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models",
        "Challenging big-bench tasks and whether chain-of-thought can solve them",
        "Lamda: Language models for dialog applications",
        "Self-consistency improves chain of thought reasoning in language models",
        "Finetuned language models are zero-shot learners",
        "Chain of thought prompting elicits reasoning in large language models",
        "An explanation of in-context learning as implicit bayesian inference",
        "Automatic chain of thought prompting in large language models",
        "Least-to-most prompting enables complex reasoning in large language models"
    ]
}