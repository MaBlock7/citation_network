literature_titles = {
    "Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning": [
        "NLTK: The natural language toolkit",
        "Language models are few-shot learners",
        "Vicuna: An opensource chatbot impressing gpt-4 with 90%* chatgpt quality",
        "Palm: Scaling language modeling with pathways",
        "Beyond i.i.d.: Three levels of generalization for question answering on knowledge bases",
        "Realm: Retrievalaugmented language model pre-training",
        "Constructing a multihop QA dataset for comprehensive evaluation of reasoning steps",
        "Hover: A dataset for many-hop fact extraction and claim verification",
        "TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension",
        "Dense passage retrieval for opendomain question answering",
        "Large language models are zero-shot reasoners",
        "Natural questions: A benchmark for question answering research",
        "Retrieval-augmented generation for knowledge-intensive nlp tasks",
        "Self-prompting large language models for opendomain qa",
        "A survey on multi-hop question answering and generation",
        "Gpt-4 technical report",
        "Training language models to follow instructions with human feedback",
        "Measuring and narrowing the compositionality gap in language models",
        "SentenceBERT: Sentence embeddings using Siamese BERTnetworks",
        "How much knowledge can you pack into the parameters of a language model?",
        "The web as a knowledge-base for answering complex questions",
        "Stanford alpaca: An instruction-following llama model",
        "Llama: Open and efficient foundation language models",
        "Musique: Multihop questions via single-hop question composition",
        "Iteratively prompt pre-trained language models for chain of thought",
        "Self-consistency improves chain of thought reasoning in language models",
        "Chain-of-thought prompting elicits reasoning in large language models",
        "Wizardlm: Empowering large language models to follow complex instructions",
        "HotpotQA: A dataset for diverse, explainable multi-hop question answering",
        "Generate rather than retrieve: Large language models are strong context generators",
        "Star: Bootstrapping reasoning with reasoning",
        "Automatic chain of thought prompting in large language models",
        "Least-to-most prompting enables complex reasoning in large language models"
    ]
}