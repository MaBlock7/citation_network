literature_titles = {
    "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models": [
        "Do as I can, not as I say: Grounding language in robotic affordances",
        "MathQA: Towards interpretable math word problem solving with operation-based formalisms",
        "Giving BERT a calculator: Finding operations and arguments with reading comprehension",
        "Learning with latent language",
        "Program synthesis with large language models",
        "Beyond the imitation game: Measuring and extrapolating the capabilities of language models",
        "Flexible generation of natural language deductions",
        "Language models are few-shot learners",
        "Making neural programming architectures generalize via recursion",
        "e-SNLI: Natural language inference with natural language explanations",
        "Can rationalization improve robustness?",
        "Evaluating large language models trained on code",
        "Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension",
        "Semantically-aligned equation generation for solving and reasoning math word problems",
        "Transformers as soft reasoners over language",
        "Training verifiers to solve math word problems",
        "BERT: Pre-training of deep bidirectional transformers for language understanding",
        "Neural logic machines",
        "Benefits of intermediate annotations in reading comprehension",
        "Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies",
        "DREAM: Uncovering mental models behind language models",
        "Training classifiers with natural language explanations",
        "When can models learn from explanations? A formal framework for understanding the roles of explanation data",
        "Measuring mathematical problem solving with the math dataset",
        "Learning to solve arithmetic word problems with verb categorization",
        "Learning to reason deductively: Math word problem solving as complex relation extraction",
        "Scaling laws for neural language models",
        "MAWPS: A math word problem repository",
        "Can language models learn from explanations in context?",
        "MWPToolkit: An open-source framework for deep learning-based math word problem solvers",
        "How many data points is a prompt worth?",
        "The power of scale for parameter-efficient prompt tuning",
        "Solving logic puzzles: From robust processing to precise semantics",
        "Prefix-tuning: Optimizing continuous prompts for generation",
        "Explainable multi-hop verbal reasoning through internal monologue",
        "Program induction by rationale generation: Learning to solve and explain algebraic word problems",
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "Rationale-inspired natural language explanations with commonsense",
        "Few-shot self-rationalization with natural language prompts",
        "On faithfulness and factuality in abstractive summarization",
        "A diverse corpus for evaluating and developing English math word problem solvers",
        "Rethinking the role of demonstrations: What makes in-context learning work?",
        "WT5?! Training text-to-text models to explain their predictions",
        "Show your work: Scratchpads for intermediate computation with language models",
        "Training language models to follow instructions with human feedback",
        "Are NLP models really able to solve simple math word problems?",
        "Deep contextualized word representations",
        "Reasoning like program executors",
        "Measuring and improving BERT's mathematical abilities by predicting the order of reasoning",
        "Scaling language models: Methods, analysis & insights from training Gopher",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "SelfExplain: A self-explaining architecture for neural text classifiers",
        "Explain yourself! Leveraging language models for commonsense reasoning",
        "NumNet: Machine reading comprehension with numerical reasoning",
        "Measuring attribution in natural language generation models",
        "Teaching autoregressive language models complex tasks by demonstration",
        "A recipe for arbitrary text style transfer with large language models",
        "Prompt programming for large language models: Beyond the few-shot paradigm",
        "Solving general arithmetic word problems",
        "Reasoning about Quantities in Natural Language",
        "RuleBERT: Teaching soft rules to pre-trained language models",
        "Multitask prompted training enables zero-shot task generalization",
        "Generate & rank: A multi-task framework for math word problems",
        "CommonsenseQA: A question answering challenge targeting commonsense knowledge",
        "Leap-of-thought: Teaching pre-trained models to systematically reason over implicit knowledge",
        "CommonsenseQA 2.0: Exposing the limits of ai through gamification",
        "Unifying language learning paradigms",
        "LaMDA: Language models for dialog applications",
        "Self-consistency improves chain of thought reasoning in language models",
        "Benchmarking generalization via in-context instructions on 1,600+ language tasks",
        "Finetuned language models are zero-shot learners",
        "Emergent abilities of large language models",
        "Reframing human-AI collaboration for generating free-text explanations",
        "Teach me to explain: A review of datasets for explainable NLP",
        "Measuring association between labels and free-text rationales",
        "PromptChainer: Chaining large language model prompts through visual programming",
        "AI chains: Transparent and controllable human-AI interaction by chaining large language model prompts",
        "Neural execution engines: Learning to execute subroutines",
        "Refining language models with compositional explanations",
        "The unreliability of explanations in few-shot in-context learning",
        "Few-shot out-of-domain transfer learning of natural language explanations",
        "Using “annotator rationales” to improve machine learning for text categorization",
        "Learning to execute",
        "STaR: Bootstrapping reasoning with reasoning",
        "Calibrate before use: Improving few-shot performance of language models",
        "Towards interpretable natural language understanding with explanations as latent variables"
    ]
}