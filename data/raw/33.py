literature_titles = {
    "Faithful Chain-of-Thought Reasoning": [
        "Do As I Can, Not As I Say: Grounding Language in Robotic Affordances",
        "FROM SYSTEM 1 DEEP LEARNING TO SYSTEM 2 DEEP LEARNING",
        "Beyond the Imitation Game: Measuring and extrapolating the capabilities of language models",
        "Language Models are Few-Shot Learners",
        "Evaluating Large Language Models Trained on Code",
        "Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks",
        "Training Verifiers to Solve Math Word Problems",
        "PAL: Program-aided Language Models",
        "Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies",
        "Explaining Explanations: An Overview of Interpretability of Machine Learning",
        "Harvey Friedman's Research on the Foundations of Mathematics",
        "The Promise and Peril of Human Evaluation for Model Interpretability",
        "Towards faithfully interpretable NLP systems: How should we define and evaluate faithfulness?",
        "Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations",
        "Large Language Models are Zero-Shot Reasoners",
        "Solving Quantitative Reasoning Problems with Language Models",
        "On the Advance of Making Language Models Better Reasoners",
        "Program induction by rationale generation: Learning to solve and explain algebraic word problems",
        "A diverse corpus for evaluating and developing English math word problem solvers",
        "Show Your Work: Scratchpads for Intermediate Computation with Language Models",
        "Gpt-4 technical report",
        "Are NLP models really able to solve simple math word problems?",
        "Boosted prompt ensembles for large language models",
        "Learning to deceive with attention-based explanations",
        "Limitations of Language Models in Arithmetic and Symbolic Induction",
        "Explaining the predictions of any classifier",
        "Solving general arithmetic word problems",
        "Inseq: An interpretability toolkit for sequence generation models",
        "CLUTRR: A diagnostic benchmark for inductive reasoning from text",
        "Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods",
        "Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting",
        "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
        "Chain of Thought Prompting Elicits Reasoning in Large Language Models",
        "Interpreting language models with contrastive explanations",
        "Improved logical reasoning of language models via differentiable symbolic programming",
        "Leastto-Most Prompting Enables Complex Reasoning in Large Language Models"
    ]
}