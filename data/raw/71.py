literature_titles = {
    "Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering": [
        "The description length of deep learning models",
        "A large annotated corpus for learning natural language inference",
        "Language models are few-shot learners",
        "Training verifiers to solve math word problems",
        "Rlprompt: Optimizing discrete text prompts with reinforcement learning",
        "Making pre-trained language models better few-shot learners",
        "Did aristotle use a laptop? A question answering benchmark with implicit reasoning strategies",
        "The minimum description length principle",
        "Toward semantics-based answer pinpointing",
        "How can we know what language models know?",
        "TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension",
        "Ground-truth labels matter: A deeper look into input-label demonstrations",
        "Autoencoding variational bayes",
        "k-dpps: Fixedsize determinantal point processes",
        "Reordering examples helps during priming-based few-shot learning",
        "What makes good in-context examples for gpt-3?",
        "Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity",
        "Rethinking the role of demonstrations: What makes in-context learning work?",
        "Grips: Gradient-free, edit-based instruction search for prompting large language models",
        "Language models are unsupervised multitask learners",
        "Scaling language models: Methods, analysis & insights from training gopher",
        "Learning to retrieve prompts for in-context learning",
        "Autoprompt: Eliciting knowledge from language models with automatically generated prompts",
        "Recursive deep models for semantic compositionality over a sentiment treebank",
        "A formal theory of inductive inference. part i",
        "An information-theoretic approach to prompt engineering without ground truth labels",
        "Selective annotation makes language models better few-shot learners",
        "CommonsenseQA: A question answering challenge targeting commonsense knowledge",
        "Transformer memory as a differentiable search index",
        "Deep learning and the information bottleneck principle",
        "Glue: A multi-task benchmark and analysis platform for natural language understanding",
        "Emergent abilities of large language models",
        "A broad-coverage challenge corpus for sentence understanding through inference",
        "An explanation of in-context learning as implicit bayesian inference",
        "Zeroprompt: Scaling prompt-based pretraining to 1,000 tasks improves zero-shot generalization",
        "Zerogen: Efficient zero-shot learning via dataset generation",
        "Character-level convolutional networks for text classification",
        "Calibrate before use: Improving few-shot performance of language models"
    ]
}