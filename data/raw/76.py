literature_titles = {
    "SELF-REFINE: Iterative Refinement with Self-Feedback": [
        "NLTK: The natural language toolkit",
        "Training a helpful and harmless assistant with reinforcement learning from human feedback",
        "Constitutional ai: Harmlessness from ai feedback",
        "Triangulating Python Performance Issues with SCALENE",
        "Large language models can implement policy iteration",
        "Interval estimation for a binomial proportion",
        "Language models are few-shot learners",
        "Evaluating Large Language Models Trained on Code",
        "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality",
        "Training verifiers to solve math word problems",
        "Teaching a black-box learner",
        "Read, revise, repeat: A system demonstration for human-in-the-loop iterative text revision",
        "NL-EDIT: Correcting semantic parse errors through natural language interaction",
        "A cognitive process theory of writing",
        "Gptscore: Evaluate as you desire",
        "Pal: Program-aided language models",
        "Koala: A dialogue model for academic research",
        "Language models can solve computer tasks",
        "CodeRL: Mastering Code Generation through Pretrained Models and Deep Reinforcement Learning",
        "Delete, retrieve, generate: a simple approach to sentiment and style transfer",
        "CommonGen: A constrained text generation challenge for generative commonsense reasoning",
        "Rainier: Reinforced knowledge introspector for commonsense question answering",
        "Quark: Controllable text generation with reinforced unlearning",
        "Learning performance-improving code edits",
        "Memory-assisted prompt editing to improve gpt-3 after deployment",
        "Think about it! improving defeasible reasoning by first modeling the question scenario",
        "Unsupervised evaluation of interactive dialog with DialoGPT",
        "Codegen: An open large language model for code with multi-turn program synthesis",
        "Model index for researchers",
        "Training language models to follow instructions with human feedback",
        "Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback",
        "Style transfer through back-translation",
        "Measuring and narrowing the compositionality gap in language models",
        "Codenet: A large-scale ai for code dataset for learning a diversity of coding tasks",
        "Learning to model editing processes",
        "Self-critiquing models for assisting human evaluators",
        "Training language models with natural language feedback",
        "Peer: A collaborative language model",
        "Reflexion: an autonomous agent with dynamic memory and self-reflection",
        "The architecture of complexity",
        "Learning to summarize with human feedback",
        "Principle-driven self-alignment of language models from scratch with minimal human supervision",
        "Challenging big-bench tasks and whether chain-of-thought can solve them",
        "Interscript: A dataset for interactive learning of scripts through error feedback",
        "Learning to repair: Repairing model output errors after deployment using a dynamic memory of feedback",
        "Llama: Open and efficient foundation language models",
        "Chain of Thought Prompting Elicits Reasoning in Large Language Models",
        "Generating sequences by learning to self-correct",
        "Re3: Generating longer stories with recursive reprompting and revision",
        "Graph-based, self-supervised program repair from diagnostic feedback",
        "Character-level convolutional networks for text classification"
    ]
}