literature_titles = {
    "CHAIN-OF-KNOWLEDGE: GROUNDING LARGE LANGUAGE MODELS VIA DYNAMIC KNOWLEDGE ADAPTING OVER HETEROGENEOUS SOURCES": [
        "Autoregressive entity retrieval",
        "KQA pro: A dataset with explicit compositional programs for complex question answering over knowledge base",
        "Reading Wikipedia to answer open-domain questions",
        "Chatgpt's one-year anniversary: Are open-source large language models catching up?",
        "Is gpt-4 a good data analyst?",
        "Palm: Scaling language modeling with pathways",
        "Scaling instruction-finetuned language models",
        "Is gpt-3 a good data annotator?",
        "Can machine translation systems be evaluated by the crowd alone",
        "Retrieval augmented language model pre-training",
        "Medalpaca â€“ an open-source collection of medical conversational ai models and training data",
        "Measuring massive multitask language understanding",
        "Lora: Low-rank adaptation of large language models",
        "Survey of hallucination in natural language generation",
        "Findings of the 2022 conference on machine translation (WMT22)",
        "The measurement of observer agreement for categorical data",
        "Retrieval-augmented generation for knowledge-intensive nlp tasks",
        "Chain of hindsight aligns language models with feedback",
        "Learn to explain: Multimodal reasoning via thought chains for science question answering",
        "Augmented large language models with parametric knowledge guiding",
        "Augmented language models: a survey",
        "FeTaQA: Free-form table question answering",
        "Gpt-4 technical report",
        "Training language models to follow instructions with human feedback",
        "Medmcqa : A large-scale multi-subject multi-choice dataset for medical domain question answering",
        "Fact-checking complex claims with program-guided reasoning",
        "KILT: a benchmark for knowledge intensive language tasks",
        "Toolformer: Language models can teach themselves to use tools",
        "Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface",
        "Replug: Retrieval-augmented black-box language models",
        "FEVER: a large-scale dataset for fact extraction and VERification",
        "Llama 2: Open foundation and fine-tuned chat models",
        "Lc-quad: A corpus for complex question answering over knowledge graphs",
        "Self-consistency improves chain of thought reasoning in language models",
        "Chain-of-thought prompting elicits reasoning in large language models",
        "UnifiedSKG: Unifying and multi-tasking structured knowledge grounding with text-to-text language models",
        "HotpotQA: A dataset for diverse, explainable multi-hop question answering",
        "React: Synergizing reasoning and acting in language models",
        "Retrieving multimodal information for augmented generation: A survey",
        "Can chatgpt-like generative models guarantee factual accuracy? on the mistakes of new generation search engines",
        "Verify-and-edit: A knowledge-enhanced chain-of-thought framework"
    ]
}