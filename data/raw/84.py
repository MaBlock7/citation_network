literature_titles = {
    "Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework": [
        "Language models are few-shot learners",
        "Reading Wikipedia to answer open-domain questions",
        "Palm: Scaling language modeling with pathways",
        "Selection-inference: Exploiting large language models for interpretable logical reasoning",
        "Roscoe: A suite of metrics for scoring step-by-step reasoning",
        "Realm: Retrieval-augmented language model pre-training",
        "Constructing a multihop QA dataset for comprehensive evaluation of reasoning steps",
        "Dense passage retrieval for open-domain question answering",
        "Internet-augmented language models through few-shot prompting for open-domain question answering",
        "Is chatgpt really a “code red” for google search?",
        "Interrater reliability: the kappa statistic",
        "Chatgpt: Optimizing language models for dialogue",
        "Training language models to follow instructions with human feedback",
        "Measuring and narrowing the compositionality gap in language models",
        "Sentence-BERT: Sentence embeddings using Siamese BERT-networks",
        "Toolformer: Language models can teach themselves to use tools",
        "FEVER: a large-scale dataset for fact extraction and VERification",
        "Self-consistency improves chain of thought reasoning in language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "Reframing human-AI collaboration for generating free-text explanations",
        "HotpotQA: A dataset for diverse, explainable multi-hop question answering",
        "ReAct: Synergizing reasoning and acting in language models",
        "The unreliability of explanations in few-shot prompting for textual reasoning",
        "Can chatgpt-like generative models guarantee factual accuracy? on the mistakes of new generation search engines",
        "Least-to-most prompting enables complex reasoning in large language models"
    ]
}