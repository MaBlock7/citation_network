literature_titles = {
    "Boosting Language Models Reasoning with Chain-of-Knowledge Prompting": [
        "Logic-guided data augmentation and regularization for consistent question answering",
        "Training a helpful and harmless assistant with reinforcement learning from human feedback",
        "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models",
        "Language models are few-shot learners",
        "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks",
        "Meta-learning via language model in-context tuning",
        "Palm: Scaling language modeling with pathways",
        "BoolQ: Exploring the surprising difficulty of natural yes/no questions",
        "Think you have solved question answering? try arc, the ai2 reasoning challenge",
        "Training verifiers to solve math word problems",
        "BERT: pre-training of deep bidirectional transformers for language understanding",
        "A survey for in-context learning",
        "Pal: Program-aided language models",
        "Simcse: Simple contrastive learning of sentence embeddings",
        "Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies",
        "Inductive and deductive reasoning",
        "Accelerating large-scale inference with anisotropic vector quantization",
        "Large language models can self-improve",
        "Towards faithfully interpretable NLP systems: How should we define and evaluate faithfulness?",
        "Survey of hallucination in natural language generation",
        "Large language models are zero-shot reasoners",
        "Internet-augmented dialogue generation",
        "Making language models better reasoners with step-aware verifier",
        "Guided generation of cause and effect",
        "Learning entity and relation embeddings for knowledge graph completion",
        "Program induction by rationale generation: Learning to solve and explain algebraic word problems",
        "What makes good in-context examples for GPT-3?",
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "Mind's eye: Grounded language model reasoning through simulation",
        "Chameleon: Plug-and-play compositional reasoning with large language models",
        "Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity",
        "Faithful chain-of-thought reasoning",
        "Can a suit of armor conduct electricity? a new dataset for open book question answering",
        "Metaicl: Learning to learn in context",
        "Rethinking the role of demonstrations: What makes in-context learning work?",
        "GLUCOSE: GeneraLized and COntextualized story explanations",
        "Webgpt: Browser-assisted question-answering with human feedback",
        "What in-context learning “learns” in-context: Disentangling task recognition and task learning",
        "Knowledge-incontext: Towards knowledgeable semi-parametric language models",
        "Are NLP models really able to solve simple math word problems?",
        "How context affects language models' factual predictions",
        "Scaling language models: Methods, analysis & insights from training gopher",
        "Solving general arithmetic word problems",
        "Atomic: An atlas of machine commonsense for if-then reasoning",
        "Bloom: A 176b-parameter open-access multilingual language model",
        "Toolformer: Language models can teach themselves to use tools",
        "On the effect of pretraining corpora on in-context learning by a large-scale language model",
        "Prompting GPT-3 to be reliable",
        "Conceptnet 5.5: An open multilingual graph of general knowledge",
        "CommonsenseQA: A question answering challenge targeting commonsense knowledge",
        "Lamda: Language models for dialog applications",
        "Llama: Open and efficient foundation language models",
        "Towards understanding chain-of-thought prompting: An empirical study of what matters",
        "Kepler: A unified model for knowledge embedding and pre-trained language representation",
        "Rationale-augmented ensembles in language models",
        "Self-consistency improves chain of thought reasoning in language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "The unreliability of explanations in few-shot prompting for textual reasoning",
        "Do large language models know what they don't know?",
        "Ground-truth labels matter: A deeper look into input-label demonstrations",
        "ASER: A large-scale eventuality knowledge graph",
        "ASER: towards large-scale commonsense knowledge acquisition via higher-order selectional preference over eventualities",
        "Opt: Open pre-trained transformer language models",
        "Automatic chain of thought prompting in large language models",
        "Calibrate before use: Improving few-shot performance of language models",
        "Least-to-most prompting enables complex reasoning in large language models"
    ]
}