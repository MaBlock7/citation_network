literature_titles = {
    "Generated Knowledge Prompting for Commonsense Reasoning": [
        "Benchmarking knowledge-enhanced commonsense question answering via knowledge-to-text transformation",
        "Dynamic neuro-symbolic knowledge graph construction for zero-shot commonsense question answering",
        "COMET: Commonsense transformers for automatic knowledge graph construction",
        "Language models are few-shot learners",
        "Incorporating commonsense knowledge graph in pretrained models for social commonsense tasks",
        "Commonsense knowledge mining from pretrained models",
        "Training products of experts by minimizing contrastive divergence",
        "The curious case of neural text degeneration",
        "How can we know what language models know?",
        "UNIFIEDQA: Crossing format boundaries with a single QA system",
        "Qasc: A dataset for question answering via sentence composition",
        "The measurement of observer agreement for categorical data",
        "Explaining question answering models through text generation",
        "KagNet: Knowledge-aware graph networks for commonsense reasoning",
        "Birds have four legs?! NumerSense: Probing Numerical Commonsense Knowledge of Pre-Trained Language Models",
        "Unicorn on rainbow: A universal commonsense reasoning model on a new multitask benchmark",
        "Graphbased reasoning over heterogeneous external knowledge for commonsense question answering",
        "Towards generalizable neuro-symbolic systems for commonsense question answering",
        "Knowledge-driven data construction for zero-shot evaluation in commonsense question answering",
        "How additional knowledge can improve natural language commonsense question answering?",
        "Prompting contrastive explanations for commonsense reasoning tasks",
        "Language models as knowledge bases?",
        "Zero-shot text classification with generative language models",
        "Exploring the limits of transfer learning with a unified text-to-text transformer",
        "Explain yourself! leveraging language models for commonsense reasoning",
        "Atomic: An atlas of machine commonsense for if-then reasoning",
        "Social IQa: Commonsense reasoning about social interactions",
        "Exploiting cloze-questions for few-shot text classification and natural language inference",
        "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts",
        "Unsupervised commonsense question answering with self-talk",
        "Conceptnet 5.5: An open multilingual graph of general knowledge",
        "CommonsenseQA: A question answering challenge targeting commonsense knowledge",
        "Commonsenseqa 2.0: Exposing the limits of ai through gamification",
        "A simple method for commonsense reasoning",
        "Usc ink submission on numersense",
        "Designing templates for eliciting commonsense knowledge from pretrained sequence-to-sequence models",
        "QA-GNN: Reasoning with language models and knowledge graphs for question answering",
        "Stanford submission on numersense",
        "Improving question answering by commonsense-based pre-training"
    ]
}