literature_titles = {
    "Large Language Models are Better Reasoners with Self-Verification": [
        "What learning algorithm is in-context learning? investigations with linear models",
        "Mathqa: Towards interpretable math word problem solving with operation-based formalisms",
        "Are nlp models really able to solve simple math word problems?",
        "Ask me anything: A simple strategy for prompting language models",
        "Logicguided data augmentation and regularization for consistent question answering",
        "Abductive commonsense reasoning",
        "Language models are few-shot learners",
        "Evaluating large language models trained on code",
        "A survey of chain of thought reasoning: Advances, frontiers and future",
        "Training verifiers to solve math word problems",
        "Reasonbert: Pre-trained to reason with distant supervision",
        "Chain-of-verification reduces hallucination in large language models",
        "On a new law of large numbers",
        "Complexity-based prompting for multi-step reasoning",
        "Pal: Program-aided language models",
        "Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies",
        "Eva2.0: Investigating open-domain chinese dialogue systems with large-scale pre-training",
        "Array programming with numpy",
        "Large language models are reasoning teachers",
        "Learning to solve arithmetic word problems with verb categorization",
        "A multi-type multi-span network for reading comprehension that requires discrete reasoning",
        "Qascore - an unsupervised unreferenced metric for the question generation evaluation",
        "Large language models are zero-shot reasoners",
        "Parsing algebraic word problems into equations",
        "Learning to automatically solve algebra word problems",
        "More but correct: Generating diversified and entity-revised medical response",
        "Modeling intrarelation in math word problems with different functional multi-head attentions",
        "On the advance of making language models better reasoners",
        "Let's verify step by step",
        "Program induction by rationale generation : Learning to solve and explain algebraic word problems",
        "Logiqa: A challenge dataset for machine reading comprehension with logical reasoning",
        "What makes pre-trained language models better zero/few-shot learners?",
        "Language models of code are few-shot commonsense learners",
        "Training language models to follow instructions with human feedback",
        "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models",
        "Paradigm shift in natural language processing",
        "Answer-focused and position-aware neural question generation",
        "Commonsenseqa: A question answering challenge targeting commonsense knowledge",
        "Towards understanding chain-of-thought prompting: An empirical study of what matters",
        "Translating a math word problem to a expression tree",
        "Logic-driven context extension and data augmentation for logical reasoning of text",
        "Large language models are implicitly topic models: Explaining and finding good demonstrations for in-context learning",
        "Self-consistency improves chain of thought reasoning in language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "Large language models need holistically thought in medical conversational qa",
        "Mastering symbolic operations: Augmenting language models with compiled neural networks",
        "Medconqa: Medical conversational question answering system based on knowledge graphs",
        "A survey on non-autoregressive generation for neural machine translation and beyond",
        "Human parity on commonsenseqa: Augmenting self-attention with external attention",
        "Turning tables: Generating examples from semistructured tables for endowing language models with reasoning skills",
        "Reclor: A reading comprehension dataset requiring logical reasoning",
        "Towards better chain-of-thought prompting strategies: A survey",
        "Automatic chain of thought prompting in large language models",
        "Least-to-most prompting enables complex reasoning in large language models",
        "A knowledge storage and semantic space alignment method for multi-documents dialogue generation",
        "Reasonchainqa: Text-based complex question answering with explainable evidence chains",
        "Learning to build reasoning chains by reliable path retrieval"
    ]
}