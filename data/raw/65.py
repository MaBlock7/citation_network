literature_titles = {
    "Prompting Large Language Models With the Socratic Method": [
        "Socratic irony and argumentation",
        "Language models are few-shot learners",
        "Asking the right questions, a guide to critical thinking",
        "A few-shot semantic parser for wizard-of-oz dialogues with the precise thingtalk representation",
        "CRIT: An inquisitive prompt template for critical reading (extended)",
        "Natural language processing (almost) from scratch",
        "Bert: Pre-training of deep bidirectional transformers for language understanding",
        "Word-level coreference resolution",
        "Coarse-to-fine decoding for neural semantic parsing",
        "The Thinker's Guide to the Art of Asking Essential Questions",
        "How close is ChatGPT to human experts? comparison corpus, evaluation, and detection",
        "Ptr: Prompt tuning with rules for text classification",
        "Bertese: Learning to speak to bert",
        "Towards reasoning in large language models: A survey",
        "How Can We Know What Language Models Know?",
        "Maieutic prompting: Logically consistent reasoning with recursive explanations",
        "Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition",
        "RACE: Largescale ReAding comprehension dataset from examinations",
        "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
        "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "501 Critical Reading Questions",
        "Augmented language models: a survey",
        "ChatGPT",
        "The pagerank citation ranking: Bringing order to the web",
        "Compositional semantic parsing on semistructured tables",
        "Critical Thinking: What Every Person Needs to Survive in a Rapidly Changing World",
        "Critical thinking: The art of socratic questioning, part iii",
        "Counterfactuals and Causal Inference: Methods and Principles for Social Research",
        "Model ensemble instead of prompt fusion: a sample-specific knowledge transfer method for few-shot prompt tuning",
        "How to Win Every Argument",
        "The republic",
        "Four problems of abduction: A brief history",
        "Cross-Examination: Science and Techniques",
        "Exploiting cloze-questions for few-shot text classification and natural language inference",
        "Would socrates have actually used the \"socratic method\" for clinical teaching?",
        "Mediating between the muse and the masses: Inspiration and the actualization of creative ideas",
        "Attention is all you need",
        "Self-consistency improves chain of thought reasoning in language models",
        "Chain of thought prompting elicits reasoning in large language models",
        "Socratic method",
        "Transfertransfo: A transfer learning approach for neural network based conversational agents",
        "Internet encyclopedia of philosophy",
        "Socratic models: Composing zero-shot multimodal reasoning with language",
        "A static and dynamic attention framework for multi-turn dialogue generation",
        "Structure-aware fine-tuning of sequence-to-sequence transformers for transition-based AMR parsing"
    ]
}